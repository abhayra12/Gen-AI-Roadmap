{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cc8e0c",
   "metadata": {},
   "source": [
    "# ðŸ” Week 7-8 Â· Notebook 04 Â· Advanced LCEL: Building Resilient Workflows\n",
    "\n",
    "**Module:** LangChain, Agents, & Advanced RAG  \n",
    "**Project:** Manufacturing Copilot - Engineering for Failure\n",
    "\n",
    "---\n",
    "\n",
    "### Beyond Linear Chains: Orchestrating Complex Workflows\n",
    "\n",
    "So far, we've built simple, linear chains: `prompt | model | parser`. But real-world applications are rarely so straightforward. They need to handle multiple steps, execute tasks in parallel, and, most importantly, be resilient to failure. What happens if a database connection drops? Or an API call times out?\n",
    "\n",
    "This is where the full power of the **LangChain Expression Language (LCEL)** shines. LCEL is more than just a way to pipe components together; it's a complete language for orchestrating complex, non-linear workflows.\n",
    "\n",
    "In this notebook, we will explore advanced LCEL concepts to build robust and resilient AI systems. We will learn how to:\n",
    "-   Execute different parts of our chain in parallel.\n",
    "-   Create fallback mechanisms to handle errors gracefully.\n",
    "-   Implement a \"Circuit Breaker\" pattern to prevent cascading failures.\n",
    "\n",
    "These techniques are essential for moving from simple prototypes to production-grade applications that can withstand the unpredictability of the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05721583",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to build sophisticated, production-ready workflows with LCEL. You will learn to:\n",
    "\n",
    "1.  **Orchestrate Non-Linear Steps with `RunnableParallel`:** Construct chains where multiple operations (like retrieval and data formatting) can run in parallel.\n",
    "2.  **Implement Resilient Fallbacks:** Use the `.with_fallbacks()` method to create chains that can gracefully handle errors by trying alternative paths.\n",
    "3.  **Create Custom Logic with `RunnableLambda`:** Wrap any Python function into a reusable LCEL component.\n",
    "4.  **Design a \"Circuit Breaker\" for Failure Prevention:** Implement a stateful pattern to temporarily halt operations after repeated failures, preventing system overloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c3382",
   "metadata": {},
   "source": [
    "### Scenario: Building a Resilient Financial Q&A System\n",
    "\n",
    "Imagine you are building a financial services chatbot. Your customers expect fast, accurate answers to their questions. However, the primary Large Language Model (LLM) you use might occasionally fail due to high traffic, API rate limits, or other transient issues.\n",
    "\n",
    "To ensure a seamless user experience, you need to design a system that can handle these failures gracefully. Your goal is to build a workflow that:\n",
    "1.  **Tries the primary, high-performance model first.**\n",
    "2.  **If the primary model fails, it automatically switches to a reliable secondary model.**\n",
    "3.  **If both models fail repeatedly, it triggers a \"circuit breaker\"** to stop sending requests for a short period, preventing further errors and allowing the system to recover.\n",
    "\n",
    "This notebook will guide you through implementing this resilient workflow using advanced LCEL features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f2ea6",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's install the necessary libraries. We'll need `langchain-openai` for the models, `python-dotenv` to manage our API keys securely, and `langchain` for the core framework.\n",
    "\n",
    "> âš ï¸ **Kernel Restart**: After running the installation cell below, you may need to restart the kernel for the changes to take effect. You can do this from the \"Kernel\" menu in your Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ebf38",
   "metadata": {},
   "source": [
    "Next, we'll load the API keys from a `.env` file. This is a best practice for keeping your credentials secure and out of your codebase.\n",
    "\n",
    "Create a `.env` file in the same directory as this notebook with the following content:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"your_openai_api_key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"OPENAI_API_KEY not found. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10a74b",
   "metadata": {},
   "source": [
    "## 2. Core Components: Prompt, Models, and Parser\n",
    "\n",
    "Let's define the basic building blocks for our chain. We'll create a prompt template, define two different OpenAI models (a primary and a fallback), and an output parser.\n",
    "\n",
    "-   **`ChatPromptTemplate`**: Structures the input for the model.\n",
    "-   **`ChatOpenAI`**: The interface to the OpenAI models. We'll use `gpt-4o` as our powerful primary model and `gpt-3.5-turbo` as our reliable fallback.\n",
    "-   **`StrOutputParser`**: A simple parser to convert the model's `AIMessage` output into a clean string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab334f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Prompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a helpful financial assistant. Answer the following question: {question}\"\n",
    ")\n",
    "\n",
    "# 2. Models\n",
    "# Primary, high-performance model\n",
    "primary_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# Fallback, reliable model\n",
    "fallback_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 3. Output Parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb0400",
   "metadata": {},
   "source": [
    "## 3. Building a Resilient Chain with Fallbacks\n",
    "\n",
    "The core of our resilient system is the ability to fall back to a secondary model if the primary one fails. LCEL makes this incredibly simple with the `.with_fallbacks()` method.\n",
    "\n",
    "You can attach this method to any `Runnable` (like a model or a chain). It takes a list of alternative `Runnables` to try in order if the primary one raises an exception.\n",
    "\n",
    "Here, we'll create a chain where `primary_llm` (`gpt-4o`) is the first choice. If it fails, the chain will automatically retry the request with `fallback_llm` (`gpt-3.5-turbo`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain with a fallback model\n",
    "resilient_chain = prompt | primary_llm.with_fallbacks([fallback_llm]) | output_parser\n",
    "\n",
    "# Let's test it. This will use the primary model (gpt-4o)\n",
    "question = \"What is the current market capitalization of Apple Inc.?\"\n",
    "response = resilient_chain.invoke({\"question\": question})\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89d960",
   "metadata": {},
   "source": [
    "### Simulating an Error to Test the Fallback\n",
    "\n",
    "How can we be sure the fallback works? We can create a \"faulty\" model that is designed to fail.\n",
    "\n",
    "Here, we'll use `RunnableLambda` to wrap a simple Python function that always raises an exception. `RunnableLambda` is a powerful tool that lets you turn any function or lambda into a `Runnable` component, making it easy to integrate custom logic into your LCEL chains.\n",
    "\n",
    "We will place this faulty model as the primary LLM in our chain. When we invoke the chain, it will first try the faulty model, which will fail. Then, thanks to `.with_fallbacks()`, it will automatically switch to the next model in the listâ€”our `primary_llm` (`gpt-4o`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# A simple function that always raises an error\n",
    "def faulty_model_func(input):\n",
    "    raise ValueError(\"This model is intentionally broken!\")\n",
    "\n",
    "# Wrap the function in a RunnableLambda to create a \"faulty\" model\n",
    "faulty_model = RunnableLambda(faulty_model_func)\n",
    "\n",
    "# Build a chain where the first model is the faulty one.\n",
    "# The chain will try faulty_model, fail, and then try primary_llm.\n",
    "chain_with_faulty_primary = (\n",
    "    prompt | faulty_model.with_fallbacks([primary_llm]) | output_parser\n",
    ")\n",
    "\n",
    "# Invoke the chain. We expect it to fail on the first try but succeed on the fallback.\n",
    "response = chain_with_faulty_primary.invoke({\"question\": question})\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response from fallback: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cb32f",
   "metadata": {},
   "source": [
    "## 4. Advanced Resilience: Implementing a Circuit Breaker\n",
    "\n",
    "Fallbacks are great for handling occasional, transient errors. But what if a service is completely down? Continuously retrying a failing service can waste resources and add load to an already struggling system.\n",
    "\n",
    "A **Circuit Breaker** is a design pattern that solves this problem. It works like an electrical circuit breaker:\n",
    "1.  **Closed State:** Requests flow normally. If a request fails, it increments a failure counter.\n",
    "2.  **Open State:** If the failure count exceeds a threshold within a certain time, the circuit \"opens.\" All subsequent requests are immediately rejected without even trying, preventing further load on the failing service.\n",
    "3.  **Half-Open State:** After a timeout period, the circuit moves to a \"half-open\" state. It allows a single request to pass through. If it succeeds, the circuit closes and returns to normal. If it fails, the circuit opens again.\n",
    "\n",
    "We will implement a simple, stateful circuit breaker using a Python class. This class will wrap our LCEL chain and manage the state (Closed, Open).\n",
    "\n",
    "### The `CircuitBreaker` Class\n",
    "Our implementation will include:\n",
    "-   `failure_threshold`: The number of failures before the circuit opens.\n",
    "-   `recovery_timeout`: The time in seconds before the circuit moves to half-open.\n",
    "-   `invoke()`: The main method that wraps the chain's `invoke` call, adding the circuit breaker logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd777eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, chain, failure_threshold=3, recovery_timeout=60):\n",
    "        self.chain = chain\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        self.failure_count = 0\n",
    "        self.state = \"CLOSED\"  # Can be CLOSED, OPEN, HALF_OPEN\n",
    "        self.last_failure_time = None\n",
    "\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        if self.state == \"OPEN\":\n",
    "            # If the recovery timeout has passed, move to HALF_OPEN\n",
    "            if (datetime.now() - self.last_failure_time) > timedelta(seconds=self.recovery_timeout):\n",
    "                self.state = \"HALF_OPEN\"\n",
    "            else:\n",
    "                # If still within the timeout, reject the call immediately\n",
    "                raise ConnectionError(\"Circuit is open. Please try again later.\")\n",
    "\n",
    "        try:\n",
    "            # In CLOSED or HALF_OPEN state, try the chain\n",
    "            result = self.chain.invoke(*args, **kwargs)\n",
    "            # If the call was successful, reset the circuit\n",
    "            self._reset()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # If the call fails, handle the failure\n",
    "            self._handle_failure()\n",
    "            # Re-raise the exception to the caller\n",
    "            raise e\n",
    "\n",
    "    def _handle_failure(self):\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = datetime.now()\n",
    "        \n",
    "        # If in HALF_OPEN, a single failure re-opens the circuit\n",
    "        if self.state == \"HALF_OPEN\":\n",
    "            self.state = \"OPEN\"\n",
    "            print(\"Circuit breaker failed in HALF_OPEN state. Re-opening circuit.\")\n",
    "        # If failure count exceeds threshold, open the circuit\n",
    "        elif self.failure_count >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "            print(f\"Circuit breaker opened due to {self.failure_count} failures.\")\n",
    "\n",
    "    def _reset(self):\n",
    "        # On success, reset the failure count and close the circuit\n",
    "        if self.state != \"CLOSED\":\n",
    "            print(\"Circuit breaker has been reset and is now CLOSED.\")\n",
    "        self.failure_count = 0\n",
    "        self.state = \"CLOSED\"\n",
    "        self.last_failure_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca3720",
   "metadata": {},
   "source": [
    "### Testing the Circuit Breaker\n",
    "\n",
    "Now, let's test our `CircuitBreaker` class. We'll wrap a chain that is designed to fail consistently.\n",
    "\n",
    "1.  **Create a chain that always fails:** We'll use our `faulty_model` again, but this time without any fallbacks.\n",
    "2.  **Wrap it with the `CircuitBreaker`:** We'll set a low `failure_threshold` (e.g., 2) and a short `recovery_timeout` (e.g., 5 seconds) for demonstration purposes.\n",
    "3.  **Simulate calls:** We'll call the circuit breaker in a loop.\n",
    "    -   The first two calls should fail, and the circuit will open.\n",
    "    -   The third call should be immediately rejected by the open circuit.\n",
    "    -   We'll wait for the recovery timeout to pass.\n",
    "    -   The next call will be in the \"half-open\" state. Since our model is still faulty, it will fail, and the circuit will re-open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A chain that is guaranteed to fail\n",
    "failing_chain = prompt | faulty_model | output_parser\n",
    "\n",
    "# Wrap the failing chain in our circuit breaker\n",
    "# Using a short timeout for demonstration\n",
    "breaker = CircuitBreaker(failing_chain, failure_threshold=2, recovery_timeout=5)\n",
    "\n",
    "# --- Simulation ---\n",
    "\n",
    "# 1. First two calls fail, tripping the breaker\n",
    "for i in range(breaker.failure_threshold):\n",
    "    try:\n",
    "        print(f\"Attempt {i+1}: Calling the chain...\")\n",
    "        breaker.invoke({\"question\": \"This will fail.\"})\n",
    "    except Exception as e:\n",
    "        print(f\"Attempt {i+1} failed as expected: {e.__class__.__name__}\")\n",
    "\n",
    "print(f\"\\nCircuit state is now: {breaker.state}\")\n",
    "\n",
    "# 2. The third call should be rejected immediately\n",
    "try:\n",
    "    print(\"\\nAttempt 3: Calling the chain while circuit is open...\")\n",
    "    breaker.invoke({\"question\": \"This should be blocked.\"})\n",
    "except Exception as e:\n",
    "    print(f\"Attempt 3 was correctly blocked: {e}\")\n",
    "\n",
    "# 3. Wait for the recovery timeout\n",
    "print(f\"\\nWaiting for {breaker.recovery_timeout} seconds for recovery...\")\n",
    "time.sleep(breaker.recovery_timeout)\n",
    "\n",
    "# 4. The fourth call is in the HALF_OPEN state. It will fail and re-open the circuit.\n",
    "try:\n",
    "    print(\"\\nAttempt 4: Calling in HALF_OPEN state...\")\n",
    "    breaker.invoke({\"question\": \"This will fail again.\"})\n",
    "except Exception as e:\n",
    "    print(f\"Attempt 4 failed as expected: {e.__class__.__name__}\")\n",
    "\n",
    "print(f\"\\nFinal circuit state: {breaker.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# --- Step 1: Define Individual Components ---\n",
    "\n",
    "# Simulate a retrieval function that might fail\n",
    "def fetch_retrieval(context_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates fetching a document from a vector store.\n",
    "    Set to fail for this demonstration.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to retrieve document for: {context_key}\")\n",
    "    # Simulate failure\n",
    "    raise ConnectionError(\"Retrieval failed: Vector DB is offline.\")\n",
    "    # In a success case, it would return:\n",
    "    # return \"SOP-455 states that vibration above 5mm/s requires immediate shutdown and inspection.\"\n",
    "\n",
    "# A fallback function that provides a cached or default response\n",
    "def fallback_cache(inputs: dict) -> str:\n",
    "    \"\"\"\n",
    "    Provides a safe, cached response when the primary retrieval fails.\n",
    "    \"\"\"\n",
    "    print(\"--- Primary retrieval failed. Using fallback cache. ---\")\n",
    "    issue = inputs.get(\"issue\", \"the reported issue\")\n",
    "    return f\"Cached Guidance: For {issue}, consult the general troubleshooting manual (GTM-001) and notify the shift supervisor.\"\n",
    "\n",
    "# --- Step 2: Build the Runnable Sequence using LCEL ---\n",
    "\n",
    "# The main prompt for the LLM\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Context: {context}\\n\\nIssue: {issue}\\n\\nAnswer succinctly with SOP citations if available.\"\n",
    ")\n",
    "\n",
    "# The LLM to use for generation\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# Define the primary generation chain\n",
    "generation_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Define the retrieval chain with a fallback\n",
    "# .with_fallbacks() creates a resilient chain that tries the primary runnable first\n",
    "# and executes the fallback if the primary one fails.\n",
    "retrieval_with_fallback = RunnableLambda(fetch_retrieval).with_fallbacks(\n",
    "    fallbacks=[RunnableLambda(fallback_cache)]\n",
    ")\n",
    "\n",
    "# --- Step 3: Compose the final workflow ---\n",
    "\n",
    "# The final workflow uses a RunnableParallel to structure the input for the generation_chain.\n",
    "# It runs the retrieval_with_fallback and passes the 'issue' straight through.\n",
    "workflow = (\n",
    "    RunnableParallel(\n",
    "        context=retrieval_with_fallback,\n",
    "        issue=lambda inputs: inputs[\"issue\"]\n",
    "    )\n",
    "    | generation_chain\n",
    ")\n",
    "\n",
    "\n",
    "# --- Step 4: Execute and Monitor ---\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "# The input dictionary for the workflow\n",
    "run_input = {\n",
    "    \"context_key\": \"vibration_alarm_press_12\",\n",
    "    \"issue\": \"High vibration alarm on Press 12\"\n",
    "}\n",
    "\n",
    "# Invoke the workflow\n",
    "final_answer = workflow.invoke(run_input)\n",
    "\n",
    "latency_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(final_answer)\n",
    "print(f'\\nLatency: {latency_ms:.1f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc542",
   "metadata": {},
   "source": [
    "### âš ï¸ Circuit Breaker Pattern\n",
    "Track failure counts; if > 3 within 10 minutes, disable automated responses and notify SMEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234fcd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"\n",
    "    A simple circuit breaker implementation to prevent repeated failures.\n",
    "    \"\"\"\n",
    "    def __init__(self, failure_threshold: int, recovery_timeout_seconds: int):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = timedelta(seconds=recovery_timeout_seconds)\n",
    "        self.failures = []\n",
    "        self.is_open = False\n",
    "        self.last_opened_time = None\n",
    "\n",
    "    def record_failure(self):\n",
    "        \"\"\"Records a failure and opens the circuit if the threshold is met.\"\"\"\n",
    "        now = datetime.now()\n",
    "        self.failures.append(now)\n",
    "        \n",
    "        # Remove old failures\n",
    "        self.failures = [t for t in self.failures if now - t < self.recovery_timeout]\n",
    "        \n",
    "        if len(self.failures) >= self.failure_threshold:\n",
    "            self.is_open = True\n",
    "            self.last_opened_time = now\n",
    "            print(f\"CIRCUIT BREAKER OPENED at {now}. Further calls will be blocked.\")\n",
    "\n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Checks if the circuit is closed or if the recovery timeout has passed.\"\"\"\n",
    "        if not self.is_open:\n",
    "            return True\n",
    "        \n",
    "        if datetime.now() - self.last_opened_time > self.recovery_timeout:\n",
    "            self.reset()\n",
    "            print(\"CIRCUIT BREAKER RESET. Calls are now permitted.\")\n",
    "            return True\n",
    "            \n",
    "        print(\"Circuit breaker is open. Call is blocked.\")\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the circuit breaker to a closed state.\"\"\"\n",
    "        self.is_open = False\n",
    "        self.failures = []\n",
    "        self.last_opened_time = None\n",
    "\n",
    "# --- Example Usage ---\n",
    "breaker = CircuitBreaker(failure_threshold=3, recovery_timeout_seconds=60)\n",
    "\n",
    "for i in range(5):\n",
    "    if breaker.can_execute():\n",
    "        print(f\"Attempt {i+1}: Executing the operation...\")\n",
    "        # Simulate a failure\n",
    "        breaker.record_failure()\n",
    "        time.sleep(1) # Simulate time between calls\n",
    "    else:\n",
    "        print(f\"Attempt {i+1}: Operation blocked by circuit breaker.\")\n",
    "        # In a real app, you would wait or redirect here\n",
    "        time.sleep(10)\n",
    "\n",
    "# Check if it resets after timeout (manual check for demo)\n",
    "print(\"\\n--- Waiting for recovery timeout ---\")\n",
    "# time.sleep(61) \n",
    "# if breaker.can_execute():\n",
    "#     print(\"System recovered and is operational again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fac468",
   "metadata": {},
   "source": [
    "## ðŸ§ª Lab Assignment\n",
    "1. Add a parallel branch that translates outputs into Spanish using `RunnableParallel`.\n",
    "2. Extend the fallback to fetch last known guidance from Redis when retrieval fails.\n",
    "3. Log per-node latency and completion status to Prometheus.\n",
    "4. Demo circuit breaker resetting after manual override by SME."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d67b6",
   "metadata": {},
   "source": [
    "## âœ… Checklist\n",
    "- [ ] Runnable sequence deployed\n",
    "- [ ] Failure handling strategy documented\n",
    "- [ ] Latency metrics instrumented\n",
    "- [ ] Lab deliverables verified with ops team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5f6ce",
   "metadata": {},
   "source": [
    "## ðŸ“š References\n",
    "- LangChain Runnables Guide\n",
    "- Site Reliability Engineering: Circuit Breakers\n",
    "- Week 09-10 Monitoring Notebook"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
