{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86130fb8",
   "metadata": {},
   "source": [
    "# üîå Week 07-08 ¬∑ Notebook 16 ¬∑ Model Context Protocol (MCP)\n",
    "\n",
    "Learn Anthropic's MCP standard for connecting LLMs to external tools and data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f03ff2",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Understand what MCP is and why it matters for Gen AI applications\n",
    "- Build a simple MCP server for manufacturing sensor data\n",
    "- Connect an MCP server to an LLM client\n",
    "- Compare MCP with traditional function calling and LangChain tools\n",
    "- Implement MCP in a production manufacturing context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89134d9",
   "metadata": {},
   "source": [
    "## üß© What is Model Context Protocol (MCP)?\n",
    "\n",
    "**Model Context Protocol (MCP)** is an open standard created by Anthropic that defines how AI applications should communicate with external data sources and tools. Think of it as a **universal adapter** that allows LLMs to safely and efficiently access real-world data.\n",
    "\n",
    "### Why MCP Matters\n",
    "\n",
    "Before MCP, every tool integration was custom-built:\n",
    "- ‚ùå Each application had its own way of connecting to databases\n",
    "- ‚ùå No standard for how tools should expose their capabilities\n",
    "- ‚ùå Security and permission management was ad-hoc\n",
    "- ‚ùå Difficult to reuse tool integrations across different AI systems\n",
    "\n",
    "With MCP:\n",
    "- ‚úÖ **Standardized**: One protocol for all tool integrations\n",
    "- ‚úÖ **Secure**: Built-in permission and authentication model\n",
    "- ‚úÖ **Reusable**: Write once, use in any MCP-compatible application\n",
    "- ‚úÖ **Composable**: Combine multiple MCP servers seamlessly\n",
    "\n",
    "### MCP Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   LLM Client    ‚îÇ (Claude, GPT, or any MCP-compatible client)\n",
    "‚îÇ  (Your App)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ MCP Protocol (JSON-RPC over stdio/HTTP)\n",
    "         ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   MCP Server    ‚îÇ (Exposes tools, resources, prompts)\n",
    "‚îÇ  (Python/Node)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Data Sources   ‚îÇ (Databases, APIs, Files, Sensors)\n",
    "‚îÇ  & Tools        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### MCP vs. LangChain Tools\n",
    "\n",
    "| Feature | MCP | LangChain Tools |\n",
    "|---------|-----|----------------|\n",
    "| **Standardization** | Open protocol | Framework-specific |\n",
    "| **Reusability** | Works across any MCP client | LangChain only |\n",
    "| **Security** | Built-in permission model | Manual implementation |\n",
    "| **Language** | Language-agnostic | Python (primarily) |\n",
    "| **Use Case** | Universal tool integration | Rapid prototyping |\n",
    "\n",
    "**Bottom Line**: MCP is better for production systems, LangChain tools are faster for prototyping. **You can use both together!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0bfcb",
   "metadata": {},
   "source": [
    "## üì¶ Installation\n",
    "\n",
    "Let's install the MCP Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mcp anthropic httpx -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7bb5ac",
   "metadata": {},
   "source": [
    "## üè≠ Use Case: Manufacturing Sensor MCP Server\n",
    "\n",
    "We'll build an MCP server that exposes manufacturing sensor data to LLMs. This server will provide:\n",
    "1. **Tools**: Functions to read sensor data, check equipment status\n",
    "2. **Resources**: Access to historical sensor logs\n",
    "3. **Prompts**: Pre-configured prompts for common diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc85c16",
   "metadata": {},
   "source": [
    "## üîß Step 1: Create a Simple MCP Server\n",
    "\n",
    "First, let's create a basic MCP server that exposes sensor reading functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this to: mcp_sensor_server.py\n",
    "# (In a real deployment, this would be a separate file)\n",
    "\n",
    "from mcp.server import Server\n",
    "from mcp.types import Tool, TextContent, ImageContent\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create MCP server instance\n",
    "server = Server(\"manufacturing-sensor-server\")\n",
    "\n",
    "# Simulated sensor database\n",
    "SENSORS_DB = {\n",
    "    \"CNC-A-102\": {\"type\": \"CNC Mill\", \"location\": \"Assembly Line A\"},\n",
    "    \"PUMP-B-05\": {\"type\": \"Hydraulic Pump\", \"location\": \"Cooling System B\"},\n",
    "    \"PRESS-C-12\": {\"type\": \"Stamping Press\", \"location\": \"Stamping Line C\"},\n",
    "}\n",
    "\n",
    "# Define MCP tool for reading sensor data\n",
    "@server.tool()\n",
    "async def read_sensor_data(equipment_id: str) -> dict:\n",
    "    \"\"\"Read current sensor data for a specific piece of equipment.\n",
    "    \n",
    "    Args:\n",
    "        equipment_id: The unique identifier for the equipment (e.g., 'CNC-A-102')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing sensor readings (temperature, vibration, pressure)\n",
    "    \"\"\"\n",
    "    if equipment_id not in SENSORS_DB:\n",
    "        return {\"error\": f\"Equipment {equipment_id} not found\"}\n",
    "    \n",
    "    # Simulate sensor readings\n",
    "    return {\n",
    "        \"equipment_id\": equipment_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"temperature_c\": round(random.uniform(60.0, 95.0), 2),\n",
    "        \"vibration_mm_s\": round(random.uniform(5.0, 15.0), 2),\n",
    "        \"pressure_bar\": round(random.uniform(2.0, 5.0), 2),\n",
    "        \"status\": \"normal\" if random.random() > 0.1 else \"warning\"\n",
    "    }\n",
    "\n",
    "@server.tool()\n",
    "async def list_equipment() -> list:\n",
    "    \"\"\"List all monitored equipment in the facility.\n",
    "    \n",
    "    Returns:\n",
    "        List of equipment with their details\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\"id\": eq_id, **details}\n",
    "        for eq_id, details in SENSORS_DB.items()\n",
    "    ]\n",
    "\n",
    "@server.tool()\n",
    "async def check_anomalies(equipment_id: str, threshold_vibration: float = 12.0) -> dict:\n",
    "    \"\"\"Check if equipment has anomalous sensor readings.\n",
    "    \n",
    "    Args:\n",
    "        equipment_id: Equipment to check\n",
    "        threshold_vibration: Vibration threshold in mm/s (default: 12.0)\n",
    "    \n",
    "    Returns:\n",
    "        Analysis of whether readings are anomalous\n",
    "    \"\"\"\n",
    "    data = await read_sensor_data(equipment_id)\n",
    "    \n",
    "    if \"error\" in data:\n",
    "        return data\n",
    "    \n",
    "    anomalies = []\n",
    "    if data[\"vibration_mm_s\"] > threshold_vibration:\n",
    "        anomalies.append(f\"High vibration: {data['vibration_mm_s']} mm/s (threshold: {threshold_vibration})\")\n",
    "    if data[\"temperature_c\"] > 90:\n",
    "        anomalies.append(f\"High temperature: {data['temperature_c']}¬∞C\")\n",
    "    \n",
    "    return {\n",
    "        \"equipment_id\": equipment_id,\n",
    "        \"has_anomalies\": len(anomalies) > 0,\n",
    "        \"anomalies\": anomalies,\n",
    "        \"readings\": data\n",
    "    }\n",
    "\n",
    "# Define MCP resource (read-only data)\n",
    "@server.resource(\"sensor://historical/{equipment_id}\")\n",
    "async def get_historical_data(equipment_id: str) -> str:\n",
    "    \"\"\"Get historical sensor data for an equipment.\"\"\"\n",
    "    # In production, this would query a time-series database\n",
    "    return f\"Historical data for {equipment_id}:\\n\" + json.dumps({\n",
    "        \"last_24h_avg_temp\": 78.5,\n",
    "        \"last_24h_avg_vibration\": 8.2,\n",
    "        \"incident_count\": 0\n",
    "    }, indent=2)\n",
    "\n",
    "# Define MCP prompt template\n",
    "@server.prompt()\n",
    "async def diagnose_equipment_prompt(equipment_id: str) -> str:\n",
    "    \"\"\"Generate a diagnostic prompt for equipment issues.\"\"\"\n",
    "    data = await read_sensor_data(equipment_id)\n",
    "    return f\"\"\"Analyze the following sensor data for {equipment_id}:\n",
    "\n",
    "{json.dumps(data, indent=2)}\n",
    "\n",
    "Provide:\n",
    "1. Assessment of equipment health\n",
    "2. Potential issues or concerns\n",
    "3. Recommended actions\n",
    "4. Urgency level (low/medium/high)\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ MCP Sensor Server defined successfully\")\n",
    "print(f\"Available tools: read_sensor_data, list_equipment, check_anomalies\")\n",
    "print(f\"Available resources: sensor://historical/{{equipment_id}}\")\n",
    "print(f\"Available prompts: diagnose_equipment_prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d34445",
   "metadata": {},
   "source": [
    "## üîó Step 2: Connect to the MCP Server\n",
    "\n",
    "Now let's create a client that connects to our MCP server and uses its tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.client import Client\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "\n",
    "# Initialize Anthropic client\n",
    "anthropic_client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# Initialize MCP client\n",
    "async def use_mcp_server():\n",
    "    \"\"\"Example of using MCP server with Claude.\"\"\"\n",
    "    \n",
    "    async with Client() as mcp_client:\n",
    "        # Connect to our sensor server\n",
    "        await mcp_client.connect_stdio(\"python\", [\"mcp_sensor_server.py\"])\n",
    "        \n",
    "        # List available tools\n",
    "        tools = await mcp_client.list_tools()\n",
    "        print(\"üìã Available MCP Tools:\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "        \n",
    "        # Use Claude with MCP tools\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Check the sensor data for equipment CNC-A-102 and tell me if there are any issues.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Claude will automatically call MCP tools as needed\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=1024,\n",
    "            tools=[tool.to_params() for tool in tools],\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        print(\"\\nü§ñ Claude's Response:\")\n",
    "        print(response.content[0].text)\n",
    "\n",
    "# Run the example (uncomment when you have ANTHROPIC_API_KEY)\n",
    "# await use_mcp_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df74e65",
   "metadata": {},
   "source": [
    "## üîÑ Step 3: MCP with LangChain Integration\n",
    "\n",
    "You can also use MCP servers with LangChain for the best of both worlds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef67ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Wrap MCP tools as LangChain tools\n",
    "def wrap_mcp_tool_for_langchain(mcp_tool):\n",
    "    \"\"\"Convert an MCP tool to a LangChain tool.\"\"\"\n",
    "    async def tool_func(**kwargs):\n",
    "        return await mcp_tool(**kwargs)\n",
    "    \n",
    "    return StructuredTool.from_function(\n",
    "        func=tool_func,\n",
    "        name=mcp_tool.__name__,\n",
    "        description=mcp_tool.__doc__,\n",
    "        coroutine=tool_func\n",
    "    )\n",
    "\n",
    "# Create LangChain-compatible tools from our MCP server\n",
    "langchain_tools = [\n",
    "    wrap_mcp_tool_for_langchain(read_sensor_data),\n",
    "    wrap_mcp_tool_for_langchain(list_equipment),\n",
    "    wrap_mcp_tool_for_langchain(check_anomalies),\n",
    "]\n",
    "\n",
    "# Create LangChain agent with MCP-backed tools\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a manufacturing diagnostic assistant. Use the available tools to check equipment status.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, langchain_tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=langchain_tools, verbose=True)\n",
    "\n",
    "# Use the agent\n",
    "# result = agent_executor.invoke({\n",
    "#     \"input\": \"List all equipment and check for any anomalies\"\n",
    "# })\n",
    "# print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ab37f",
   "metadata": {},
   "source": [
    "## üè≠ Production Deployment Pattern\n",
    "\n",
    "In production, you would deploy MCP servers as separate services:\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "services:\n",
    "  mcp-sensor-server:\n",
    "    build: ./mcp-servers/sensor\n",
    "    environment:\n",
    "      - DATABASE_URL=postgresql://...\n",
    "    ports:\n",
    "      - \"8001:8001\"\n",
    "  \n",
    "  mcp-maintenance-server:\n",
    "    build: ./mcp-servers/maintenance\n",
    "    environment:\n",
    "      - DATABASE_URL=postgresql://...\n",
    "    ports:\n",
    "      - \"8002:8002\"\n",
    "  \n",
    "  ai-app:\n",
    "    build: ./app\n",
    "    environment:\n",
    "      - MCP_SENSOR_URL=http://mcp-sensor-server:8001\n",
    "      - MCP_MAINTENANCE_URL=http://mcp-maintenance-server:8002\n",
    "    depends_on:\n",
    "      - mcp-sensor-server\n",
    "      - mcp-maintenance-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f0152",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **MCP is a standard protocol** for connecting LLMs to external tools and data\n",
    "2. **Better for production** than ad-hoc integrations due to standardization and security\n",
    "3. **Can be used with LangChain** for maximum flexibility\n",
    "4. **Three main components**: Tools (functions), Resources (data), Prompts (templates)\n",
    "5. **Reusable**: One MCP server can serve multiple AI applications\n",
    "\n",
    "### When to Use MCP vs. LangChain Tools:\n",
    "\n",
    "**Use MCP when**:\n",
    "- Building production systems\n",
    "- Need to share tools across multiple applications\n",
    "- Require strong security and permissions\n",
    "- Working in a multi-language environment\n",
    "\n",
    "**Use LangChain Tools when**:\n",
    "- Rapid prototyping\n",
    "- Staying within LangChain ecosystem\n",
    "- Building Python-only applications\n",
    "- Need quick iteration\n",
    "\n",
    "**Best Practice**: Start with LangChain tools for prototyping, migrate to MCP for production! ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0232f",
   "metadata": {},
   "source": [
    "## üîó Additional Resources\n",
    "\n",
    "- [MCP Official Documentation](https://modelcontextprotocol.io/)\n",
    "- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\n",
    "- [Anthropic MCP Guide](https://docs.anthropic.com/claude/docs/model-context-protocol)\n",
    "- [MCP Server Examples](https://github.com/modelcontextprotocol/servers)\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: Continue to `14_agent_state_management.ipynb` to learn about managing complex agent workflows! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
