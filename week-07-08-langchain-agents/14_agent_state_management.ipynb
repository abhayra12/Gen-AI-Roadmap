{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df29f50",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è Week 07-08 ¬∑ Notebook 14 ¬∑ Agent State Management & Persistence\n",
    "\n",
    "Persist agent memory and checkpoints to support multi-shift handoffs and compliance reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8fd2e",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Implement memory modules (conversation buffer, vectorstore-backed memory).\n",
    "- Persist agent state to Redis / PostgreSQL for cross-shift continuity.\n",
    "- Manage checkpointing and rollback strategies.\n",
    "- Enforce retention policies to comply with IT and legal standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a1d9c",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "Night shift escalates a complex issue. Morning shift must resume with full context while ensuring sensitive data is retained only for 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# --- 1. Basic Conversation Buffer Memory ---\n",
    "# This memory keeps a simple list of the conversation turns.\n",
    "\n",
    "# Initialize memory to store the conversation\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Initialize the LLM and the conversation chain\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "\n",
    "# --- Simulate a conversation during a shift ---\n",
    "print(\"--- Shift 1 Conversation ---\")\n",
    "chain.predict(input='Technician on duty. We just replaced the spindle bearings on Press-14, but vibration is still high.')\n",
    "chain.predict(input='What was the root cause the last time this happened, around 6 months ago?')\n",
    "\n",
    "# --- 2. Inspect the Memory ---\n",
    "# At the end of the shift, we can see what's stored in memory.\n",
    "print(\"\\n--- Memory State at End of Shift 1 ---\")\n",
    "memory_state = memory.load_memory_variables({})\n",
    "for message in memory_state['chat_history']:\n",
    "    print(f\"[{message.__class__.__name__}]: {message.content}\")\n",
    "\n",
    "# --- 3. Simulating a Shift Handoff ---\n",
    "# To hand off, we could serialize the memory content. For this demo, we'll just create a new chain\n",
    "# and manually load the previous conversation history.\n",
    "\n",
    "# New shift, new chain, but with the *same memory object*\n",
    "print(\"\\n--- Shift 2 Begins ---\")\n",
    "chain_shift2 = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "\n",
    "# The new technician can now ask questions with full context.\n",
    "chain_shift2.predict(input=\"This is the morning shift taking over. Based on the previous conversation, what's the next logical troubleshooting step?\")\n",
    "\n",
    "print(\"\\n--- Final Memory State ---\")\n",
    "final_memory_state = memory.load_memory_variables({})\n",
    "for message in final_memory_state['chat_history']:\n",
    "    print(f\"[{message.__class__.__name__}]: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04854b1",
   "metadata": {},
   "source": [
    "### üß† Vectorstore-Backed Memory\n",
    "Use embeddings to recall similar incidents across shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4031c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- VectorStore-Backed Memory for Long-Term Recall ---\n",
    "# This type of memory stores conversation snippets in a vector store, allowing the agent\n",
    "# to recall semantically similar past events, even from different shifts or years ago.\n",
    "\n",
    "# 1. Setup the Vector Store and Embedding function\n",
    "embedding = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Using a persistent directory for the vector store\n",
    "vectorstore = Chroma(\n",
    "    collection_name='long_term_agent_memory', \n",
    "    embedding_function=embedding,\n",
    "    persist_directory='./agent_memory_db'\n",
    ")\n",
    "\n",
    "# 2. Create the RetrieverMemory\n",
    "# This connects the vector store to the memory interface.\n",
    "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
    "retriever_memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# 3. Save context from past incidents (simulating historical data)\n",
    "# This would happen continuously as the agent operates.\n",
    "retriever_memory.save_context(\n",
    "    {'input': 'Press 14 had a bearing failure due to improper lubrication.'}, \n",
    "    {'output': 'Resolved by changing lubricant and updating SOP-122.'}\n",
    ")\n",
    "retriever_memory.save_context(\n",
    "    {'input': 'CNC-08 showed high vibration after a software update.'},\n",
    "    {'output': 'Resolved by rolling back the update and recalibrating the tool head.'}\n",
    ")\n",
    "retriever_memory.save_context(\n",
    "    {'input': 'Press 14 had another vibration issue, this time caused by a loose mounting bolt.'},\n",
    "    {'output': 'Resolved by tightening bolts to spec.'}\n",
    ")\n",
    "\n",
    "# 4. Use the memory to recall relevant context for a new problem\n",
    "new_incident_query = 'Press 14 is vibrating again after we did some maintenance.'\n",
    "relevant_history = retriever_memory.load_memory_variables({'input': new_incident_query})\n",
    "\n",
    "print(f\"--- New Incident ---\")\n",
    "print(f\"Query: '{new_incident_query}'\")\n",
    "print(\"\\n--- Relevant Historical Context Recalled from Vector Memory ---\")\n",
    "# The 'history' key contains the most relevant past conversation snippet.\n",
    "print(relevant_history.get('history'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9deef7b",
   "metadata": {},
   "source": [
    "## üßæ Retention Policy\n",
    "- Conversation buffers retained 30 days (auto-purge).\n",
    "- Vectorstore entries tagged with `retire_after` timestamp.\n",
    "- Manual purge process documented for legal holds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd329176",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Add Redis backend for memory persistence and simulate restart recovery.\n",
    "2. Implement checkpoint snapshots saved to Cloud Storage with checksum.\n",
    "3. Design retention job that purges expired entries daily and logs results.\n",
    "4. Present memory architecture to IT for approval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b19d3",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Memory modules implemented\n",
    "- [ ] Persistence layer configured\n",
    "- [ ] Retention policy documented\n",
    "- [ ] Lab deliverables reviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e18f0",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- LangChain Memory Guide\n",
    "- Corporate Data Retention Policy\n",
    "- Redis Persistence Best Practices"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
