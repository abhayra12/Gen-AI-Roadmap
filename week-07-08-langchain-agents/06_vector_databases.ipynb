{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906c9224",
   "metadata": {},
   "source": [
    "# üóÉÔ∏è Week 07-08 ¬∑ Notebook 06 ¬∑ Vector Database Benchmarking\n",
    "\n",
    "Compare Chroma, FAISS, and pgvector for storing manufacturing knowledge and supporting plant SLAs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb694bb2",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Ingest identical document sets into Chroma, FAISS, and pgvector.\n",
    "- Benchmark latency, recall, storage cost, and operational complexity.\n",
    "- Track evaluation runs in MLflow for future audits.\n",
    "- Produce a recommendation matrix for plant deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2cb016",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "Pune and Monterrey plants debate hosting the retrieval store on-prem (FAISS) vs. managed (pgvector/CloudSQL). Leadership requires data to justify decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import mlflow\n",
    "\n",
    "# --- Setup ---\n",
    "# Use a real-world-like set of documents for benchmarking\n",
    "docs = [\n",
    "    Document(page_content=f'Standard Operating Procedure for CNC Machine {i+1}: Regular maintenance includes checking coolant levels and ensuring safety guards are in place. Spindle calibration is required every 200 hours.', metadata={'doc_id': f'SOP-CNC-{i+1}'}) for i in range(100)\n",
    "] + [\n",
    "    Document(page_content=f'Maintenance Log {i+1}: Technician [REDACTED] reported unusual noise from Press Machine {i+1}. Root cause was a loose bolt, which was tightened.', metadata={'doc_id': f'LOG-PRESS-{i+1}'}) for i in range(100)\n",
    "]\n",
    "\n",
    "# Use a standard, lightweight embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# --- Benchmarking Function ---\n",
    "def benchmark(store_cls, name: str, docs: list, embedding_function):\n",
    "    \"\"\"\n",
    "    Benchmarks a vector store for ingestion time and query latency.\n",
    "    \"\"\"\n",
    "    print(f\"--- Benchmarking {name} ---\")\n",
    "    \n",
    "    # 1. Ingestion Time\n",
    "    start_ingest = time.perf_counter()\n",
    "    if name == 'Chroma':\n",
    "        # Chroma can be ephemeral or persistent\n",
    "        vector_store = store_cls.from_documents(docs, embedding_function, persist_directory=f\"./chroma_db_{name}\")\n",
    "    else: # FAISS\n",
    "        vector_store = store_cls.from_documents(docs, embedding_function)\n",
    "    ingest_time_ms = (time.perf_counter() - start_ingest) * 1000\n",
    "    print(f\"Ingestion Time: {ingest_time_ms:.2f} ms\")\n",
    "\n",
    "    # 2. Query Latency\n",
    "    query = \"What is the procedure for spindle calibration?\"\n",
    "    latencies = []\n",
    "    for _ in range(10): # Run multiple queries to get an average\n",
    "        start_query = time.perf_counter()\n",
    "        vector_store.similarity_search(query, k=4)\n",
    "        query_time_ms = (time.perf_counter() - start_query) * 1000\n",
    "        latencies.append(query_time_ms)\n",
    "    \n",
    "    avg_latency_ms = np.mean(latencies)\n",
    "    p95_latency_ms = np.percentile(latencies, 95)\n",
    "    print(f\"Average Query Latency: {avg_latency_ms:.2f} ms\")\n",
    "    print(f\"P95 Query Latency: {p95_latency_ms:.2f} ms\\n\")\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    with mlflow.start_run(run_name=f\"VectorStore_Benchmark_{name}\"):\n",
    "        mlflow.log_param(\"vector_store\", name)\n",
    "        mlflow.log_metric(\"ingestion_time_ms\", ingest_time_ms)\n",
    "        mlflow.log_metric(\"avg_query_latency_ms\", avg_latency_ms)\n",
    "        mlflow.log_metric(\"p95_query_latency_ms\", p95_latency_ms)\n",
    "        mlflow.log_param(\"num_documents\", len(docs))\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"ingestion_time_ms\": ingest_time_ms,\n",
    "        \"avg_query_latency_ms\": avg_latency_ms,\n",
    "        \"p95_query_latency_ms\": p95_latency_ms\n",
    "    }\n",
    "\n",
    "# --- Run Benchmarks ---\n",
    "# List of vector stores to benchmark\n",
    "vector_stores_to_benchmark = [\n",
    "    {\"class\": Chroma, \"name\": \"Chroma\"},\n",
    "    {\"class\": FAISS, \"name\": \"FAISS\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for store_info in vector_stores_to_benchmark:\n",
    "    result = benchmark(store_info[\"class\"], store_info[\"name\"], docs, embeddings)\n",
    "    results.append(result)\n",
    "\n",
    "print(\"--- Benchmark Summary ---\")\n",
    "for res in results:\n",
    "    print(f\"{res['name']}: Ingestion={res['ingestion_time_ms']:.2f}ms, Avg Query={res['avg_query_latency_ms']:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004eb0e1",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è pgvector benchmarking requires a running Postgres instance with the extension enabled. Refer to `infrastructure/pgvector_setup.sql`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd060a",
   "metadata": {},
   "source": [
    "## üìä Evaluation Matrix\n",
    "| Criterion | Chroma | FAISS | pgvector |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e29fb5",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Run pgvector benchmark using CloudSQL dev instance and capture metrics.\n",
    "2. Evaluate recall by scoring against labeled maintenance Q&A set.\n",
    "3. Log benchmarks to MLflow (`mlflow.log_metrics` & `mlflow.log_dict`).\n",
    "4. Draft recommendation memo for CIO summarizing trade-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409ecc7",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Benchmarks executed for all stores\n",
    "- [ ] Metrics logged\n",
    "- [ ] Recommendation memo drafted\n",
    "- [ ] Governance evidence archived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef273a8",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- LangChain Vectorstore Docs\n",
    "- pgvector Extension Guide\n",
    "- Week 05 Data Storage Policy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
