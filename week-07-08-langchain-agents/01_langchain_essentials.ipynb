{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a19c1d2",
   "metadata": {},
   "source": [
    "# ðŸ§  Week 07-08 Â· Notebook 01 Â· LangChain Essentials for Manufacturing Copilots\n",
    "\n",
    "Lay the foundation for building LangChain pipelines that power maintenance, quality, and EHS assistants across Arvind Manufacturing's plants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863441f",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "- Understand LangChain core abstractions (prompt, LLM, chains, tools).\n",
    "- Connect LangChain to the synthetic manufacturing corpus prepared in Weeks 05-06.\n",
    "- Prototype a maintenance triage chain with lineage logging for audits.\n",
    "- Document lifecycle checkpoints that align with corporate governance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c45ce6",
   "metadata": {},
   "source": [
    "## ðŸ§© Scenario\n",
    "The Pune plant wants a first-class troubleshooting assistant exposing SOP summaries and IoT alerts. LangChain needs to be evaluated for rapid prototyping while meeting ISO 9001 change control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253995e",
   "metadata": {},
   "source": [
    "## ðŸ§± LangChain Building Blocks\n",
    "| Component | Manufacturing Use Case | Notes |\n",
    "| --- | --- | --- |\n",
    "| `PromptTemplate` | Standardize safety disclaimers | Tag with revision IDs |\n",
    "| `ChatOpenAI` | Generate bilingual responses | Enforce completion tokens ceiling |\n",
    "| `LLMChain` | Maintenance triage | Log run metadata to MLflow |\n",
    "| `Tool` | Spare part lookup, downtime analytics | Wrap plant REST APIs |\n",
    "| `Memory` | Persist shift conversation | Store in Redis with TTL = 24h |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14293fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal LangChain pipeline using synthetic maintenance data\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Ensure the SOP directory and file exist\n",
    "SOP_DIR = Path('data/sop_manuals')\n",
    "SOP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SOP_PATH = SOP_DIR / 'punch_press_v7.txt'\n",
    "if not SOP_PATH.exists():\n",
    "    SOP_PATH.write_text(\"\"\"\n",
    "Standard Operating Procedure: Punch Press v7\n",
    "\n",
    "Safety First: Always wear safety glasses and gloves. Ensure machine is locked out before maintenance.\n",
    "\n",
    "Lubrication Schedule:\n",
    "- Daily: Check hydraulic fluid levels.\n",
    "- Weekly: Lubricate punch press bearings with Grade 2 lithium grease.\n",
    "- Monthly: Inspect and lubricate all moving parts.\n",
    "\"\"\", encoding='utf-8')\n",
    "\n",
    "sample_context = SOP_PATH.read_text(encoding='utf-8')[:800]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful Manufacturing Copilot that references SOPs for maintenance guidance.\"),\n",
    "    (\"human\", \"Context: {context}\n",
    "\n",
    "Question: {question}\")\n",
    "])\n",
    "\n",
    "# Using LangChain Expression Language (LCEL)\n",
    "chain = prompt | ChatOpenAI(model='gpt-4o-mini', temperature=0.2) | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"context\": sample_context,\n",
    "    \"question\": \"How often should I lubricate the punch press bearings?\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3568da7",
   "metadata": {},
   "source": [
    "### ðŸ”’ Governance Inline\n",
    "- Record prompt, input, and output hashes for audit trail.\n",
    "- Tag runs with plant, shift, and technician supervisor ID.\n",
    "- Enforce translation to Spanish when `technician_language = es`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# --- Governance and Logging Wrapper ---\n",
    "def execute_and_log_chain(chain, inputs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute the chain\n",
    "    response = chain.invoke(inputs)\n",
    "    \n",
    "    latency_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # Create governance record\n",
    "    run_evidence = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"plant_id\": \"PUNE-01\",\n",
    "        \"shift\": \"morning\",\n",
    "        \"supervisor_id\": \"SUP-4872\",\n",
    "        \"prompt_hash\": sha256(str(chain.get_prompts()).encode()).hexdigest()[:12],\n",
    "        \"input_hash\": sha256(inputs['context'].encode()).hexdigest()[:12],\n",
    "        \"output_hash\": sha256(response.encode()).hexdigest()[:12],\n",
    "        \"model\": chain.middle[0].model_name,\n",
    "        \"latency_ms\": round(latency_ms, 2)\n",
    "    }\n",
    "    \n",
    "    # Append log to a file\n",
    "    log_dir = Path('governance')\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    with open(log_dir / 'langchain_run_log.jsonl', 'a') as f:\n",
    "        f.write(json.dumps(run_evidence) + '\\n')\n",
    "        \n",
    "    return response, run_evidence\n",
    "\n",
    "# --- Execute with Logging ---\n",
    "inputs = {\n",
    "    \"context\": sample_context,\n",
    "    \"question\": \"How often should I lubricate the punch press bearings?\"\n",
    "}\n",
    "final_response, evidence = execute_and_log_chain(chain, inputs)\n",
    "\n",
    "print(\"--- Chain Response ---\")\n",
    "print(final_response)\n",
    "print(\"\\n--- Governance Log ---\")\n",
    "print(json.dumps(evidence, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31dce35",
   "metadata": {},
   "source": [
    "## ðŸ§ª Lab Assignment\n",
    "1. **Access Real SOP Data**: Create a function that loads `data/sop_manuals/punch_press_v7.txt` or creates the directory and file with sample content if it doesn't exist. Use Path from pathlib for platform-independent paths.\n",
    "\n",
    "2. **Implement Bilingual Support**: Extend the chain to detect language preference and translate responses when `technician_language = \"es\"`. Use this prompt template:\n",
    "   ```python\n",
    "   bilingual_prompt = ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"You are a bilingual Manufacturing Copilot. If technician_language is 'es', respond in Spanish.\"),\n",
    "       (\"human\", \"Context: {context}\\nQuestion: {question}\\nTechnician language: {technician_language}\")\n",
    "   ])\n",
    "   ```\n",
    "\n",
    "3. **Add Comprehensive Logging**: Extend the `run_evidence` dictionary to include these exact fields:\n",
    "   - `completion_tokens`: Count of tokens in the response\n",
    "   - `latency_ms`: Time taken for chain execution\n",
    "   - `prompt_version`: SOP manual version (extract from filename)\n",
    "   - `safety_disclaimer_present`: Boolean check if response contains safety warning\n",
    "   \n",
    "4. **Create MLflow Integration**: Write a function that logs the metrics to MLflow using this pattern:\n",
    "   ```python\n",
    "   import mlflow\n",
    "   \n",
    "   def log_chain_metrics(run_evidence):\n",
    "       mlflow.start_run()\n",
    "       for key, value in run_evidence.items():\n",
    "           if isinstance(value, (int, float)):\n",
    "               mlflow.log_metric(key, value)\n",
    "           else:\n",
    "               mlflow.log_param(key, value)\n",
    "       mlflow.end_run()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b42f86",
   "metadata": {},
   "source": [
    "## âœ… Checklist\n",
    "- [ ] SOP data loading function implemented with proper error handling\n",
    "- [ ] Bilingual chain responds correctly in Spanish when requested\n",
    "- [ ] Governance log contains all required fields (completion_tokens, latency_ms, etc.)\n",
    "- [ ] MLflow integration successfully records metrics\n",
    "- [ ] Chain outputs contain appropriate safety disclaimers for maintenance tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0ff60",
   "metadata": {},
   "source": [
    "## ðŸ“š References\n",
    "- LangChain Docs â€” [LLMChain](https://python.langchain.com/docs/modules/model_io/chains/)\n",
    "- ISO 9001 Change Control Guidelines\n",
    "- Week 05-06 Data Profiling Notebook"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
