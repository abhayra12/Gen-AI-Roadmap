{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7578dfb9",
   "metadata": {},
   "source": [
    "# ü™Ñ Week 09-10 ¬∑ Notebook 09 ¬∑ LoRA & QLoRA for Cost-Efficient Fine-tuning\n",
    "\n",
    "Apply low-rank adapters and 4-bit quantization to tailor models for remote plants running on modest GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86070509",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Understand LoRA math and target module selection.\n",
    "- Configure QLoRA with `bitsandbytes` for 4-bit training.\n",
    "- Evaluate latency, memory, and accuracy trade-offs on maintenance logs.\n",
    "- Implement safety gates to ensure SOP steps survive quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788389e",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "A supplier wants an on-prem assistant running on a single NVIDIA T4. LoRA + QLoRA provides maintainable adapters without full fine-tuning cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf65531",
   "metadata": {},
   "source": [
    "## üìÑ Synthetic Shift Reports\n",
    "Short instructions and responses representing maintenance troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22859652",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_reports = Dataset.from_list([\n",
    "shift_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89fdce",
   "metadata": {},
   "source": [
    "## üßæ Tokenizer & Preprocess\n",
    "We simulate instruction tuning with prompt ‚Üí response pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280906e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'meta-llama/Llama-2-7b-hf'  # placeholder; requires license\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83459e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    prompts = [f\n",
    "    inputs = tokenizer(prompts, padding='max_length', truncation=True, max_length=256)\n",
    "    labels = tokenizer(batch['response'], padding='max_length', truncation=True, max_length=128)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "tokenized_shifts = shift_reports.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7126da",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è LoRA Configuration\n",
    "Target query/key/value projections in attention layers for maximum leverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "full_precision_model = AutoModelForCausalLM.from_pretrained(base_model_name, load_in_4bit=False)\n",
    "lora_model = get_peft_model(full_precision_model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce3447",
   "metadata": {},
   "source": [
    "## üßÆ QLoRA Setup\n",
    "Load base model in 4-bit using `bitsandbytes` to reduce memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "qlora_base = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=bnb_config, device_map='auto')\n",
    "qlora_model = get_peft_model(qlora_base, lora_config)\n",
    "qlora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328bdf8",
   "metadata": {},
   "source": [
    "## üß™ Training Loop (QLoRA)\n",
    "Adjust epochs, dataset size, and evaluation hooks in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "qlora_trainer = Trainer(\n",
    "# qlora_trainer.train()  # Uncomment when running with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d02b5e",
   "metadata": {},
   "source": [
    "## üìâ Safety Gate Checks\n",
    "Ensure quantization preserved critical steps by verifying the model regenerates mandatory SOP steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_gate(model, prompt, expected_keywords):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=96)\n",
    "    text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    missing = [kw for kw in expected_keywords if kw.lower() not in text.lower()]\n",
    "    return text, missing\n",
    "\n",
    "test_prompt = 'Shift summary: Press 12 error code E42. Provide response checklist.'\n",
    "expected = ['Isolate hydraulic pump', 'Reset PLC']\n",
    "generated, missing_keywords = safety_gate(qlora_model, test_prompt, expected)\n",
    "generated, missing_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ad40a",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Latency & Memory Snapshot\n",
    "Collect quick comparisons for stakeholder update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics():\n",
    "    return pd.DataFrame([\n",
    "\n",
    "compare_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11578ca",
   "metadata": {},
   "source": [
    "### üõ°Ô∏è Governance Checklist\n",
    "- Validate licensing (LLaMA/EULA) with legal before deployment.\n",
    "- Document quantization settings in model registry.\n",
    "- Capture safety gate results and attach to release ticket.\n",
    "- Schedule drift review every 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c86ade",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Run QLoRA training on your maintenance dataset (Zephyr or Mistral 7B).\n",
    "2. Profile latency on both T4 and A10 GPUs.\n",
    "3. Extend safety gate to include bilingual keywords and numeric tolerances.\n",
    "4. Produce a comparison memo for IT showcasing cost savings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91af42",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] LoRA targets selected and documented\n",
    "- [ ] QLoRA quantization tested\n",
    "- [ ] Safety gates passed\n",
    "- [ ] Metrics shared with stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e113aa",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- Dettmers et al., *QLoRA: Efficient Finetuning of Quantized LLMs* (2023)\n",
    "- HuggingFace Blog: *Low-Rank Adapters in Production*\n",
    "- Week 07 Decision Matrix Notebook"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
