{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa88a917",
   "metadata": {},
   "source": [
    "# üè≠ Week 09-10 ¬∑ Notebook 01 ¬∑ Pre-Training Concepts for Manufacturing Corpora\n",
    "\n",
    "Understand how to audit, curate, and prepare manufacturing text data before launching large-scale language model pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8d5ff",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Diagnose whether a manufacturing corpus is ready for masked or causal language modeling.\n",
    "- Engineer domain-specific curricula that balance routine operations with edge-case incidents.\n",
    "- Quantify coverage, freshness, and risk hotspots across maintenance, quality, and safety documents.\n",
    "- Produce a governance-ready data audit that satisfies IT/Compliance stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b0d7a",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "You have five years of shift logs, non-conformance reports (NCRs), maintenance tickets, and safety bulletins collected from four automotive plants. Leadership wants a maintenance co-pilot pre-trained on this corpus. Your job is to surface data gaps, compliance hazards, and curriculum strategy before anyone spins up GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba81e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for profiling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879775f",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Sample Manufacturing Corpus\n",
    "The notebook ships with a synthetic corpus that mimics mixed-format manufacturing documents. Replace these CSV/JSON stubs with your plant exports when running in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset with multiple document classes\n",
    "np.random.seed(42)\n",
    "num_docs = 1000\n",
    "doc_types = ['shift_log', 'maintenance_ticket', 'ncr', 'safety_bulletin']\n",
    "plants = ['Plant_A', 'Plant_B', 'Plant_C', 'Plant_D']\n",
    "pii_flags = ['none', 'name', 'id', 'contact']\n",
    "\n",
    "data = {\n",
    "    'doc_id': [f'DOC-{i:04d}' for i in range(num_docs)],\n",
    "    'doc_type': np.random.choice(doc_types, num_docs, p=[0.5, 0.3, 0.15, 0.05]),\n",
    "    'plant': np.random.choice(plants, num_docs),\n",
    "    'last_updated': pd.to_datetime('2025-10-13') - pd.to_timedelta(np.random.randint(1, 1000, size=num_docs), unit='d'),\n",
    "    'pii_flags': np.random.choice(pii_flags, num_docs, p=[0.8, 0.1, 0.05, 0.05]),\n",
    "    'safety_sensitive': np.random.choice([True, False], num_docs, p=[0.1, 0.9])\n",
    "}\n",
    "documents = pd.DataFrame(data)\n",
    "\n",
    "# Make safety bulletins more likely to be safety sensitive\n",
    "documents.loc[documents['doc_type'] == 'safety_bulletin', 'safety_sensitive'] = True\n",
    "\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04297ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage summary by document type\n",
    "coverage = documents.groupby('doc_type').agg(\n",
    "    count=('doc_id', 'size'),\n",
    "    percentage=('doc_id', lambda x: 100 * x.count() / len(documents))\n",
    ").sort_values('count', ascending=False)\n",
    "\n",
    "print(\"Corpus Coverage Analysis:\")\n",
    "print(coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d6a41",
   "metadata": {},
   "source": [
    "### üîé Interpretation Guidance\n",
    "- **Coverage**: Ensure high-risk document classes (e.g., safety bulletins) have sufficient volume.\n",
    "- **Curriculum Candidate**: Stage training from routine shift logs ‚Üí maintenance tickets ‚Üí high-severity NCRs.\n",
    "- **Action**: Flag doc types with <10% representation for synthetic augmentation or targeted collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freshness analysis: days since last update\n",
    "today = pd.Timestamp('2025-10-13')\n",
    "documents['days_stale'] = (today - documents['last_updated']).dt.days\n",
    "staleness = documents.groupby('doc_type')['days_stale'].describe()[['mean', '50%','max']].astype(int)\n",
    "\n",
    "print(\"Data Freshness Analysis (in days):\")\n",
    "print(staleness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb65e98",
   "metadata": {},
   "source": [
    "### üß≠ Governance Check\n",
    "- Define a freshness SLA: e.g.,  180 days for maintenance tickets,  90 days for safety bulletins.\n",
    "- Trigger review workflows if `max`  730 days (stale procedures).\n",
    "- Document exceptions and notify plant managers for updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize plant-wise distribution and PII risk\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plant Distribution\n",
    "plant_counts = documents.groupby('plant').size()\n",
    "plant_counts.plot(kind='bar', ax=axes[0], title='Documents per Plant', color='#1f77b4', rot=0)\n",
    "axes[0].set_ylabel('Document Count')\n",
    "axes[0].set_xlabel('Plant ID')\n",
    "\n",
    "# PII Flags Distribution\n",
    "pii_counts = documents.groupby('pii_flags').size()\n",
    "pii_counts.plot(kind='bar', ax=axes[1], title='PII Flags Detected', color='#d62728', rot=0)\n",
    "axes[1].set_ylabel('Document Count')\n",
    "axes[1].set_xlabel('PII Type')\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e11f71",
   "metadata": {},
   "source": [
    "## üß± Masked vs. Causal LM Readiness\n",
    "\n",
    "| Dimension | Masked LM (e.g., BERT) Proof Points | Causal LM (e.g., GPT/Llama) Proof Points | Manufacturing Notes |\n",
    "|---|---|---|---|\n",
    "| **Goal** | Bidirectional understanding, classification, entity recognition. | Text generation, summarization, Q&A. | **Causal LM** is better for a copilot that needs to draft reports and answer questions. **Masked LM** is good for pre-processing steps like identifying machine parts in text. |\n",
    "| **Data Structure** | Unstructured text, sentences with missing words. | Sequential, conversational, or instruction-formatted text. | Our corpus is a mix. Shift logs are sequential (good for Causal), while NCRs are structured forms (good for Masked). |\n",
    "| **Task Example** | \"The [MASK] failed due to overheating.\" -> Predicts \"motor\". | \"Generate a maintenance report for motor failure...\" -> Drafts a full report. | The copilot's primary value is generative, favoring a **Causal LM** architecture. |\n",
    "| **Training Cost** | Generally cheaper and faster to pre-train. | More computationally expensive. | Start with a pre-trained Causal LM and fine-tune it. Full pre-training is a massive undertaking. |\n",
    "| **Verdict** | Use for specialized NLP tasks (e.g., PII detection). | **Primary choice** for the Manufacturing Copilot's core generative engine. | A hybrid approach is powerful: use a fine-tuned Masked LM to extract structured data from logs, then feed that data to a Causal LM to generate a summary. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk scoring heuristic to prioritize governance reviews\n",
    "risk_weights = {\n",
    "    'safety_bulletin': 5,\n",
    "    'ncr': 4,\n",
    "    'maintenance_ticket': 3,\n",
    "    'shift_log': 1\n",
    "}\n",
    "\n",
    "def calculate_risk(row):\n",
    "    doc_type_risk = risk_weights.get(row['doc_type'], 0)\n",
    "    pii_risk = 2 if row['pii_flags'] != 'none' else 0\n",
    "    stale_risk = 1 if row['days_stale'] > 365 else 0\n",
    "    safety_risk = 3 if row['safety_sensitive'] else 0\n",
    "    return doc_type_risk + pii_risk + stale_risk + safety_risk\n",
    "\n",
    "documents['governance_risk'] = documents.apply(calculate_risk, axis=1)\n",
    "\n",
    "risk_summary = documents.groupby('plant')['governance_risk'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Average Governance Risk Score per Plant:\")\n",
    "print(risk_summary)\n",
    "\n",
    "# Display documents with the highest risk scores\n",
    "print(\"\\nTop 5 High-Risk Documents:\")\n",
    "print(documents.sort_values('governance_risk', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81507d",
   "metadata": {},
   "source": [
    "### üõ°Ô∏è Risk Register Template\n",
    "- Plants with average risk  6 require Compliance sign-off before data export.\n",
    "- Flag PII types and note anonymization method (hash, redact, aggregate).\n",
    "- Capture risks in ISO 9001 change log with mitigation owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c0b5f",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Replace the synthetic dataset with your plant corpus exports (CSV/JSON/PDF).\n",
    "2. Extend the freshness SLA by equipment criticality and create alert rules.\n",
    "3. Propose a three-phase curriculum schedule and justify each phase with metrics.\n",
    "4. Present a governance report to IT + Compliance with risk scores and mitigation actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b658fc",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Corpus inventoried with volume, freshness, and language breakdown\n",
    "- [ ] PII and safety-sensitive text cataloged with mitigation plan\n",
    "- [ ] Curriculum roadmap drafted and validated with SMEs\n",
    "- [ ] Governance report delivered to stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693788af",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- *ISO 9001:2015 Quality Management Systems*\n",
    "- *OSHA Recordkeeping Guidelines*\n",
    "- HuggingFace Datasets: [Data Curation Playbook](https://huggingface.co/docs/datasets/main/en/process)\n",
    "- NVIDIA: *Data-Centric AI for Industrial Use Cases* (2024)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
