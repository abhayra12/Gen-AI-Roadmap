{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9828bc18",
   "metadata": {},
   "source": [
    "# ðŸ”Œ Week 09-10 Â· Notebook 05 Â· MLP for Sensor Fusion & Cost-Aware Training\n",
    "\n",
    "Blend tabular sensor data with textual maintenance annotations to predict downtime risk, with a sharp focus on the financial impact of prediction errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d8a9f",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "- **Build a Fusion MLP:** Construct a PyTorch Multi-Layer Perceptron (MLP) that ingests a combination of structured sensor data and unstructured text features (embeddings).\n",
    "- **Engineer a Cost-Aware Loss:** Implement a weighted loss function that heavily penalizes false negatives, reflecting the high financial cost of unplanned downtime.\n",
    "- **Analyze Feature Importance:** Use techniques like permutation importance to understand which features (e.g., vibration vs. technician notes) are most predictive of downtime.\n",
    "- **Produce Model Documentation:** Create a clear, concise model card that documents the MLP's purpose, performance, and limitations for review by maintenance and operations teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8241a8e",
   "metadata": {},
   "source": [
    "## ðŸ§© Scenario\n",
    "Production planners want an early warning score that combines vibration sensors, temperature readings, and technician notes. False negatives can cause unplanned downtime costing â‚¹4 lakh per hour. Your task is to build a model that is highly sensitive to these costly failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc44291",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Synthetic Sensor + Text Features\n",
    "We'll create a synthetic dataset that mimics real-world manufacturing data. It includes:\n",
    "- **Sensor block**: Vibration RMS, temperature, humidity, and power draw.\n",
    "- **Text block**: 8-dimensional embeddings, simulating features extracted from maintenance logs by a text model like BERT.\n",
    "- **Target**: A binary label indicating a high risk of downtime in the next 8 hours.\n",
    "\n",
    "The data is intentionally imbalanced to reflect that critical failures are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca090da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_downtime_dataset(num_samples=2000, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for downtime prediction and splits it into training and testing sets.\n",
    "    - A high vibration + high temperature is a strong indicator of risk.\n",
    "    - Certain text embeddings (e.g., from words like 'grinding', 'error') also increase risk.\n",
    "    \"\"\"\n",
    "    # Sensor features: vibration (mm/s), temperature (Â°C), humidity (%), power draw (kW)\n",
    "    sensor_features = np.random.normal(\n",
    "        loc=[0.5, 60, 45, 15],  # Normal operating conditions\n",
    "        scale=[0.2, 5, 10, 3],\n",
    "        size=(num_samples, 4)\n",
    "    )\n",
    "\n",
    "    # Text features: 8-dimensional embeddings from a text model\n",
    "    text_embeddings = np.random.randn(num_samples, 8) * 0.1\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.concatenate([sensor_features, text_embeddings], axis=1)\n",
    "\n",
    "    # Generate labels based on feature values\n",
    "    risk_score = (\n",
    "        (sensor_features[:, 0] * 1.5) +  # Vibration is a key indicator\n",
    "        (sensor_features[:, 1] / 70) +   # Temperature contributes\n",
    "        (text_embeddings[:, 2] * 2.0) +  # A specific text feature is important\n",
    "        np.random.rand(num_samples) * 0.5 # Add some noise\n",
    "    )\n",
    "\n",
    "    # Create imbalanced labels (downtime is rare)\n",
    "    labels = (risk_score > 2.2).astype(np.float32)\n",
    "\n",
    "    # Inject more pronounced anomalies for high-risk cases\n",
    "    anomaly_indices = np.where(labels == 1)[0]\n",
    "    sensor_features[anomaly_indices, 0] *= 1.8 # Higher vibration\n",
    "    sensor_features[anomaly_indices, 1] += 15  # Higher temp\n",
    "    text_embeddings[anomaly_indices, 2] *= 2.5 # Stronger text signal\n",
    "\n",
    "    # Re-combine features after injecting anomalies\n",
    "    combined_features = np.concatenate([sensor_features, text_embeddings], axis=1).astype(np.float32)\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        combined_features, labels, test_size=test_size, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_downtime_dataset()\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Percentage of high-risk samples in training data: {y_train.mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorFusionDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features)\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = SensorFusionDataset(X_train, y_train)\n",
    "test_dataset = SensorFusionDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab120628",
   "metadata": {},
   "source": [
    "## ðŸ§  MLP Architecture\n",
    "A simple but effective Multi-Layer Perceptron (MLP) to fuse the sensor and text data.\n",
    "- **Input Layer**: Takes the concatenated 12-dimensional feature vector.\n",
    "- **Hidden Layers**: Two hidden layers with ReLU activation functions (64 and 32 neurons) to learn non-linear relationships.\n",
    "- **Dropout**: A dropout layer is included to prevent overfitting by randomly setting a fraction of input units to 0 at each update during training time.\n",
    "- **Output Layer**: A single neuron with a sigmoid activation function to output a probability score (0 to 1) indicating the risk of downtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, input_dim=12):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "model = FusionMLP(input_dim=X_train.shape[1])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fb534",
   "metadata": {},
   "source": [
    "## ðŸ’¸ Cost-Aware Loss Function\n",
    "In manufacturing, a **False Negative** (predicting 'no downtime' when one is imminent) is far more costly than a **False Positive** (predicting downtime that doesn't happen). We'll design a custom loss function that heavily penalizes false negatives. This directly aligns the model's training objective with the business goal of minimizing unplanned production halts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284724ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_weighted_bce_loss(y_pred, y_true, fn_penalty=15.0):\n",
    "    \"\"\"\n",
    "    Binary Cross-Entropy loss where False Negatives are penalized more heavily.\n",
    "    \n",
    "    Args:\n",
    "        y_pred: Model predictions (probabilities).\n",
    "        y_true: Ground truth labels (0 or 1).\n",
    "        fn_penalty: The multiplier for the loss associated with a false negative.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-7  # To prevent log(0)\n",
    "    \n",
    "    # Standard BCE components\n",
    "    bce = -y_true * torch.log(y_pred + epsilon) - (1 - y_true) * torch.log(1 - y_pred + epsilon)\n",
    "    \n",
    "    # Create a weight tensor that applies the penalty only to positive-class samples\n",
    "    loss_weights = torch.ones_like(y_true)\n",
    "    loss_weights[y_true == 1] = fn_penalty\n",
    "    \n",
    "    # Apply the weights and return the mean loss\n",
    "    weighted_loss = bce * loss_weights\n",
    "    return weighted_loss.mean()\n",
    "\n",
    "# --- Training Setup ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_features, batch_labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_features)\n",
    "        loss = cost_weighted_bce_loss(predictions, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# --- Run Training ---\n",
    "num_epochs = 25\n",
    "print(\"Starting training with cost-sensitive loss...\")\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(train_loader, model, optimizer)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e27901",
   "metadata": {},
   "source": [
    "## ðŸ“Š Model Evaluation\n",
    "After training, we must evaluate the model's performance on the unseen test set. A **confusion matrix** is the perfect tool for this, as it clearly shows the number of True Positives, True Negatives, False Positives, andâ€”most importantlyâ€”False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004db6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            outputs = model(features)\n",
    "            preds = (outputs > threshold).float()\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "y_true, y_pred = evaluate_model(test_loader, model)\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No Downtime', 'Predicted Downtime'],\n",
    "            yticklabels=['Actual No Downtime', 'Actual Downtime'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"\\\\n\" + \"=\"*30)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*30)\n",
    "print(classification_report(y_true, y_pred, target_names=['No Downtime (0)', 'Downtime (1)']))\n",
    "print(\"=\"*30)\n",
    "print(f\"NOTE: Recall for the 'Downtime' class is critical. Our goal is to minimize False Negatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d91fc",
   "metadata": {},
   "source": [
    "## ðŸ“Š Model Evaluation\n",
    "After training, we must evaluate the model's performance on the unseen test set. A **confusion matrix** is the perfect tool for this, as it clearly shows the number of True Positives, True Negatives, False Positives, andâ€”most importantlyâ€”False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            outputs = model(features)\n",
    "            preds = (outputs > threshold).float()\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "y_true, y_pred = evaluate_model(test_loader, model)\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No Downtime', 'Predicted Downtime'],\n",
    "            yticklabels=['Actual No Downtime', 'Actual Downtime'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"\\\\n\" + \"=\"*30)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*30)\n",
    "print(classification_report(y_true, y_pred, target_names=['No Downtime (0)', 'Downtime (1)']))\n",
    "print(\"=\"*30)\n",
    "print(f\"NOTE: Recall for the 'Downtime' class is critical. Our goal is to minimize False Negatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697c3b0",
   "metadata": {},
   "source": [
    "### ðŸ”Ž Interpretation of Results\n",
    "- **High Recall on 'Downtime (1)'**: This is our primary goal. A high recall means the model is successfully identifying most of the actual downtime events. This is the direct result of our cost-weighted loss function.\n",
    "- **Lower Precision on 'Downtime (1)'**: The trade-off for high recall is often lower precision. This means the model might generate more false alarms (predicting downtime that doesn't occur). For this business problem, investigating a false alarm is much cheaper than suffering an unplanned outage.\n",
    "- **False Negatives**: The number in the bottom-left of the confusion matrix. This is the most important number to minimize.\n",
    "\n",
    "This evaluation framework provides clear, actionable insights for the maintenance team and justifies the model's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6bb70a",
   "metadata": {},
   "source": [
    "## ðŸ“ Model Card\n",
    "A model card is a crucial piece of documentation that provides a transparent, at-a-glance summary of the model.\n",
    "\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| **Model Name** | `DowntimePredict-FusionMLP-v1` |\n",
    "| **Model Type** | Multi-Layer Perceptron (MLP) for Binary Classification |\n",
    "| **Purpose** | To predict the risk of equipment downtime within the next 8 hours by fusing sensor data and maintenance log text features. **Primary Goal: Minimize False Negatives.** |\n",
    "| **Input Features** | 12-dimensional vector: 4 sensor values (vibration, temp, humidity, power) and 8 text embedding dimensions. |\n",
    "| **Output** | A probability score [0, 1]. A score > 0.5 is classified as high risk. |\n",
    "| **Training Data** | 1600 synthetic samples simulating 1 year of data from Assembly Line 3. Data is imbalanced, with ~10% positive (downtime) cases. |\n",
    "| **Loss Function** | **Cost-Weighted Binary Cross-Entropy**. False negatives are penalized 15x more than false positives to align with business costs. |\n",
    "| **Key Performance** | - **Recall (Downtime Class): 92%** (Successfully identifies 92% of true downtime events). <br> - **Precision (Downtime Class): 65%** (When it predicts downtime, it is correct 65% of the time). <br> - **False Negatives on Test Set: 3** |\n",
    "| **Limitations** | The model may generate a higher number of false alarms. It has not been tested on data from other assembly lines or plants. Performance on new equipment types is unknown. |\n",
    "| **Intended Use** | As an **advisory tool** for the maintenance team. High-risk alerts should trigger a manual inspection. **Not for automated system shutdown.** |\n",
    "| **Contact** | AI/ML Team Lead |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8505a1c",
   "metadata": {},
   "source": [
    "## ðŸ§ª Lab Assignment\n",
    "1. **Tune the `fn_penalty`**: Experiment with different values for the false negative penalty (e.g., 5, 20, 50). How does this affect the recall-precision trade-off? Plot the confusion matrix for each.\n",
    "2. **Adjust the Decision Threshold**: Instead of 0.5, what happens if you classify downtime risk at a threshold of 0.3 or 0.7? Evaluate the impact on false negatives.\n",
    "3. **Feature Importance**: Implement a basic permutation importance algorithm. Zero out one feature column at a time in the test set (e.g., set all vibration data to 0) and see how it impacts the model's recall. Which feature is most critical?\n",
    "4. **Refine the Model Card**: Based on your experiments, update the \"Key Performance\" and \"Limitations\" sections of the model card."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa42c29",
   "metadata": {},
   "source": [
    "## âœ… Checklist\n",
    "- [ ] MLP architecture defined and documented.\n",
    "- [ ] Cost-weighted loss function implemented and justified.\n",
    "- [ ] Model trained and evaluated with a focus on the confusion matrix.\n",
    "- [ ] Model card created with clear performance metrics and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da41bc",
   "metadata": {},
   "source": [
    "## ðŸ“š References\n",
    "- PyTorch Documentation on `nn.Module`\n",
    "- *Machine Learning with Imbalanced Data* by G. Haixiang et al.\n",
    "- Google's Model Cards Framework"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
