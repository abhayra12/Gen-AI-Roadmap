{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70767218",
   "metadata": {},
   "source": [
    "# üì¶ Week 09-10 ¬∑ Notebook 06 ¬∑ Mini-batch Training & Curriculum Scheduling\n",
    "\n",
    "Design batching strategies and curricula to stabilize training on skewed manufacturing corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28a2ff",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Implement streaming data loaders for mixed PDF/CSV corpora.\n",
    "- Compare curriculum strategies for rare incident coverage.\n",
    "- Balance batch size vs. throughput vs. GPU memory.\n",
    "- Build shift hand-off SOPs for 24/7 training operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b582d08",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "Only 3% of maintenance logs capture critical failures, yet they matter most. You need a training curriculum that ramps from routine notes ‚Üí cautionary signals ‚Üí critical incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65602d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(909)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f5441d",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Curriculum Tags\n",
    "Each sample is assigned a severity level. Critical incidents are oversampled later in the curriculum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c49c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_curriculum_dataset(n=1200):\n",
    "    severities = ['routine', 'warning', 'critical']\n",
    "    severity_weights = [0.82, 0.15, 0.03]\n",
    "    records = []\n",
    "    for i in range(n):\n",
    "        level = random.choices(severities, weights=severity_weights)[0]\n",
    "        embedding = torch.randn(512)\n",
    "        if level == 'critical':\n",
    "            embedding += 2.0\n",
    "        elif level == 'warning':\n",
    "            embedding += 0.5\n",
    "        records.append({'id': i, 'severity': level, 'embedding': embedding})\n",
    "    return records\n",
    "\n",
    "curriculum_records = create_curriculum_dataset()\n",
    "pd.Series([r['severity'] for r in curriculum_records]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b53115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurriculumDataset(Dataset):\n",
    "    def __init__(self, records, severity_priority):\n",
    "        self.records = records\n",
    "        self.severity_priority = severity_priority\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        return record['embedding'], self.severity_priority[record['severity']]\n",
    "\n",
    "severity_priority = {'routine': 0, 'warning': 1, 'critical': 2}\n",
    "dataset = CurriculumDataset(curriculum_records, severity_priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd8290",
   "metadata": {},
   "source": [
    "## üóúÔ∏è Adaptive Batch Sampler\n",
    "Start with routine samples, then gradually mix in higher-severity items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curriculum_indices(epoch, severity_priority, dataset):\n",
    "    base = [i for i, _ in enumerate(dataset.records) if severity_priority[dataset.records[i]['severity']] == 0]\n",
    "    warning = [i for i, _ in enumerate(dataset.records) if severity_priority[dataset.records[i]['severity']] == 1]\n",
    "    critical = [i for i, _ in enumerate(dataset.records) if severity_priority[dataset.records[i]['severity']] == 2]\n",
    "    schedule = {\n",
    "        0: base,\n",
    "1\n",
    "        2: base + warning + critical\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ","
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
