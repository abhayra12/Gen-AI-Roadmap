{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0659e298",
   "metadata": {},
   "source": [
    "# ðŸ Notebook 02: Python Essentials for Generative AI\n",
    "\n",
    "**Week 1-2: Python & ML Foundations**  \n",
    "**Gen AI Masters Program**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Objectives\n",
    "\n",
    "Welcome to the second notebook in our Python foundations module. While the previous notebook focused on setting up your environment, this one dives deep into the **core Python programming concepts** that are essential for building any AI or machine learning application. A solid grasp of these fundamentals is non-negotiable for a successful career in this field.\n",
    "\n",
    "By the end of this notebook, you will have a strong command of:\n",
    "1.  **Core Data Structures**: Master the use of lists, dictionaries, sets, and tuples for storing and organizing data.\n",
    "2.  **Control Flow**: Implement sophisticated logic using `if/else` statements, loops, and highly efficient comprehensions.\n",
    "3.  **Modular Code**: Write clean, reusable, and maintainable code with functions and lambda expressions.\n",
    "4.  **Object-Oriented Programming (OOP)**: Structure your code effectively with classes, a key skill for building complex systems like model training pipelines.\n",
    "5.  **Robustness and I/O**: Learn to handle files for data loading/saving and manage potential errors gracefully with exception handling.\n",
    "6.  **Pythonic Best Practices**: Write code that is not just functional but also efficient, readable, and maintainableâ€”the hallmark of a professional developer.\n",
    "\n",
    "**Estimated Time:** 2-3 hours\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Why is Python the Undisputed Language of AI?\n",
    "\n",
    "Python's dominance in the AI and machine learning landscape is a result of a powerful combination of factors:\n",
    "\n",
    "-   ðŸš€ **A Rich and Mature Ecosystem**: Python is the home of essential libraries that power modern AI, including **PyTorch**, **TensorFlow**, and **Hugging Face**. This ecosystem provides pre-built tools for nearly every task, from model training to deployment.\n",
    "-   ðŸ“Š **Data Science Powerhouses**: It seamlessly integrates with libraries like **NumPy**, **Pandas**, and **Matplotlib**, which are the industry standards for numerical computation, data manipulation, and visualization.\n",
    "-   ðŸ¤ **Simple and Flexible Integration**: Python's simplicity allows it to be easily connected with web frameworks (like Flask or FastAPI for creating APIs), databases, and cloud services, making it ideal for building end-to-end AI applications.\n",
    "-   ðŸ‘¥ **A Vibrant and Supportive Community**: Python is backed by a massive global community of developers and researchers. This means you have access to extensive documentation, tutorials, and open-source libraries for almost any problem you might encounter.\n",
    "\n",
    "This notebook will equip you with the essential Python skills needed to leverage this powerful ecosystem and build cutting-edge AI applications. Let's get started! ðŸŽ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfa7d7",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Section 1: Python's Core Data Structures\n",
    "\n",
    "Data structures are the fundamental constructs used to organize, manage, and store data in a program. Choosing the right data structure is crucial for writing efficient and readable code. In AI, they are used to store everything from **model configurations** and **training data batches** to **tokenized text sequences** and **probability distributions** from a model's output layer.\n",
    "\n",
    "### Lists: Ordered, Mutable Collections\n",
    "\n",
    "A **list** is one of the most versatile data structures in Python. It is an ordered and mutable collection, meaning you can change its contents, add new items, or remove existing ones.\n",
    "\n",
    "-   **Ordered**: The items in a list have a defined order, and that order will not change unless you explicitly modify it.\n",
    "-   **Mutable**: You can add, remove, or change items in a list after it has been created.\n",
    "\n",
    "In AI, lists are commonly used for:\n",
    "-   Storing sequences of data, like a series of text prompts for a language model.\n",
    "-   Holding a history of model outputs or training loss values.\n",
    "-   Representing a batch of data points before they are converted into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece901ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- List Creation and Basic Operations ---\n",
    "# Here, we define two lists: one for popular language models and another for their corresponding performance scores.\n",
    "# This is a common pattern for storing related data, although dictionaries or lists of objects are often better for more complex scenarios.\n",
    "models = [\"GPT-4\", \"Claude 3\", \"Gemini 1.5\", \"Llama 3\"]\n",
    "scores = [0.95, 0.93, 0.91, 0.89]\n",
    "\n",
    "print(f\"Initial models: {models}\")\n",
    "# Accessing elements by index is a fundamental list operation. Python uses 0-based indexing.\n",
    "print(f\"Score of the first model ('{models[0]}'): {scores[0]}\")\n",
    "\n",
    "# --- Modifying Lists ---\n",
    "# Lists are mutable, which means you can change their content after they are created.\n",
    "# The .append() method adds an item to the end of the list.\n",
    "models.append(\"Mistral\")\n",
    "scores.append(0.85)\n",
    "print(f\"\\nUpdated models after append: {models}\")\n",
    "\n",
    "# --- Slicing Lists ---\n",
    "# Slicing is a powerful feature for accessing sub-lists. The syntax is `list[start:stop:step]`.\n",
    "# The `stop` index is exclusive, meaning the element at that index is not included.\n",
    "print(f\"The top 2 models are: {models[:2]}\")  # From the beginning up to (but not including) index 2\n",
    "print(f\"Models from the third position onwards: {models[2:]}\")  # From index 2 to the end\n",
    "\n",
    "# --- Common List Operations ---\n",
    "# The `len()` function returns the number of items in a list.\n",
    "print(f\"\\nTotal number of models: {len(models)}\")\n",
    "# The `in` keyword is an efficient way to check for the existence of an element in a list.\n",
    "print(f\"Is 'Gemini 1.5' in our list? {'Gemini 1.5' in models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ee804",
   "metadata": {},
   "source": [
    "### Dictionaries: Unordered Key-Value Pairs\n",
    "\n",
    "A **dictionary** is a collection of key-value pairs. Unlike lists, which are indexed by a range of numbers, dictionaries are indexed by **keys**, which can be any immutable type (like strings, numbers, or tuples).\n",
    "\n",
    "-   **Unordered (Historically)**: In Python versions before 3.7, dictionaries were unordered. Since Python 3.7, they are **insertion ordered**, meaning they remember the order in which items were inserted.\n",
    "-   **Mutable**: You can add, remove, or change key-value pairs.\n",
    "-   **Efficient Lookups**: Dictionaries are highly optimized for retrieving values when the key is known. This is much faster than searching for an element in a list.\n",
    "\n",
    "Dictionaries are perfect for storing structured information, such as:\n",
    "-   **Hyperparameters** for a model (e.g., learning rate, batch size).\n",
    "-   **Metadata** for a dataset (e.g., name, version, author).\n",
    "-   **JSON-like objects** returned from an API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dictionary for Model Configuration ---\n",
    "# Dictionaries are the ideal data structure for storing model hyperparameters and configurations.\n",
    "# The keys are strings that describe the hyperparameter, and the values are the settings.\n",
    "model_config = {\n",
    "    \"name\": \"GPT-4\",\n",
    "    \"parameters\": \"1.8T\",\n",
    "    \"context_length\": 128000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"provider\": \"OpenAI\"\n",
    "}\n",
    "\n",
    "print(\"--- Model Configuration ---\")\n",
    "# The .items() method returns a view object that displays a list of a dictionary's key-value tuple pairs.\n",
    "# This is useful for iterating over all key-value pairs in a dictionary.\n",
    "for key, value in model_config.items():\n",
    "    print(f\"  - {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# --- Accessing and Modifying Dictionary Values ---\n",
    "# You can access the value of a key using square bracket notation.\n",
    "# This will raise a `KeyError` if the key does not exist.\n",
    "print(f\"\\nModel Name: {model_config['name']}\")\n",
    "\n",
    "# A safer way to access keys is using the .get() method.\n",
    "# It returns `None` (or a specified default value) if the key is not found, avoiding an error.\n",
    "print(f\"Model's learning rate: {model_config.get('learning_rate', 'Not specified')}\")\n",
    "\n",
    "# Add a new key-value pair or update an existing one.\n",
    "model_config[\"status\"] = \"production\"\n",
    "print(f\"\\nUpdated config with status: {model_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b7344",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Section 2: Control Flow\n",
    "\n",
    "**Control flow** refers to the order in which the statements in your program are executed. Python provides several constructs to control this flow, allowing you to execute code conditionally and repeatedly. These form the logical core of any program.\n",
    "\n",
    "### Conditional Logic: `if`, `elif`, `else`\n",
    "\n",
    "Conditional statements allow you to execute certain blocks of code only when specific conditions are met. This is fundamental for decision-making in a program.\n",
    "\n",
    "In machine learning, conditional statements are used everywhere:\n",
    "-   **Making decisions** based on model performance metrics (e.g., if accuracy > 90%, deploy the model).\n",
    "-   **Controlling the training loop** (e.g., if validation loss stops improving, stop training early).\n",
    "-   **Preprocessing data** based on feature values (e.g., if a value is missing, fill it with the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476737c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for Model Evaluation ---\n",
    "# This function uses conditional logic (`if`, `elif`, `else`) to classify a model's performance.\n",
    "# Using functions to encapsulate logic like this is a core principle of good programming.\n",
    "def evaluate_model_performance(score: float) -> str:\n",
    "    \"\"\"\n",
    "    Evaluates a model's performance tier based on a given score.\n",
    "    \n",
    "    Args:\n",
    "        score (float): The performance score of the model (e.g., accuracy, F1-score).\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the performance tier.\n",
    "    \"\"\"\n",
    "    if score >= 0.95:\n",
    "        return \"Tier 1: Excellent performance. Ready for production.\"\n",
    "    elif score >= 0.85:\n",
    "        return \"Tier 2: Good performance. Suitable for fine-tuning or specific tasks.\"\n",
    "    elif score >= 0.75:\n",
    "        return \"Tier 3: Average performance. Consider retraining or using a different model.\"\n",
    "    else:\n",
    "        return \"Tier 4: Poor performance. Requires significant review and retraining.\"\n",
    "\n",
    "# --- Testing the Evaluation Function ---\n",
    "# It's crucial to test your functions with a range of inputs to ensure they work as expected.\n",
    "test_scores = [0.98, 0.87, 0.76, 0.65]\n",
    "\n",
    "print(\"--- Model Performance Evaluation ---\")\n",
    "for score in test_scores:\n",
    "    evaluation = evaluate_model_performance(score)\n",
    "    print(f\"Score: {score:.2f} -> {evaluation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d00fa0",
   "metadata": {},
   "source": [
    "### Loops and Comprehensions\n",
    "\n",
    "**Loops** are used for iterating over a sequence (like a list, tuple, dictionary, or string) and executing a block of code for each item.\n",
    "\n",
    "**Comprehensions** provide a concise, elegant, and often more efficient way to create lists, dictionaries, or sets from other iterables. They are considered more \"Pythonic\" than traditional loops for many common tasks and can result in more readable code.\n",
    "\n",
    "-   **List Comprehension**: `[expression for item in iterable if condition]`\n",
    "-   **Dictionary Comprehension**: `{key_expression: value_expression for item in iterable if condition}`\n",
    "-   **Set Comprehension**: `{expression for item in iterable if condition}`\n",
    "\n",
    "In AI, you might use comprehensions to:\n",
    "-   Quickly preprocess a list of text documents.\n",
    "-   Create a dictionary mapping words to their frequencies.\n",
    "-   Filter a list of results based on a confidence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893edada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard `for` loop ---\n",
    "# A `for` loop is the standard way to iterate over a sequence.\n",
    "prompts = [\"Summarize this long article\", \"Translate this sentence to Spanish\", \"Extract key entities from this text\"]\n",
    "\n",
    "print(\"--- Iterating with a standard `for` loop: ---\")\n",
    "# `enumerate` is a useful function that adds a counter to an iterable.\n",
    "# It returns pairs of (index, item), which is often cleaner than managing the index manually.\n",
    "for i, prompt in enumerate(prompts, 1):  # Start counting from 1\n",
    "    print(f\"  Prompt {i}: '{prompt}'\")\n",
    "\n",
    "# --- List Comprehension ---\n",
    "# This is a more concise and often faster way to create a new list by transforming an existing one.\n",
    "# The following line is equivalent to:\n",
    "# prompt_lengths = []\n",
    "# for p in prompts:\n",
    "#     prompt_lengths.append(len(p))\n",
    "print(\"\\n--- Using a list comprehension to get prompt lengths: ---\")\n",
    "prompt_lengths = [len(p) for p in prompts]\n",
    "print(f\"  Lengths of prompts: {prompt_lengths}\")\n",
    "\n",
    "# --- List Comprehension with Filtering ---\n",
    "# Comprehensions can also include a conditional `if` clause to filter items.\n",
    "# This creates a new list containing only the prompts that are longer than 30 characters.\n",
    "print(\"\\n--- Using a list comprehension to find long prompts: ---\")\n",
    "long_prompts = [p for p in prompts if len(p) > 30]\n",
    "print(f\"  Long prompts: {long_prompts}\")\n",
    "\n",
    "# --- Dictionary Comprehension ---\n",
    "# You can also use comprehensions to create dictionaries.\n",
    "# Here, we create a dictionary mapping each prompt to its length.\n",
    "print(\"\\n--- Using a dictionary comprehension: ---\")\n",
    "prompt_length_map = {p: len(p) for p in prompts}\n",
    "print(f\"  Prompt-to-length map: {prompt_length_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d16707",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Section 3: Functions and Lambda Expressions\n",
    "\n",
    "**Functions** are reusable blocks of code that perform a specific task. They are the cornerstone of writing modular, organized, and maintainable programs. By breaking down a complex problem into smaller, manageable functions, you make your code easier to read, debug, and scale.\n",
    "\n",
    "In machine learning, functions are used to define everything from:\n",
    "-   **Data preprocessing steps** (e.g., cleaning text, normalizing images).\n",
    "-   **Model training and evaluation loops**.\n",
    "-   **API endpoints** that serve model predictions.\n",
    "\n",
    "A well-written function should have:\n",
    "-   A clear, descriptive name.\n",
    "-   A **docstring** that explains what it does, its parameters, and what it returns.\n",
    "-   **Type hints** to specify the expected data types for arguments and the return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# --- A Well-Documented Function with Type Hinting ---\n",
    "# This function demonstrates several best practices:\n",
    "# - Type hints (`text: str`, `-> str`) make the function's contract clear.\n",
    "# - Default arguments (`lowercase: bool = True`) make the function more flexible.\n",
    "# - A detailed docstring explains the function's purpose, arguments, and return value.\n",
    "def preprocess_text(\n",
    "    text: str, \n",
    "    lowercase: bool = True, \n",
    "    remove_punctuation: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses raw text for Natural Language Processing (NLP) tasks.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string to be processed.\n",
    "        lowercase (bool): If True, converts the text to lowercase. Defaults to True.\n",
    "        remove_punctuation (bool): If True, removes all punctuation marks. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and preprocessed text.\n",
    "    \"\"\"\n",
    "    # Apply lowercase transformation if the flag is set\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Apply punctuation removal if the flag is set\n",
    "    if remove_punctuation:\n",
    "        # `str.maketrans` creates a translation table. Here, it's configured to map\n",
    "        # every character in `string.punctuation` to `None`, effectively deleting them.\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        text = text.translate(translator)\n",
    "    \n",
    "    # `strip()` removes any leading or trailing whitespace.\n",
    "    return text.strip()\n",
    "\n",
    "# --- Testing the Preprocessing Function ---\n",
    "sample_text = \"  Hello, World! This is the Gen AI Masters Program.  \"\n",
    "print(f\"Original text: '{sample_text}'\")\n",
    "\n",
    "# Test case 1: Default behavior (lowercase, keep punctuation)\n",
    "processed_default = preprocess_text(sample_text)\n",
    "print(f\"Processed (default): '{processed_default}'\")\n",
    "\n",
    "# Test case 2: Both lowercase and remove punctuation\n",
    "processed_full = preprocess_text(sample_text, remove_punctuation=True)\n",
    "print(f\"Processed (lowercase & no punctuation): '{processed_full}'\")\n",
    "\n",
    "# Test case 3: Keep original case, remove punctuation\n",
    "processed_no_lower = preprocess_text(sample_text, lowercase=False, remove_punctuation=True)\n",
    "print(f\"Processed (no lowercase, no punctuation): '{processed_no_lower}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ebfa6",
   "metadata": {},
   "source": [
    "### Lambda Functions: Small, Anonymous Functions\n",
    "\n",
    "A **lambda function** is a small, anonymous function defined with the `lambda` keyword. It can take any number of arguments but can only have one expression.\n",
    "\n",
    "**Syntax**: `lambda arguments: expression`\n",
    "\n",
    "Lambda functions are syntactically restricted and cannot contain complex statements or annotations. They are best suited for short, one-off operations where a full function definition would be overly verbose.\n",
    "\n",
    "They are particularly useful when working with higher-order functions (functions that take other functions as arguments), such as:\n",
    "-   `map()`: Applies a function to every item of an iterable.\n",
    "-   `filter()`: Creates a new iterable with elements that satisfy a condition.\n",
    "-   `sorted()`: Sorts an iterable, optionally with a custom key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786776fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Lambda for a Simple Calculation ---\n",
    "# This lambda function performs min-max normalization, a common technique in machine learning\n",
    "# to scale features to a fixed range (usually 0 to 1).\n",
    "normalize = lambda x, min_val, max_val: (x - min_val) / (max_val - min_val)\n",
    "\n",
    "scores = [65, 78, 82, 95, 100]\n",
    "min_score, max_score = min(scores), max(scores)\n",
    "\n",
    "# We can use this lambda function directly within a list comprehension for a concise transformation.\n",
    "normalized_scores = [normalize(s, min_score, max_score) for s in scores]\n",
    "print(f\"Original scores: {scores}\")\n",
    "# Using an f-string with formatting to make the output cleaner.\n",
    "print(f\"Normalized scores (0-1): {[f'{s:.2f}' for s in normalized_scores]}\")\n",
    "\n",
    "\n",
    "# --- Using Lambda with `map` and `filter` ---\n",
    "# These built-in functions are powerful when combined with lambdas for data processing.\n",
    "texts = [\"hello world\", \"generative ai is transforming industries\", \"python is a key skill\"]\n",
    "\n",
    "# `map` applies the lambda function to every item in the `texts` list.\n",
    "# `map` returns a map object, so we convert it to a list to see the results.\n",
    "word_counts = list(map(lambda t: len(t.split()), texts))\n",
    "print(f\"\\nWord count of each text: {word_counts}\")\n",
    "\n",
    "# `filter` applies the lambda function to each item and returns only those for which the function returns True.\n",
    "# Like `map`, `filter` returns an iterator, so we convert it to a list.\n",
    "long_texts = list(filter(lambda t: len(t) > 20, texts))\n",
    "print(f\"Texts longer than 20 characters: {long_texts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86b025",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Section 4: Object-Oriented Programming (OOP)\n",
    "\n",
    "**Object-Oriented Programming (OOP)** is a programming paradigm that structures a program around \"objects\" rather than functions and logic. An object is a self-contained unit that combines data (called **attributes**) and behavior that operates on that data (called **methods**).\n",
    "\n",
    "The core principles of OOP are:\n",
    "-   **Encapsulation**: Bundling data and methods that work on that data within one unit (the class).\n",
    "-   **Abstraction**: Hiding the complex implementation details and exposing only the necessary parts of an object.\n",
    "-   **Inheritance**: Allowing a new class (child) to inherit attributes and methods from an existing class (parent).\n",
    "-   **Polymorphism**: Allowing objects of different classes to be treated as objects of a common superclass.\n",
    "\n",
    "In machine learning, classes are essential for creating reusable and organized components, such as:\n",
    "-   **Models**: A `Model` class can encapsulate the model architecture, its weights (attributes), and its forward pass logic (a method).\n",
    "-   **DataLoaders**: A `DataLoader` class can manage a dataset, batching, and preprocessing logic.\n",
    "-   **Training Pipelines**: A `Trainer` class can orchestrate the entire training process, including the training loop, validation, and saving checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b401caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "\n",
    "# --- Using `@dataclass` for Configuration ---\n",
    "# Dataclasses are a modern Python feature (introduced in 3.7) that provide a concise\n",
    "# way to create classes that are primarily used for storing data.\n",
    "# They automatically generate special methods like `__init__`, `__repr__`, and `__eq__`.\n",
    "@dataclass\n",
    "class LLMConfig:\n",
    "    \"\"\"A dataclass to hold the configuration for a Language Model.\"\"\"\n",
    "    name: str\n",
    "    model_id: str\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 1024\n",
    "    top_p: float = 0.9\n",
    "\n",
    "# --- Defining a Class for a Text Generator ---\n",
    "class TextGenerator:\n",
    "    \"\"\"A simple class representing a text generation model.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: LLMConfig):\n",
    "        \"\"\"\n",
    "        Initializes the generator with a given configuration.\n",
    "        The `__init__` method is the constructor for a class.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.history: List[str] = []  # An attribute to store generation history\n",
    "        print(f\"Initialized TextGenerator with model: '{self.config.name}'\")\n",
    "    \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Simulates text generation based on a prompt.\n",
    "        This is a method, a function that belongs to the class.\n",
    "        \"\"\"\n",
    "        print(f\"\\nGenerating response for prompt: '{prompt}'...\")\n",
    "        # In a real-world scenario, this method would contain the logic to call a model's API\n",
    "        # or run a local model to get a response.\n",
    "        response = f\"[{self.config.name}] This is a simulated response to your prompt.\"\n",
    "        self.history.append(prompt)  # Modify the object's state\n",
    "        return response\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clears the generation history.\"\"\"\n",
    "        self.history = []\n",
    "        print(\"\\nGeneration history has been cleared.\")\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Provides a developer-friendly string representation of the object.\n",
    "        This is useful for debugging and logging.\n",
    "        \"\"\"\n",
    "        return f\"TextGenerator(model='{self.config.name}', history_count={len(self.history)})\"\n",
    "\n",
    "# --- Creating and Using an Instance of the Class ---\n",
    "# 1. Create a configuration object using our dataclass.\n",
    "gpt4_config = LLMConfig(name=\"GPT-4 Turbo\", model_id=\"gpt-4-1106-preview\")\n",
    "\n",
    "# 2. Instantiate the TextGenerator class with the configuration object.\n",
    "# This creates an \"object\" or \"instance\" of the class.\n",
    "my_generator = TextGenerator(config=gpt4_config)\n",
    "print(my_generator)  # This calls the __repr__ method\n",
    "\n",
    "# 3. Use the object's methods to perform actions.\n",
    "response1 = my_generator.generate(\"What is Generative AI?\")\n",
    "print(f\"  -> Response: {response1}\")\n",
    "\n",
    "response2 = my_generator.generate(\"How do transformers work?\")\n",
    "print(f\"  -> Response: {response2}\")\n",
    "\n",
    "# 4. Inspect the object's state (its attributes).\n",
    "print(f\"\\nCurrent generator state: {my_generator}\")\n",
    "print(f\"Generation history: {my_generator.history}\")\n",
    "\n",
    "# Dataclasses provide a handy `asdict` function to convert an instance to a dictionary,\n",
    "# which is useful for serialization (e.g., saving to a JSON file).\n",
    "print(f\"Configuration as dictionary: {asdict(gpt4_config)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ce66a",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Section 5: File I/O and Exception Handling\n",
    "\n",
    "**File I/O (Input/Output)** is the process of reading from and writing to files on the file system. This is a daily task in machine learning, whether you're:\n",
    "-   Loading a dataset from a CSV or JSON file.\n",
    "-   Saving a trained model's weights (a \"checkpoint\").\n",
    "-   Writing logs to track the progress of a training run.\n",
    "\n",
    "**Exception Handling** is a critical mechanism for building robust and reliable programs. It allows you to gracefully handle errors that might occur during program execution (e.g., a file not being found, a network error) instead of letting your program crash.\n",
    "\n",
    "The primary tool for this in Python is the **`try...except`** block:\n",
    "-   The **`try`** block contains the code that might raise an error.\n",
    "-   The **`except`** block contains the code that will be executed if a specific error occurs.\n",
    "-   The **`finally`** block contains code that will be executed no matter what, whether an error occurred or not (useful for cleanup operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9701701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Creating a Sample Dataset ---\n",
    "# This dictionary represents a simple dataset we want to save to a file.\n",
    "# This structure is very similar to what you would find in a JSON file.\n",
    "dataset = {\n",
    "    \"metadata\": {\n",
    "        \"name\": \"Instruction Prompts Dataset\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"author\": \"Gen AI Masters Program\",\n",
    "        \"total_samples\": 3\n",
    "    },\n",
    "    \"prompts\": [\n",
    "        {\"id\": \"001\", \"task\": \"summarization\", \"text\": \"Summarize the provided article on climate change.\"},\n",
    "        {\"id\": \"002\", \"task\": \"translation\", \"text\": \"Translate 'Hello, how are you?' to French.\"},\n",
    "        {\"id\": \"003\", \"task\": \"classification\", \"text\": \"Classify this movie review as positive or negative.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Writing to and Reading from a JSON File ---\n",
    "# Using `pathlib.Path` is the modern, object-oriented way to handle file paths.\n",
    "output_file = Path(\"sample_dataset.json\")\n",
    "\n",
    "# The `try...except...finally` block allows us to handle potential errors gracefully.\n",
    "try:\n",
    "    print(f\"--- Writing data to '{output_file}' ---\")\n",
    "    # The `with` statement is a context manager that ensures the file is automatically\n",
    "    # closed, even if errors occur. This is the recommended way to work with files.\n",
    "    with output_file.open('w', encoding='utf-8') as f:\n",
    "        # `json.dump` serializes a Python dictionary into a JSON formatted string and writes it to the file.\n",
    "        # `indent=4` makes the JSON file human-readable.\n",
    "        json.dump(dataset, f, indent=4)\n",
    "    print(f\"âœ… Successfully saved dataset.\")\n",
    "    \n",
    "    print(f\"\\n--- Reading data back from '{output_file}' ---\")\n",
    "    with output_file.open('r', encoding='utf-8') as f:\n",
    "        # `json.load` deserializes a JSON formatted string from a file back into a Python dictionary.\n",
    "        loaded_dataset = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Successfully loaded dataset.\")\n",
    "    print(f\"   - Dataset Name: {loaded_dataset['metadata']['name']}\")\n",
    "    print(f\"   - Number of prompts: {len(loaded_dataset['prompts'])}\")\n",
    "\n",
    "# --- Graceful Error Handling ---\n",
    "# We can catch specific errors to provide more helpful feedback.\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The file '{output_file}' was not found during the read operation.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"âŒ Error: Failed to decode JSON. The file may be corrupted or not in valid JSON format.\")\n",
    "except Exception as e:\n",
    "    # This is a general catch-all for any other unexpected errors.\n",
    "    print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    # The `finally` block is always executed, making it ideal for cleanup tasks\n",
    "    # like closing connections or releasing resources.\n",
    "    print(\"\\nâœ¨ File I/O operations complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d45abb",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Section 6: Python Best Practices for Machine Learning\n",
    "\n",
    "Writing code that is not only correct but also **clean, efficient, and maintainable** is crucial for building robust and scalable ML systems. Adhering to best practices makes your code easier to debug, reuse, and collaborate on.\n",
    "\n",
    "### The Importance of Type Hints and Docstrings\n",
    "\n",
    "As demonstrated in previous examples, clear documentation and type hints are not just \"nice-to-haves\"; they are essential for professional software development.\n",
    "\n",
    "-   **Type Hints**: By specifying the expected data types of function arguments and return values (e.g., `text: str -> List[str]`), you make your code more self-documenting. This also allows static analysis tools and IDEs (like VS Code) to catch potential bugs before you even run the code.\n",
    "-   **Docstrings**: A good docstring explains the \"why\" and \"how\" of a function. It should describe what the function does, what its parameters are, what it returns, and any errors it might raise. This is invaluable for anyone using your code, including your future self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "\n",
    "def calculate_regression_metrics(\n",
    "    y_true: List[float], \n",
    "    y_pred: List[float]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates key regression metrics: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).\n",
    "\n",
    "    This function is a good example of Python best practices:\n",
    "    - Clear type hints for inputs and outputs.\n",
    "    - A comprehensive docstring explaining the function, its arguments, return value, and potential errors.\n",
    "    - An example of usage right in the docstring (which can even be used for automated testing with `doctest`).\n",
    "    - Defensive programming with a check for input validity.\n",
    "\n",
    "    Args:\n",
    "        y_true (List[float]): A list of ground truth target values.\n",
    "        y_pred (List[float]): A list of predicted values from the model.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary containing the calculated MSE and RMSE, \n",
    "                          rounded to four decimal places, along with the sample count.\n",
    "                          \n",
    "    Raises:\n",
    "        ValueError: If the input lists `y_true` and `y_pred` have different lengths.\n",
    "    \n",
    "    Example:\n",
    "        >>> true_values = [1.0, 2.0, 3.0]\n",
    "        >>> pred_values = [1.1, 2.1, 2.9]\n",
    "        >>> metrics = calculate_regression_metrics(true_values, pred_values)\n",
    "        >>> print(f\"MSE: {metrics['mse']:.4f}, RMSE: {metrics['rmse']:.4f}\")\n",
    "        MSE: 0.0100, RMSE: 0.1000\n",
    "    \"\"\"\n",
    "    # Input validation is crucial for robust functions.\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"Input lists `y_true` and `y_pred` must have the same length.\")\n",
    "    \n",
    "    # Using libraries like NumPy for numerical operations is highly recommended.\n",
    "    # NumPy arrays allow for efficient, vectorized calculations that are much faster than Python loops.\n",
    "    y_true_np = np.array(y_true)\n",
    "    y_pred_np = np.array(y_pred)\n",
    "    \n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    # This is the average of the squared differences between the predicted and actual values.\n",
    "    mse = np.mean((y_true_np - y_pred_np) ** 2)\n",
    "    \n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    # This is the square root of the MSE and is often preferred as it is in the same units as the target variable.\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return {\n",
    "        \"mse\": round(mse, 4),\n",
    "        \"rmse\": round(rmse, 4),\n",
    "        \"samples\": len(y_true)\n",
    "    }\n",
    "\n",
    "# --- Test the metrics function ---\n",
    "true_values = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "predicted_values = [1.1, 2.2, 2.9, 4.1, 5.2]\n",
    "\n",
    "try:\n",
    "    metrics = calculate_regression_metrics(true_values, predicted_values)\n",
    "    print(f\"Calculated Regression Metrics: {metrics}\")\n",
    "    \n",
    "    # Test the error handling\n",
    "    print(\"\\n--- Testing error handling with mismatched lengths ---\")\n",
    "    calculate_regression_metrics([1, 2], [1, 2, 3])\n",
    "except ValueError as e:\n",
    "    print(f\"Caught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14461ea",
   "metadata": {},
   "source": [
    "### Advanced Python: Decorators and Context Managers\n",
    "\n",
    "These are more advanced but powerful Python features that you will frequently encounter in ML libraries and frameworks.\n",
    "\n",
    "-   **Decorators**: A decorator is a function that takes another function as an argument and extends its behavior without explicitly modifying it. They are a form of metaprogramming and are heavily used for tasks like:\n",
    "    -   **Logging**: Automatically log when a function is called and what it returns.\n",
    "    -   **Timing**: Measure the execution time of a function.\n",
    "    -   **Caching**: Cache the results of expensive function calls.\n",
    "    -   **Authentication/Authorization**: In web frameworks, decorators are used to check if a user is logged in before allowing them to access an endpoint.\n",
    "\n",
    "-   **Context Managers** (`with` statements): A context manager is an object that defines the methods `__enter__` and `__exit__`. It is used to manage resources by ensuring that setup and teardown operations are always executed. The `with` statement guarantees that the `__exit__` method is called, even if an error occurs within the block. This is crucial for:\n",
    "    -   **File Handling**: Automatically closing files to prevent resource leaks.\n",
    "    -   **Database Connections**: Ensuring a database connection is closed.\n",
    "    -   **Model States**: In PyTorch, a context manager like `torch.no_grad()` is used to temporarily disable gradient calculations during inference, which saves memory and computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d696aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# --- A Decorator for Timing Function Execution ---\n",
    "def timing_decorator(func):\n",
    "    \"\"\"A decorator that prints the execution time of the decorated function.\"\"\"\n",
    "    @wraps(func)  # `@wraps` is a helper decorator that preserves the original function's metadata (like its name and docstring).\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()  # Use perf_counter for high-precision timing\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"â±ï¸  Function '{func.__name__}' executed in {elapsed_time:.4f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# --- Applying the Decorator ---\n",
    "# We apply the decorator to our function using the `@` syntax.\n",
    "# Now, whenever `simulate_data_processing` is called, `timing_decorator` will be executed automatically.\n",
    "@timing_decorator\n",
    "def simulate_data_processing(num_records: int):\n",
    "    \"\"\"A function that simulates a time-consuming data processing task.\"\"\"\n",
    "    print(f\"Processing {num_records:,} records...\")\n",
    "    # A generator expression is used here for memory efficiency.\n",
    "    # It doesn't create a full list in memory.\n",
    "    _ = sum(i * i for i in range(num_records))\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "# Test the decorated function\n",
    "simulate_data_processing(5_000_000)\n",
    "\n",
    "\n",
    "# --- A Context Manager for Model Inference ---\n",
    "# The `@contextmanager` decorator from the `contextlib` module is a convenient way to create a context manager from a simple generator function.\n",
    "@contextmanager\n",
    "def inference_mode(model_name: str):\n",
    "    \"\"\"A context manager to simulate setting up and tearing down a model for inference.\"\"\"\n",
    "    print(f\"\\nðŸ”„ Preparing model '{model_name}' for inference...\")\n",
    "    # Code before the `yield` is the setup phase (like __enter__).\n",
    "    # e.g., loading model weights, setting model to evaluation mode.\n",
    "    try:\n",
    "        yield  # The `yield` keyword passes control back to the `with` block.\n",
    "    finally:\n",
    "        # Code after the `yield` is the teardown phase (like __exit__).\n",
    "        # This code is guaranteed to run, even if errors occur in the `with` block.\n",
    "        print(f\"âœ… Finished inference with '{model_name}'. Cleaning up resources.\")\n",
    "\n",
    "# Use the context manager with a `with` statement.\n",
    "with inference_mode(\"ResNet-50\"):\n",
    "    print(\"   -> Running inference on a batch of images...\")\n",
    "    time.sleep(0.5) # Simulate the work being done.\n",
    "    print(\"   -> Inference successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd9199",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Section 7: Practice Exercises\n",
    "\n",
    "The best way to solidify your understanding is through practice. These exercises are designed to reinforce the concepts covered in this notebook. Try to solve them yourself before looking at the provided solutions.\n",
    "\n",
    "**Goal**: Apply your knowledge of functions, decorators, and classes to solve common programming challenges in the context of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecc832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exercise 1: Text Tokenization Function ---\n",
    "# A common first step in many NLP tasks is tokenization.\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a string into a list of cleaned tokens.\n",
    "    \n",
    "    This function should perform the following steps:\n",
    "    1. Convert the input text to lowercase to ensure consistency.\n",
    "    2. Split the text by whitespace to get a list of potential tokens.\n",
    "    3. Remove any resulting empty strings that might appear from multiple spaces.\n",
    "    \"\"\"\n",
    "    # A list comprehension is a clean and efficient way to implement this.\n",
    "    return [token for token in text.lower().split() if token]\n",
    "\n",
    "# Test Exercise 1\n",
    "text_to_tokenize = \"  This is a sample sentence for tokenization. \"\n",
    "tokens = tokenize_text(text_to_tokenize)\n",
    "print(f\"--- Tokenization Exercise ---\")\n",
    "print(f\"Original: '{text_to_tokenize}'\")\n",
    "print(f\"Tokens: {tokens}\\n\")\n",
    "\n",
    "\n",
    "# --- Exercise 2: Caching Decorator ---\n",
    "# Caching is a powerful optimization technique. This exercise implements a simple version.\n",
    "def simple_cache(func):\n",
    "    \"\"\"A decorator that caches the results of a function based on its arguments.\"\"\"\n",
    "    _cache = {}  # The cache is stored in a dictionary within the decorator's scope.\n",
    "    @wraps(func)\n",
    "    def wrapper(*args):\n",
    "        # The arguments to the function are used as the cache key.\n",
    "        # Since `args` is a tuple, it is hashable and can be used as a dictionary key.\n",
    "        if args in _cache:\n",
    "            print(f\"(Result for {args} found in cache)\")\n",
    "            return _cache[args]\n",
    "        \n",
    "        print(f\"(Calculating result for {args} and caching...)\")\n",
    "        result = func(*args)\n",
    "        _cache[args] = result\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# We can chain decorators. The one closest to the function (`@timing_decorator`) is applied first.\n",
    "@simple_cache\n",
    "@timing_decorator\n",
    "def slow_computation(a: int, b: int) -> int:\n",
    "    \"\"\"A function that simulates a slow computation that we want to cache.\"\"\"\n",
    "    time.sleep(1)  # Simulate a 1-second delay\n",
    "    return a + b\n",
    "\n",
    "print(\"--- Caching Decorator Exercise ---\")\n",
    "# The first call will be slow and will cache the result.\n",
    "slow_computation(5, 10)\n",
    "# The second call with the same arguments should be almost instantaneous and hit the cache.\n",
    "slow_computation(5, 10)\n",
    "# A call with different arguments will be slow again.\n",
    "slow_computation(3, 7)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# --- Exercise 3: Iterable DataLoader Class ---\n",
    "# In ML, data is often processed in batches. This class mimics that behavior.\n",
    "class SimpleDataLoader:\n",
    "    \"\"\"A class that takes a list of data and makes it iterable in batches.\"\"\"\n",
    "    def __init__(self, data: List, batch_size: int):\n",
    "        if not isinstance(batch_size, int) or batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be a positive integer.\")\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of batches. This is a special \"dunder\" method.\n",
    "        The calculation ensures that even a partial final batch is counted.\n",
    "        \"\"\"\n",
    "        return (len(self.data) + self.batch_size - 1) // self.batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        This dunder method makes the object iterable, allowing it to be used in a `for` loop.\n",
    "        It should `yield` one batch at a time.\n",
    "        \"\"\"\n",
    "        for i in range(0, len(self.data), self.batch_size):\n",
    "            yield self.data[i:i + self.batch_size]\n",
    "\n",
    "print(\"--- DataLoader Exercise ---\")\n",
    "my_data = list(range(33))  # A sample dataset of 33 data points\n",
    "data_loader = SimpleDataLoader(my_data, batch_size=8)\n",
    "\n",
    "# Because we implemented __len__, we can call len() on our object.\n",
    "print(f\"Data: {my_data}\")\n",
    "print(f\"Batch Size: {data_loader.batch_size}, Total Batches: {len(data_loader)}\")\n",
    "\n",
    "# Because we implemented __iter__, we can loop over our object directly.\n",
    "print(\"\\nIterating through the data loader:\")\n",
    "for i, batch in enumerate(data_loader):\n",
    "    print(f\"  Batch {i+1}: {batch}\")\n",
    "\n",
    "print(\"\\n\\nâœ… All exercises completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd784e0a",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Summary & Key Takeaways\n",
    "\n",
    "Congratulations on completing this intensive review of essential Python concepts! You have revisited and reinforced the fundamental skills that are absolutely critical for building sophisticated and robust Generative AI applications. A deep understanding of these topics separates a hobbyist from a professional AI engineer.\n",
    "\n",
    "### Core Concepts Mastered:\n",
    "-   **Data Structures**: You are now proficient with lists, dictionaries, sets, and tuples, and you have a clear understanding of when to use each one for maximum efficiency. You can write clean, efficient list and dictionary comprehensions to transform and filter data.\n",
    "-   **Control Flow**: You can confidently use `if/elif/else` statements and `for/while` loops to direct the logic of your programs, from simple decision-making to complex training loops.\n",
    "-   **Functions & Lambdas**: You can write modular, reusable functions with clear type hints and docstrings, making your code more maintainable and easier to debug. You know how and when to use lambda functions for concise, on-the-fly operations.\n",
    "-   **Object-Oriented Programming**: You understand how to structure complex systems using classes and dataclasses, encapsulating data and behavior into logical, reusable units like models, data loaders, and trainers.\n",
    "-   **Pythonic Best Practices**: You can write robust code that handles errors gracefully using `try...except` blocks, manages resources safely with context managers (`with` statements), and leverages advanced features like decorators to add functionality cleanly.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“š Next Steps\n",
    "\n",
    "With your Python foundations solidified, you are now fully prepared to move on to the specialized libraries that form the backbone of data science and machine learning in Python. The skills you've honed in this notebook will be applied in every subsequent module of this program.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <h3>Great job! You're ready for the next step in your AI journey.</h3>\n",
    "    <p>The next notebook in this module will cover <strong>NumPy and Pandas</strong>, the essential libraries for high-performance numerical computing and data manipulation. Get ready to work with large datasets efficiently!</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
