{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43159d39",
   "metadata": {},
   "source": [
    "# 🤖 Notebook 05: Machine Learning with scikit-learn\n",
    "\n",
    "**Week 1-2: Python & ML Foundations**  \n",
    "**Gen AI Masters Program**\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "1. ✅ ML fundamentals and workflow\n",
    "2. ✅ Classification algorithms\n",
    "3. ✅ Regression models\n",
    "4. ✅ Model evaluation metrics\n",
    "5. ✅ Cross-validation and hyperparameter tuning\n",
    "6. ✅ Building a complete ML pipeline\n",
    "\n",
    "**Estimated Time:** 3-4 hours\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Why scikit-learn?\n",
    "\n",
    "scikit-learn is the foundation of classical ML:\n",
    "- 🎯 **Simple API**: Easy to learn and use\n",
    "- 🔧 **Complete Toolkit**: Preprocessing, models, evaluation\n",
    "- 📊 **Industry Standard**: Used in production worldwide\n",
    "- 🚀 **Fast Prototyping**: Test ideas quickly\n",
    "\n",
    "Let's build our first ML models! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed093be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e4299",
   "metadata": {},
   "source": [
    "## 1️⃣ Understanding Machine Learning\n",
    "\n",
    "### ML Workflow\n",
    "\n",
    "```\n",
    "1. Data Collection → 2. Data Preparation → 3. Model Selection\n",
    "                                ↓\n",
    "6. Deployment ← 5. Evaluation ← 4. Training\n",
    "```\n",
    "\n",
    "### Types of ML\n",
    "- **Supervised**: Learn from labeled data (Classification, Regression)\n",
    "- **Unsupervised**: Find patterns in unlabeled data (Clustering)\n",
    "- **Reinforcement**: Learn from rewards/penalties\n",
    "\n",
    "Today we'll focus on **Supervised Learning**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607ef57",
   "metadata": {},
   "source": [
    "## 2️⃣ Classification: Quality Defect Prediction\n",
    "\n",
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39216bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create manufacturing quality dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Features: temperature, pressure, humidity, vibration\n",
    "temperature = np.random.normal(75, 10, n_samples)\n",
    "pressure = np.random.normal(120, 15, n_samples)\n",
    "humidity = np.random.normal(50, 10, n_samples)\n",
    "vibration = np.random.normal(0.5, 0.2, n_samples)\n",
    "\n",
    "# Target: defective (1) or not (0)\n",
    "# Higher temperature, extreme pressure, high vibration → more defects\n",
    "defect_probability = (\n",
    "    0.1 + \n",
    "    0.01 * (temperature - 75) + \n",
    "    0.005 * abs(pressure - 120) + \n",
    "    0.2 * vibration\n",
    ")\n",
    "defect_probability = np.clip(defect_probability, 0, 1)\n",
    "is_defective = (np.random.random(n_samples) < defect_probability).astype(int)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'temperature': temperature,\n",
    "    'pressure': pressure,\n",
    "    'humidity': humidity,\n",
    "    'vibration': vibration,\n",
    "    'is_defective': is_defective\n",
    "})\n",
    "\n",
    "print(\"📊 Manufacturing Quality Dataset\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Defective: {df['is_defective'].sum()} ({df['is_defective'].mean():.1%})\")\n",
    "print(f\"Non-defective: {(1-df['is_defective']).sum()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Class distribution\n",
    "df['is_defective'].value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
    "axes[0].set_title('Class Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Is Defective')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "# Feature relationship\n",
    "for defect in [0, 1]:\n",
    "    mask = df['is_defective'] == defect\n",
    "    axes[1].scatter(df[mask]['temperature'], df[mask]['vibration'], \n",
    "                   label=f'Defective={defect}', alpha=0.6, s=50)\n",
    "axes[1].set_title('Temperature vs Vibration', fontweight='bold')\n",
    "axes[1].set_xlabel('Temperature (°C)')\n",
    "axes[1].set_ylabel('Vibration')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa25bb",
   "metadata": {},
   "source": [
    "### Train-Test Split and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df[['temperature', 'pressure', 'humidity', 'vibration']]\n",
    "y = df['is_defective']\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"📊 Data Split:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nTraining set defect rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test set defect rate: {y_test.mean():.1%}\")\n",
    "\n",
    "# Feature scaling (important for many ML algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✅ Data preprocessed and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c420024",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = log_reg.predict(X_train_scaled)\n",
    "y_pred_test = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"🎯 Logistic Regression Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy: {train_acc:.2%}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2%}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Non-defective', 'Defective']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-defective', 'Defective'],\n",
    "            yticklabels=['Non-defective', 'Defective'])\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d960c6b",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"🌳 Random Forest Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test Accuracy: {rf_acc:.2%}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Non-defective', 'Defective']))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "plt.title('Feature Importance - Random Forest', fontweight='bold')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f8ca5",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"🏆 Model Comparison\")\n",
    "print(\"=\" * 50)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['gold', 'silver', '#CD7F32', 'lightblue', 'lightgreen']\n",
    "sns.barplot(data=results_df, y='Model', x='Accuracy', palette=colors)\n",
    "plt.title('Model Performance Comparison', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Accuracy', fontweight='bold')\n",
    "plt.ylabel('Model', fontweight='bold')\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.axvline(x=0.9, color='red', linestyle='--', label='90% threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a8b69",
   "metadata": {},
   "source": [
    "## 3️⃣ Regression: Production Time Prediction\n",
    "\n",
    "### Create Regression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create production time prediction dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "\n",
    "# Features\n",
    "complexity = np.random.uniform(1, 10, n_samples)\n",
    "material_quality = np.random.uniform(5, 10, n_samples)\n",
    "worker_experience = np.random.uniform(1, 15, n_samples)\n",
    "machine_age = np.random.uniform(0, 20, n_samples)\n",
    "\n",
    "# Target: production time (in minutes)\n",
    "# More complex, older machine, less experience → longer time\n",
    "production_time = (\n",
    "    20 + \n",
    "    5 * complexity + \n",
    "    2 * machine_age - \n",
    "    3 * worker_experience - \n",
    "    1 * material_quality + \n",
    "    np.random.normal(0, 5, n_samples)\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df_reg = pd.DataFrame({\n",
    "    'complexity': complexity,\n",
    "    'material_quality': material_quality,\n",
    "    'worker_experience': worker_experience,\n",
    "    'machine_age': machine_age,\n",
    "    'production_time': production_time\n",
    "})\n",
    "\n",
    "print(\"📊 Production Time Prediction Dataset\")\n",
    "print(df_reg.describe())\n",
    "\n",
    "# Visualize relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "features = ['complexity', 'material_quality', 'worker_experience', 'machine_age']\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    axes[row, col].scatter(df_reg[feature], df_reg['production_time'], alpha=0.6)\n",
    "    axes[row, col].set_xlabel(feature.replace('_', ' ').title(), fontweight='bold')\n",
    "    axes[row, col].set_ylabel('Production Time (min)', fontweight='bold')\n",
    "    axes[row, col].set_title(f'{feature.replace(\"_\", \" \").title()} vs Production Time', \n",
    "                            fontweight='bold')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff43b6",
   "metadata": {},
   "source": [
    "### Train Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare data\n",
    "X_reg = df_reg[['complexity', 'material_quality', 'worker_experience', 'machine_age']]\n",
    "y_reg = df_reg['production_time']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# Train models\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "regression_results = []\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    # Train\n",
    "    model.fit(X_train_reg_scaled, y_train_reg)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train_reg_scaled)\n",
    "    y_pred_test = model.predict(X_test_reg_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = r2_score(y_train_reg, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_reg, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_test))\n",
    "    \n",
    "    regression_results.append({\n",
    "        'Model': name,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'RMSE': test_rmse\n",
    "    })\n",
    "\n",
    "reg_results_df = pd.DataFrame(regression_results).sort_values('Test R²', ascending=False)\n",
    "\n",
    "print(\"📊 Regression Model Comparison\")\n",
    "print(\"=\" * 70)\n",
    "print(reg_results_df.to_string(index=False))\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "best_model = regression_models['Random Forest']\n",
    "y_pred_best = best_model.predict(X_test_reg_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_reg, y_pred_best, alpha=0.6, edgecolors='black')\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Production Time (min)', fontweight='bold')\n",
    "plt.ylabel('Predicted Production Time (min)', fontweight='bold')\n",
    "plt.title('Actual vs Predicted Production Time\\n(Random Forest)', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256baba5",
   "metadata": {},
   "source": [
    "## 4️⃣ Cross-Validation and Hyperparameter Tuning\n",
    "\n",
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"🔄 5-Fold Cross-Validation Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Fold scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.2%}\")\n",
    "print(f\"Std Deviation: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), cv_scores, marker='o', markersize=10, linewidth=2)\n",
    "plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', \n",
    "            label=f'Mean: {cv_scores.mean():.2%}')\n",
    "plt.fill_between(range(1, 6), \n",
    "                 cv_scores.mean() - cv_scores.std(), \n",
    "                 cv_scores.mean() + cv_scores.std(), \n",
    "                 alpha=0.2, color='blue')\n",
    "plt.xlabel('Fold', fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontweight='bold')\n",
    "plt.title('Cross-Validation Scores', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f8a14",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    rf, param_grid, cv=5, scoring='accuracy', \n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "print(\"🔍 Performing Grid Search...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n✅ Grid Search Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.2%}\")\n",
    "\n",
    "# Test best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "best_test_acc = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Test accuracy with best model: {best_test_acc:.2%}\")\n",
    "\n",
    "# Compare with default model\n",
    "default_model = RandomForestClassifier(random_state=42)\n",
    "default_model.fit(X_train_scaled, y_train)\n",
    "y_pred_default = default_model.predict(X_test_scaled)\n",
    "default_acc = accuracy_score(y_test, y_pred_default)\n",
    "\n",
    "print(f\"\\n📊 Comparison:\")\n",
    "print(f\"Default model accuracy: {default_acc:.2%}\")\n",
    "print(f\"Tuned model accuracy: {best_test_acc:.2%}\")\n",
    "print(f\"Improvement: {(best_test_acc - default_acc):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea1f65",
   "metadata": {},
   "source": [
    "## 5️⃣ Complete ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_pipeline = pipeline.predict(X_test)\n",
    "pipeline_acc = accuracy_score(y_test, y_pred_pipeline)\n",
    "\n",
    "print(\"🔧 ML Pipeline Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {pipeline_acc:.2%}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'temperature': [80, 70, 85],\n",
    "    'pressure': [130, 115, 140],\n",
    "    'humidity': [55, 45, 60],\n",
    "    'vibration': [0.8, 0.3, 1.0]\n",
    "})\n",
    "\n",
    "predictions = pipeline.predict(new_data)\n",
    "probabilities = pipeline.predict_proba(new_data)\n",
    "\n",
    "print(\"\\n🔮 Predictions on New Data:\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities), 1):\n",
    "    status = \"DEFECTIVE\" if pred == 1 else \"NON-DEFECTIVE\"\n",
    "    confidence = prob[pred] * 100\n",
    "    print(f\"Sample {i}: {status} (confidence: {confidence:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1d7ba",
   "metadata": {},
   "source": [
    "## 6️⃣ Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "model_filename = 'quality_defect_classifier.pkl'\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(f\"✅ Model saved as {model_filename}\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(f\"✅ Model loaded successfully\")\n",
    "\n",
    "# Test loaded model\n",
    "test_prediction = loaded_model.predict(new_data)\n",
    "print(f\"\\n🔮 Test prediction with loaded model: {test_prediction}\")\n",
    "\n",
    "print(\"\\n💾 Model can now be deployed to production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6db92",
   "metadata": {},
   "source": [
    "## 🎉 Summary\n",
    "\n",
    "Congratulations! You've mastered classical machine learning with scikit-learn!\n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "#### Classification\n",
    "- ✅ Logistic Regression\n",
    "- ✅ Decision Trees & Random Forests\n",
    "- ✅ SVM and KNN\n",
    "- ✅ Model evaluation (accuracy, precision, recall, F1)\n",
    "- ✅ Confusion matrices\n",
    "\n",
    "#### Regression\n",
    "- ✅ Linear, Ridge, and Lasso Regression\n",
    "- ✅ Random Forest Regressor\n",
    "- ✅ Evaluation metrics (R², RMSE, MAE)\n",
    "\n",
    "#### Best Practices\n",
    "- ✅ Train-test split\n",
    "- ✅ Feature scaling\n",
    "- ✅ Cross-validation\n",
    "- ✅ Hyperparameter tuning\n",
    "- ✅ ML pipelines\n",
    "- ✅ Model persistence\n",
    "\n",
    "### ML Workflow Checklist\n",
    "1. ✅ Load and explore data\n",
    "2. ✅ Preprocess and scale features\n",
    "3. ✅ Split into train/test sets\n",
    "4. ✅ Train multiple models\n",
    "5. ✅ Evaluate and compare\n",
    "6. ✅ Tune hyperparameters\n",
    "7. ✅ Create production pipeline\n",
    "8. ✅ Save model for deployment\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 Week 1-2 Complete!\n",
    "\n",
    "You've completed:\n",
    "- ✅ Environment setup\n",
    "- ✅ Python essentials\n",
    "- ✅ NumPy & Pandas\n",
    "- ✅ Data visualization\n",
    "- ✅ Machine learning fundamentals\n",
    "\n",
    "**Next:** Complete the **Week 1-2 Homework** to apply everything you've learned!\n",
    "\n",
    "<div align=\"center\">\n",
    "<b>🎓 Foundation Complete! Ready for Deep Learning! 🚀</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
