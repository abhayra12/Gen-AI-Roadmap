{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f5140c",
   "metadata": {},
   "source": [
    "# 🎯 Week 5-6, Notebook 6: Few-Shot Learning for Actionable Insights\n",
    "\n",
    "**Module:** LLMs, Prompt Engineering & RAG  \n",
    "**Project:** Build the Knowledge Core for the Manufacturing Copilot\n",
    "\n",
    "---\n",
    "\n",
    "Fine-tuning an entire Large Language Model on your custom data is a powerful but often expensive and time-consuming process. **Few-Shot Learning** offers a compelling and highly effective alternative. The core idea is to guide a pre-trained LLM by providing a handful of high-quality examples (`shots`) directly within the prompt itself. This technique, also known as **in-context learning**, allows the model to learn a new task or adapt to a new domain on the fly.\n",
    "\n",
    "In this notebook, we will use few-shot learning to build a system that suggests corrective actions for machine operators based on incident reports. This is a core feature of our Manufacturing Copilot, demonstrating how we can elicit expert-level behavior from a general-purpose model without any changes to its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b98a5",
   "metadata": {},
   "source": [
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1.  **Distinguish Few-Shot from Zero-Shot:** Articulate when and why providing in-context examples is necessary to improve model performance.\n",
    "2.  **Curate High-Quality Exemplars:** Understand the importance of creating a small, clean, and representative dataset of examples (known as exemplars) that reflect real-world problems and solutions.\n",
    "3.  **Automate Example Selection with Semantic Search:** Implement a system that uses semantic similarity to dynamically find the most relevant examples from your dataset for any new, incoming query.\n",
    "4.  **Build and Evaluate a Few-Shot System:** Combine prompt templates, a curated exemplar database, and a semantic retrieval mechanism to generate useful, actionable, and contextually relevant recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe0fda",
   "metadata": {},
   "source": [
    "## ⚙️ Setup: The Model and the Exemplar Dataset\n",
    "\n",
    "We will continue to use the `google/flan-t5-base` model for its excellent balance of performance and resource efficiency.\n",
    "\n",
    "The most critical component of a few-shot learning system is the **exemplar dataset**. This is a small, carefully curated collection of high-quality input-output pairs that represent the task we want the model to perform. For our use case, this will be a set of incident tickets and the corresponding corrective actions taken by experienced engineers. The quality of these exemplars is paramount—garbage in, garbage out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706204d",
   "metadata": {},
   "source": [
    "# Hands-On: Initializing the Model and Creating the Exemplar Dataset\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- Model Initialization ---\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    generator = pipeline(\n",
    "        'text2text-generation',\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device,\n",
    "        max_length=128,  # Corrective actions should be concise\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    print(f\"Pipeline created successfully for model '{model_name}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create pipeline: {e}\")\n",
    "    generator = lambda x: [{\"generated_text\": \"Error: Pipeline not initialized.\"}]\n",
    "\n",
    "\n",
    "# --- Exemplar Dataset Creation ---\n",
    "# This is our curated dataset of high-quality examples. In a real system,\n",
    "# this would be stored in a database or a version-controlled file.\n",
    "exemplars_df = pd.DataFrame([\n",
    "    {\"ticket\": \"Vibration spike on compressor #7 after bearing replacement.\", \"action\": \"Inspect bearing seating and alignment. Re-torque all mounting fasteners to spec.\"},\n",
    "    {\"ticket\": \"Hydraulic leak detected on the main clamp cylinder of Press-3.\", \"action\": \"Immediately isolate the machine using LOTO protocol. Replace the primary rod and piston seals.\"},\n",
    "    {\"ticket\": \"Camera on the main SMT line is misreading 2D barcodes due to glare from overhead lights.\", \"action\": \"Adjust the angle and polarization of the overhead lighting. Recalibrate the vision system's exposure and contrast thresholds.\"},\n",
    "    {\"ticket\": \"The packing line robot #2 is flagging repeated overcurrent alarms on its wrist axis (J5).\", \"action\": \"Verify the robot's payload is within specification. Check for mechanical binding and recalibrate motor torque limits.\"},\n",
    "    {\"ticket\": \"AGV-5 is slowing down and reporting intermittent lidar faults when approaching charging station B.\", \"action\": \"Clean the lidar sensor lens with an approved solution. Check the station's firmware for pending updates.\"}\n",
    "])\n",
    "\n",
    "print(\"\\n--- Curated Exemplar Dataset ---\")\n",
    "exemplars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32964c80",
   "metadata": {},
   "source": [
    "## 🛠️ Part 1: Building a Static Few-Shot Prompt\n",
    "\n",
    "The core idea of few-shot learning is to construct a prompt that includes both the instructions for the task and the high-quality examples. The LLM then uses these examples to understand the desired input-output pattern and applies that pattern to the new query.\n",
    "\n",
    "A well-structured few-shot prompt has three key parts:\n",
    "1.  **Instruction:** A clear, high-level command telling the model what to do.\n",
    "2.  **Exemplars:** A few `input -> output` pairs, formatted consistently.\n",
    "3.  **Query:** The new input for which we want a response, followed by a trigger for the model to start generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Constructing a Few-Shot Prompt\n",
    "def build_few_shot_prompt(examples_df, query):\n",
    "    \"\"\"Constructs a complete few-shot prompt with instructions, examples, and a query.\"\"\"\n",
    "\n",
    "    # 1. The high-level instruction\n",
    "    instruction = \"You are a senior reliability engineer. Based on the incident ticket, recommend a single, concise corrective action for the maintenance team.\"\n",
    "\n",
    "    # 2. The formatted exemplars\n",
    "    exemplar_texts = []\n",
    "    for _, row in examples_df.iterrows():\n",
    "        exemplar_texts.append(f\"Ticket: {row['ticket']}\\nAction: {row['action']}\")\n",
    "\n",
    "    # 3. The new query, formatted to match the exemplars\n",
    "    query_text = f\"Ticket: {query}\\nAction:\"\n",
    "\n",
    "    # Combine all parts with a clear separator\n",
    "    return \"\\n===\\n\".join([instruction] + exemplar_texts + [query_text])\n",
    "\n",
    "# --- Test the prompt construction ---\n",
    "# Let's create a prompt using the first 3 exemplars from our dataset.\n",
    "new_incident_ticket = \"The coolant pump for CNC-12 is showing a gradual pressure drop over the last 3 hours, but there are no visible leaks.\"\n",
    "static_few_shot_prompt = build_few_shot_prompt(exemplars_df.head(3), new_incident_ticket)\n",
    "\n",
    "print(\"--- Generated Static Few-Shot Prompt ---\")\n",
    "print(static_few_shot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4d6a9",
   "metadata": {},
   "source": [
    "# --- Generate a response using the static prompt ---\n",
    "print(\"--- LLM Response (Static Few-Shot) ---\")\n",
    "response = generator(static_few_shot_prompt)\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd286a0",
   "metadata": {},
   "source": [
    "## 🤖 Part 2: Dynamic Exemplar Selection with Semantic Search\n",
    "\n",
    "Manually picking which examples to include in the prompt is not a scalable or effective solution. For a real-world system, we need a way to **automatically find the most relevant examples** for any given ticket. The best examples are those that are semantically similar to the new problem. We can achieve this using **semantic search**.\n",
    "\n",
    "The process is straightforward:\n",
    "1.  **Embed the Knowledge:** Convert all of our high-quality exemplar tickets into numerical vectors (embeddings) using a sentence transformer model. This is a one-time, offline process.\n",
    "2.  **Embed the Query:** When a new ticket arrives, convert its text into an embedding using the same model.\n",
    "3.  **Compare and Select:** Calculate the similarity (typically using cosine similarity) between the new ticket's embedding and all the exemplar embeddings. Select the top-k most similar exemplars.\n",
    "\n",
    "This ensures that the examples provided to the LLM are highly relevant to the problem at hand, dramatically improving the quality of the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Implementing Dynamic Exemplar Selection\n",
    "# We need to install the sentence-transformers library for this step.\n",
    "# In a real project, you would add this to your requirements.txt file.\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer, util\n",
    "except ImportError:\n",
    "    print(\"SentenceTransformers library not found. Installing...\")\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install -q sentence-transformers\n",
    "    from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Step 1: Embed the Exemplar Corpus ---\n",
    "# Use a lightweight but effective model for creating the embeddings.\n",
    "# \"all-MiniLM-L6-v2\" is a great choice for general-purpose semantic search.\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "# This is a one-time process. In a real system, you'd store these embeddings.\n",
    "corpus_embeddings = embedding_model.encode(exemplars_df['ticket'].tolist(), convert_to_tensor=True)\n",
    "print(f\"Successfully created {corpus_embeddings.shape[0]} embeddings of dimension {corpus_embeddings.shape[1]}.\")\n",
    "\n",
    "# --- Step 2: Embed the New Query ---\n",
    "query_embedding = embedding_model.encode(new_incident_ticket, convert_to_tensor=True)\n",
    "\n",
    "# --- Step 3: Find the Most Similar Exemplars ---\n",
    "# Calculate cosine similarity between the query and all corpus embeddings.\n",
    "similarities = util.cos_sim(query_embedding, corpus_embeddings).squeeze()\n",
    "\n",
    "# Add the similarity scores to our dataframe and sort to find the best matches.\n",
    "exemplars_df['similarity'] = similarities.cpu().numpy()\n",
    "retrieved_exemplars_df = exemplars_df.sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "print(f\"\\n--- Most Relevant Exemplars for Query: '{new_incident_ticket}' ---\")\n",
    "retrieved_exemplars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b6170",
   "metadata": {},
   "source": [
    "Now, instead of using static, hardcoded examples, we can build our prompt using the **best examples** found by our semantic search retriever. This makes the prompt highly adaptive and context-aware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c137663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Generating a Response with a Dynamic Prompt\n",
    "# Select the top k most similar exemplars.\n",
    "top_k = 3\n",
    "best_exemplars_df = retrieved_exemplars_df.head(top_k)\n",
    "\n",
    "# Build a new prompt with these dynamically selected, highly relevant examples.\n",
    "dynamic_few_shot_prompt = build_few_shot_prompt(best_exemplars_df, new_incident_ticket)\n",
    "\n",
    "print(\"--- Dynamically Generated Few-Shot Prompt (Top 3 Exemplars) ---\")\n",
    "print(dynamic_few_shot_prompt)\n",
    "\n",
    "# --- Generate the final response ---\n",
    "print(\"\\n--- LLM Response (Dynamic Few-Shot) ---\")\n",
    "dynamic_response = generator(dynamic_few_shot_prompt)\n",
    "print(dynamic_response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083bde8",
   "metadata": {},
   "source": [
    "## ✅ Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the power and elegance of few-shot learning with dynamic exemplar selection. By providing a small number of relevant, high-quality examples directly in the prompt, we can guide a general-purpose LLM to perform a specific, domain-intensive task with impressive accuracy—all without the need for costly fine-tuning.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "-   **Quality Over Quantity:** A few well-chosen, high-quality examples are far more effective than many noisy or irrelevant ones. Your exemplar dataset is a critical asset.\n",
    "-   **Relevance is Key:** Static, hardcoded examples are brittle. A dynamic approach using semantic search to find the most relevant exemplars for any given query is crucial for building a robust and scalable system.\n",
    "-   **A Systemic Approach:** A powerful few-shot learning system is more than just a prompt. It's a combination of a clear prompt template, a curated exemplar database, and an efficient retrieval mechanism working together.\n",
    "\n",
    "In the next notebook, we will explore the fundamentals of **Retrieval-Augmented Generation (RAG)**. RAG takes the retrieval idea a step further, allowing us to fetch information not just from a small set of exemplars, but from a vast knowledge base of documents, such as technical manuals, past incident reports, or safety procedures. This is the final step in building a truly knowledgeable and trustworthy Manufacturing Copilot."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
