{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664791cf",
   "metadata": {},
   "source": [
    "# üßÆ Week 5-6 ¬∑ Notebook 09 ¬∑ Vector Embeddings\n",
    "\n",
    "Understand how embeddings translate manufacturing text into math, evaluate model choices, and wire them into semantic search + RAG pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719738",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Explain how embeddings capture semantics for maintenance, quality, and safety text.\n",
    "- Compare open-source embedding models on manufacturing corpora.\n",
    "- Visualize similarity relationships to spot clusters and outliers.\n",
    "- Persist embeddings in vector stores and optimize search parameters.\n",
    "- Design evaluation harnesses for recall@k, precision, and latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fd0a6",
   "metadata": {},
   "source": [
    "## üß† Concept Recap\n",
    "- Embeddings map text into high-dimensional vectors where proximity ‚âà semantic similarity.\n",
    "- Cosine similarity measures angle similarity; dot product scales with magnitude.\n",
    "- Domain-specific embeddings (e.g., maintenance logs) reduce OOV terminology.\n",
    "- Hybrid search pairs dense vectors with keywords for precision + recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4a4d0",
   "metadata": {},
   "source": [
    "## üè≠ Manufacturing Use Cases\n",
    "| Scenario | Embedding Application |\n",
    "| --- | --- |\n",
    "| Maintenance ticket routing | Match new incidents to historical fixes |\n",
    "| Spare parts search | Map component descriptions to supplier catalogs |\n",
    "| Shift summaries | Cluster similar incidents for reporting |\n",
    "| Quality deviations | Retrieve similar NCRs for containment plans |\n",
    "| EHS knowledge base | Surface relevant policies for incidents |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "samples = pd.DataFrame([\n",
    "    {\"text\": \"Change filter on paint booth every 2 shifts.\", \"label\": \"maintenance\"},\n",
    "    {\"text\": \"Replace hydraulic oil in press 12 quarterly.\", \"label\": \"maintenance\"},\n",
    "    {\"text\": \"Inspect conveyor belt tension weekly.\", \"label\": \"maintenance\"},\n",
    "    {\"text\": \"Calibrate torque wrench before use.\", \"label\": \"quality\"},\n",
    "    {\"text\": \"Supplier shipped incorrect fasteners for line 8.\", \"label\": \"supply\"},\n",
    "    {\"text\": \"Record OEE drop to 71% after unplanned downtime.\", \"label\": \"operations\"},\n",
    "])\n",
    "\n",
    "embeddings = model.encode(samples.text.tolist(), convert_to_tensor=True)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = util.cos_sim(embeddings, embeddings).cpu().numpy()\n",
    "sim_df = pd.DataFrame(similarity_matrix, columns=samples.text, index=samples.text)\n",
    "sim_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46165fd",
   "metadata": {},
   "source": [
    "## üîç Interpreting Similarities\n",
    "- Values close to 1 indicate strong semantic overlap (e.g., maintenance tasks).\n",
    "- Cross-domain pairs (maintenance vs. supply) show lower similarity, helpful for routing.\n",
    "- Use thresholds (e.g., ‚â•0.6) to filter relevant neighbors in retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for (x, y), label in zip(coords, samples.label):\n",
    "    plt.scatter(x, y, label=label)\n",
    "    plt.text(x + 0.02, y + 0.02, label, fontsize=9)\n",
    "plt.title(\"Embedding PCA Projection\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf360dcf",
   "metadata": {},
   "source": [
    "## üß™ Model Comparison Cheatsheet\n",
    "| Model | Dim | Strengths | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| `all-MiniLM-L6-v2` | 384 | Fast, multilingual-lite | Great baseline for prototypes |\n",
    "| `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` | 768 | Multilingual support | Higher latency |\n",
    "| `intfloat/multilingual-e5-large` | 1024 | Strong recall | Needs more memory |\n",
    "| Custom fine-tuned model | varies | Captures plant-specific jargon | Requires labelled pairs |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "store = Chroma.from_texts(samples.text.tolist(), HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "results = store.similarity_search(\"How do we maintain the press?\", k=2)\n",
    "[(r.page_content, r.metadata) for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20800287",
   "metadata": {},
   "source": [
    "## üìè Evaluation Metrics\n",
    "| Metric | Definition | Target |\n",
    "| --- | --- | --- |\n",
    "| Recall@k | % of relevant docs in top-k | ‚â• 0.85 |\n",
    "| MRR | Mean reciprocal rank | ‚â• 0.75 |\n",
    "| Latency | Average retrieval time | < 200 ms |\n",
    "| Memory footprint | Model + index size | Fits GPU/CPU budget |\n",
    "| Drift | Cosine distance shift over time | < 10% monthly |\n",
    "\n",
    "Log these metrics per deployment to build confidence in retrieval performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aaa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = pd.DataFrame([\n",
    "    {\"question\": \"When do we change hydraulic oil?\", \"relevant\": samples.text[1]},\n",
    "    {\"question\": \"What is daily vision maintenance?\", \"relevant\": samples.text[2]},\n",
    "])\n",
    "\n",
    "def recall_at_k(question: str, relevant: str, k: int = 3) -> float:\n",
    "    hits = store.similarity_search(question, k=k)\n",
    "    return 1.0 if any(hit.page_content == relevant for hit in hits) else 0.0\n",
    "\n",
    "eval_questions[\"recall@3\"] = eval_questions.apply(lambda row: recall_at_k(row.question, row.relevant), axis=1)\n",
    "eval_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea964f4b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Best Practices\n",
    "- Normalize text (units, casing) before embedding to reduce noise.\n",
    "- Store metadata like equipment type, shift, language for filtered search.\n",
    "- Periodically re-embed documents after SOP updates.\n",
    "- Version embedding models and vector indexes.\n",
    "- Combine dense + keyword filters for high-precision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a7c3f",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Collect 200 historical tickets and preprocess (normalization, unit expansion).\n",
    "2. Benchmark at least three embedding models for recall@5 and latency.\n",
    "3. Visualize clusters (PCA/UMAP) and highlight edge cases.\n",
    "4. Document hardware requirements and cost for production deployment.\n",
    "5. Publish evaluation report + recommendations for the RAG team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbde9ac",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Embedding model selected and documented\n",
    "- [ ] Preprocessing pipeline implemented\n",
    "- [ ] Evaluation metrics computed and logged\n",
    "- [ ] Vector store integration tested\n",
    "- [ ] Governance plan for re-embedding schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94b4f0",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- SentenceTransformers documentation\n",
    "- FAISS cookbook\n",
    "- *Evaluating Embeddings in Industrial NLP* (2024)\n",
    "- Week 08 RAG Implementation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680aa27",
   "metadata": {},
   "source": [
    "## Embedding Stores\n",
    "- **Chroma / FAISS**: prototypes and small-scale deployments.\n",
    "- **Milvus / Pinecone**: scalable, managed options.\n",
    "- **Elasticsearch / OpenSearch**: hybrid dense + keyword search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a955604",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Benchmark three embedding models on your maintenance FAQ set. Compare recall@5 and latency."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
