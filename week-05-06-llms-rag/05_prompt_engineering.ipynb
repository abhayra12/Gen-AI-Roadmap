{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d987fc9",
   "metadata": {},
   "source": [
    "# üéõÔ∏è Week 5-6 ¬∑ Notebook 05 ¬∑ Prompt Engineering for Manufacturing\n",
    "\n",
    "Design prompts that coax large language models into reliable copilots for maintenance, quality, and operations teams. We'll blend personas, structure, and evaluation to drive consistent responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ed99f",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Choose the right prompt pattern (zero-shot, few-shot, chain-of-thought) for manufacturing tasks.\n",
    "- Layer roles, constraints, and structured outputs to reduce hallucinations.\n",
    "- Build reusable prompt templates for maintenance tickets, safety briefings, and supplier outreach.\n",
    "- Establish an evaluation loop that scores prompt variants for accuracy, tone, and compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06dce4c",
   "metadata": {},
   "source": [
    "## üè≠ Common Prompt Scenarios\n",
    "| Use Case | Stakeholder | Example Input | Desired Output |\n",
    "| --- | --- | --- | --- |\n",
    "| Maintenance triage | Reliability engineer | \"Robot arm stalled during sealant dispense\" | Root cause summary + next actions |\n",
    "| Safety alert rewrite | EHS officer | Raw incident log | 3 bullet safety briefing |\n",
    "| Supplier clarification | Procurement | Mixed-language email thread | Formal bilingual response |\n",
    "| Executive summary | Plant manager | Shift report paragraphs | 150-word highlights with KPIs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455aa6e",
   "metadata": {},
   "source": [
    "## üß± Prompt Building Blocks\n",
    "1. **Persona & role** ‚Äì \"You are a senior controls engineer‚Ä¶\"\n",
    "2. **Task definition** ‚Äì specify format, depth, and tone.\n",
    "3. **Context payload** ‚Äì include machine IDs, timestamps, KPI targets.\n",
    "4. **Constraints & guardrails** ‚Äì safety-first, cite data, respond bilingually.\n",
    "5. **Output schema** ‚Äì bullet list, JSON, table, or Markdown summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831447e",
   "metadata": {},
   "source": [
    "## üß™ Prompt Pattern Matrix\n",
    "| Pattern | When to use | Manufacturing Example | Tips |\n",
    "| --- | --- | --- | --- |\n",
    "| Zero-shot | Quick triage with limited data | Classify ticket severity | Add explicit labels to reduce drift |\n",
    "| One-shot | Mixed language or niche jargon | Supplier email translation | Include bilingual exemplar |\n",
    "| Few-shot | High accuracy routing | Maintenance tickets labelled by experts | Curate edge-case examples |\n",
    "| Chain-of-thought | Root cause analysis | Failure analysis from logs | Request \"Reasoning\" + \"Answer\" sections |\n",
    "| ReAct / Toolformer | When external tools needed | Retrieve SOP snippet before response | Provide placeholder for search results |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use an instruction-tuned model; swap with in-house deployment in production\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/falcon-7b-instruct\",\n",
    "    max_new_tokens=160,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "incident = {\n",
    "    \"context\": \"Robot arm stalled during sealant dispense causing 45 seconds downtime.\",\n",
    "    \"telemetry\": \"Torque exceeded 140 Nm at time of stall; axis-2 temperature +18C\",\n",
    "}\n",
    "\n",
    "prompt_zero = f\"Summarize the root cause of this incident: {incident['context']}\"\n",
    "\n",
    "prompt_structured = f\"\"\"\n",
    "You are a reliability engineer. Respond in JSON with keys: root_cause, immediate_actions, follow_up.\n",
    "Context: {incident['context']}\n",
    "Telemetry: {incident['telemetry']}\n",
    "Safety constraints: reference lockout-tagout if needed.\n",
    "\"\"\".strip()\n",
    "\n",
    "for label, prompt in {\"zero_shot\": prompt_zero, \"structured\": prompt_structured}.items():\n",
    "    print(f\"\\n--- {label} ---\")\n",
    "    output = generator(prompt)[0][\"generated_text\"]\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10eb401",
   "metadata": {},
   "source": [
    "## ‚úÖ Prompt Quality Checklist\n",
    "- **Role clarity:** state expertise level, safety obligations, language requirements.\n",
    "- **Context sufficiency:** include machine IDs, time ranges, KPIs, and relevant SOP IDs.\n",
    "- **Output contract:** define tokens like JSON keys or bullet count to simplify automation.\n",
    "- **Guardrails:** ban speculation, cite data source, escalate safety-critical findings.\n",
    "- **Evaluation hook:** ask the model to self-rate confidence or list assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5913f92",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Template Library\n",
    "```text\n",
    "You are a manufacturing reliability assistant. Respond in 3 bullet points.\n",
    "Context: {context}\n",
    "Task: {task}\n",
    "Constraints: {constraints}\n",
    "```\n",
    "\n",
    "```text\n",
    "You are an EHS officer. Draft a safety briefing in English and Spanish.\n",
    "Incident: {incident}\n",
    "Audience: Shift supervisors\n",
    "Include: root cause, PPE reminder, next inspection date\n",
    "```\n",
    "\n",
    "```text\n",
    "You are a supplier liaison. Reply in polite email format.\n",
    "Thread summary: {summary}\n",
    "Clarify: {questions}\n",
    "Tone: Professional, appreciative\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbda4b",
   "metadata": {},
   "source": [
    "## üìä Prompt Evaluation Framework\n",
    "| Criterion | Metric | Tooling |\n",
    "| --- | --- | --- |\n",
    "| Accuracy | Exact match / semantic similarity | Azure/OpenAI evals, internal scoring scripts |\n",
    "| Safety | Policy violations, hallucinated steps | Red-teaming checklists |\n",
    "| Tone | Sentiment / formality | Heuristic checks, embedding similarity |\n",
    "| Latency | Tokens generated vs. budget | Prompt length analyzer |\n",
    "| Cost | Tokens √ó price | Billing dashboard |\n",
    "\n",
    "Track metrics in an experiment log (see homework) and promote only prompts that pass thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82059be",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Prompt Anti-Patterns\n",
    "- Stuffing raw logs without structure (causes truncation & confusion).\n",
    "- Asking for \"any other thoughts\" when compliance matters.\n",
    "- Mixing multiple tasks (classification + translation) in one request.\n",
    "- Omitting negative examples for sensitive classifications.\n",
    "- Forgetting to reset context between batch runs (carry-over risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae67f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiments = pd.DataFrame([\n",
    "    {\n",
    "        \"prompt_name\": \"maintenance_structured_v1\",\n",
    "        \"pattern\": \"structured\",\n",
    "        \"accuracy\": 0.82,\n",
    "        \"safety_flags\": 0,\n",
    "        \"avg_latency_ms\": 780,\n",
    "    },\n",
    "    {\n",
    "        \"prompt_name\": \"maintenance_structured_v2\",\n",
    "        \"pattern\": \"structured\",\n",
    "        \"accuracy\": 0.89,\n",
    "        \"safety_flags\": 0,\n",
    "        \"avg_latency_ms\": 840,\n",
    "    },\n",
    "    {\n",
    "        \"prompt_name\": \"maintenance_zero_shot\",\n",
    "        \"pattern\": \"zero-shot\",\n",
    "        \"accuracy\": 0.64,\n",
    "        \"safety_flags\": 1,\n",
    "        \"avg_latency_ms\": 620,\n",
    "    },\n",
    "])\n",
    "\n",
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2917b",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Select two manufacturing workflows (e.g., maintenance triage, supplier email).\n",
    "2. Draft at least three prompt variants per workflow (zero-shot, few-shot, structured JSON).\n",
    "3. Run through 20 historical examples and log metrics in the experiment tracker.\n",
    "4. Present the winning prompt with evidence, risks, and fallback plan to stakeholders.\n",
    "5. Archive prompts and evaluation scores in the shared prompt registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09cba2",
   "metadata": {},
   "source": [
    "## üöÄ Deployment Tips\n",
    "- Version prompts alongside model releases; annotate with changelog.\n",
    "- Implement automated linting to catch missing constraints or schema drift.\n",
    "- Pair prompts with guardrail policies (content filters, refusal handling).\n",
    "- Monitor live metrics (accuracy, deflection rate, escalation volume) after rollout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e619f",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Prompt templates captured with personas and constraints\n",
    "- [ ] Metrics logged for accuracy, tone, safety, latency\n",
    "- [ ] Winning prompts approved by EHS/IT stakeholders\n",
    "- [ ] Rollback prompt defined and tested\n",
    "- [ ] Prompts stored in version-controlled registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081dafc5",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- Prompt Engineering Guide (PromptingGuide.ai)\n",
    "- Manufacturing Prompt Patterns Playbook (2025)\n",
    "- OpenAI Guidance on Structured Outputs (2024)\n",
    "- Week 06 Homework rubric (see `HOMEWORK.md`)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
