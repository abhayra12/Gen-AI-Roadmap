{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56ce008",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Week 5-6 ¬∑ Notebook 08 ¬∑ RAG Implementation Walkthrough\n",
    "\n",
    "Build an end-to-end retrieval-augmented assistant for manufacturing maintenance knowledge using open-source tooling. We'll cover ingestion, chunking, embeddings, retrieval, grounded generation, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4dbc3",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Configure LangChain/Chroma primitives for chunking and vector search.\n",
    "- Compose prompts that bind retrieved evidence with safety-conscious instructions.\n",
    "- Evaluate retrieval + generation quality with manufacturing-specific metrics.\n",
    "- Capture observability data (latency, citations, feedback) for continuous improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3e198",
   "metadata": {},
   "source": [
    "## üîÑ Pipeline Overview\n",
    "| Stage | Tooling | Key Decisions |\n",
    "| --- | --- | --- |\n",
    "| Ingest | File loaders / APIs | Metadata schema, access control |\n",
    "| Chunk | `RecursiveCharacterTextSplitter` | Chunk size, overlap, separators |\n",
    "| Embed | `sentence-transformers` | Model choice, normalization |\n",
    "| Index | `Chroma`, `FAISS`, `PGVector` | Persistence, replication |\n",
    "| Retrieve | Similarity search + re-rank | k value, filters |\n",
    "| Generate | HF pipeline / Azure OpenAI | Prompt template, temperature |\n",
    "| Evaluate | Custom harness | Accuracy, citation, latency |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2819158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "maintenance_docs = pd.DataFrame([\n",
    "    {\n",
    "        \"doc_id\": \"press_maintenance.txt\",\n",
    "        \"text\": \"Inspect ram alignment weekly. Replace hydraulic oil every 2000 hours. Verify lockout-tagout steps before servicing.\",\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"conveyor_ops.txt\",\n",
    "        \"text\": \"Monitor belt tension, adjust idlers quarterly, calibrate speed sensors after major maintenance.\",\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"vision_sop.txt\",\n",
    "        \"text\": \"Clean lenses daily, check lighting uniformity, rerun baseline calibration monthly for the vision system.\",\n",
    "    },\n",
    "])\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40, separators=[\"\\n\\n\", \". \", \" \"])\n",
    "records = []\n",
    "for _, row in maintenance_docs.iterrows():\n",
    "    for chunk in splitter.split_text(row.text):\n",
    "        records.append({\"source\": row.doc_id, \"text\": chunk})\n",
    "\n",
    "chunks = pd.DataFrame(records)\n",
    "chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=chunks.text.tolist(),\n",
    "    embedding=embedding_fn,\n",
    "    metadatas=chunks.drop(columns=\"text\").to_dict(orient=\"records\"),\n",
    ")\n",
    "\n",
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 3):\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"source\": [doc.metadata[\"source\"] for doc in docs],\n",
    "            \"snippet\": [doc.page_content for doc in docs],\n",
    "            \"score\": [round(doc.metadata.get(\"distance\", 0.0), 3) if \"distance\" in doc.metadata else None],\n",
    "        }\n",
    "    )\n",
    "\n",
    "query = \"How often should hydraulic oil be replaced?\"\n",
    "retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/falcon-7b-instruct\",\n",
    "    max_new_tokens=160,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "retrieved_df = retrieve(query)\n",
    "\n",
    "context = \"\\n\".join(\n",
    "    f\"Source: {row.source}\\n{row.snippet}\" for _, row in retrieved_df.iterrows()\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "SYSTEM: You are a manufacturing maintenance assistant. Use only the context provided. Cite sources at the end of each sentence.\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "RESPONSE:\n",
    "\"\"\".strip()\n",
    "\n",
    "rag_answer = generator(prompt)[0][\"generated_text\"]\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d13018",
   "metadata": {},
   "source": [
    "## üìä Retrieval Quality Checks\n",
    "- Inspect top-k snippets for relevance and diversity.\n",
    "- Track coverage of metadata (machine, shift, language) in retrieved results.\n",
    "- Evaluate recall@k against a labelled question set.\n",
    "- Compare similarity scores before/after domain-specific embedding fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de00d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = pd.DataFrame([\n",
    "    {\n",
    "        \"question\": \"How often should hydraulic oil be replaced?\",\n",
    "        \"expected\": \"Replace hydraulic oil every 2000 hours.\",\n",
    "        \"answer\": rag_answer,\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the daily task for vision systems?\",\n",
    "        \"expected\": \"Clean lenses daily and check lighting uniformity.\",\n",
    "        \"answer\": None,\n",
    "    },\n",
    "])\n",
    "\n",
    "evaluation_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48eb5c",
   "metadata": {},
   "source": [
    "## üìà Generation Evaluation\n",
    "- Manual SME review for accuracy and completeness.\n",
    "- Automated semantic similarity between answer and expected references.\n",
    "- Citation check: ensure each sentence references a source.\n",
    "- Latency tracking: retrieval time + generation time.\n",
    "- Cost tracking: total tokens consumed per query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d9f8c",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Guardrails & Observability\n",
    "- Implement response validators (safety keywords, prohibited actions).\n",
    "- Log retrieval hits, scores, and prompt tokens to telemetry store.\n",
    "- Use circuit breakers for low-confidence responses (fallback to human).\n",
    "- Monitor vector store growth and stale document ratios.\n",
    "- Version prompts, embeddings, and LLM checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "observability = pd.DataFrame([\n",
    "    {\"query\": query, \"tokens_prompt\": len(prompt.split()), \"retrieval_ms\": 120, \"generation_ms\": 850, \"citations\": len(retrieved_df)},\n",
    "])\n",
    "observability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd8331",
   "metadata": {},
   "source": [
    "## üöÄ Deployment Notes\n",
    "- Containerize the retriever + generator with health checks.\n",
    "- Use asynchronous workers for retrieval to keep generation responsive.\n",
    "- Cache embeddings and prompts for frequent queries (e.g., daily checks).\n",
    "- Implement blue/green rollout when updating vector stores or prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da24be",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Ingest at least five documents per equipment family and persist the vector store to disk.\n",
    "2. Run evaluation on 40 curated questions (mix of easy/hard) and log accuracy, latency, citations.\n",
    "3. Add guardrails for safety keywords and test against red-team prompts.\n",
    "4. Produce a deployment checklist (infra, security, monitoring) for plant leadership."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834646bd",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Documents ingested with metadata schema\n",
    "- [ ] Vector store persisted and secured\n",
    "- [ ] Prompt template includes citations + safety reminders\n",
    "- [ ] Evaluation metrics logged and reviewed\n",
    "- [ ] Monitoring dashboard configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7857837",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- LangChain documentation (text splitters, retrievers)\n",
    "- Chroma DB operations guide\n",
    "- Falcon-7B Instruct card\n",
    "- Week 07 RAG Foundations notebook"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
