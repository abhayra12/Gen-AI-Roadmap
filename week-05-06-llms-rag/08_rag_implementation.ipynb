{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56ce008",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Week 5-6 ¬∑ Notebook 08 ¬∑ RAG Implementation Walkthrough\n",
    "\n",
    "Build an end-to-end retrieval-augmented assistant for manufacturing maintenance knowledge using open-source tooling. We'll cover ingestion, chunking, embeddings, retrieval, grounded generation, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4dbc3",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Configure LangChain/Chroma primitives for chunking and vector search.\n",
    "- Compose prompts that bind retrieved evidence with safety-conscious instructions.\n",
    "- Evaluate retrieval + generation quality with manufacturing-specific metrics.\n",
    "- Capture observability data (latency, citations, feedback) for continuous improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3e198",
   "metadata": {},
   "source": [
    "## üîÑ Pipeline Overview\n",
    "| Stage | Tooling | Key Decisions |\n",
    "| --- | --- | --- |\n",
    "| Ingest | File loaders / APIs | Metadata schema, access control |\n",
    "| Chunk | `RecursiveCharacterTextSplitter` | Chunk size, overlap, separators |\n",
    "| Embed | `sentence-transformers` | Model choice, normalization |\n",
    "| Index | `Chroma`, `FAISS`, `PGVector` | Persistence, replication |\n",
    "| Retrieve | Similarity search + re-rank | k value, filters |\n",
    "| Generate | HF pipeline / Azure OpenAI | Prompt template, temperature |\n",
    "| Evaluate | Custom harness | Accuracy, citation, latency |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2819158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "maintenance_docs = pd.DataFrame([\n",
    "    {\n",
    "        \"doc_id\": \"press_maintenance.txt\",\n",
    "        \"text\": \"Inspect ram alignment weekly. Replace hydraulic oil every 2000 hours. Verify lockout-tagout steps before servicing.\",\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"conveyor_ops.txt\",\n",
    "        \"text\": \"Monitor belt tension, adjust idlers quarterly, calibrate speed sensors after major maintenance.\",\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": \"vision_sop.txt\",\n",
    "        \"text\": \"Clean lenses daily, check lighting uniformity, rerun baseline calibration monthly for the vision system.\",\n",
    "    },\n",
    "])\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40, separators=[\"\\n\\n\", \". \", \" \"])\n",
    "records = []\n",
    "for _, row in maintenance_docs.iterrows():\n",
    "    for chunk in splitter.split_text(row.text):\n",
    "        records.append({\"source\": row.doc_id, \"text\": chunk})\n",
    "\n",
    "chunks = pd.DataFrame(records)\n",
    "chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=chunks.text.tolist(),\n",
    "    embedding=embedding_fn,\n",
    "    metadatas=chunks.drop(columns=\"text\").to_dict(orient=\"records\"),\n",
    ")\n",
    "\n",
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 3):\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"source\": [doc.metadata[\"source\"] for doc in docs],\n",
    "            \"snippet\": [doc.page_content for doc in docs],\n",
    "            \"score\": [round(doc.metadata.get(\"distance\", 0.0), 3) if \"distance\" in doc.metadata else None],\n",
    "        }\n",
    "    )\n",
    "\n",
    "query = \"How often should hydraulic oil be replaced?\"\n",
    "retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/falcon-7b-instruct\",\n",
    "    max_new_tokens=160,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "retrieved_df = retrieve(query)\n",
    "\n",
    "context = \"\\n\".join(\n",
    "    f\"Source: {row.source}\\n{row.snippet}\" for _, row in retrieved_df.iterrows()\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "SYSTEM: You are a manufacturing maintenance assistant. Use only the context provided. Cite sources at the end of each sentence.\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "RESPONSE:\n",
    "\"\"\".strip()\n",
    "\n",
    "rag_answer = generator(prompt)[0][\"generated_text\"]\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d13018",
   "metadata": {},
   "source": [
    "## üìä Retrieval Quality Checks\n",
    "- Inspect top-k snippets for relevance and diversity.\n",
    "- Track coverage of metadata (machine, shift, language) in retrieved results.\n",
    "- Evaluate recall@k against a labelled question set.\n",
    "- Compare similarity scores before/after domain-specific embedding fine-tuning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
