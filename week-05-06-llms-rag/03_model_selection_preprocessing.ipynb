{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dc64de",
   "metadata": {},
   "source": [
    "# Notebook 03 ¬∑ Model Selection & Preprocessing\n",
    "\n",
    "Choose the right model, tokenizer, and preprocessing steps for downstream manufacturing NLP projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115f21a",
   "metadata": {},
   "source": [
    "## Selection Framework\n",
    "1. **Business objective**: root cause summarization vs. ticket routing\n",
    "2. **Data sensitivity**: bring model on-premise if logs contain IP\n",
    "3. **Latency budget**: edge analytics vs. cloud batch jobs\n",
    "4. **Multilingual needs**: supplier documentation often bilingual\n",
    "5. **Tuning appetite**: zero-shot vs. fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "candidate = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(candidate)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(candidate)\n",
    "\n",
    "sample = \"Line 4 packaging robot stopped due to torque sensor fault.\"\n",
    "inputs = tokenizer(sample, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d5950",
   "metadata": {},
   "source": [
    "## Tokenizer Deep Dive\n",
    "`AutoTokenizer` abstracts vocabulary, normalization, and pre-tokenization logic. Inspect tokens to understand truncation and special tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee117e1",
   "metadata": {},
   "source": [
    "## üéØ Outcomes\n",
    "- Build a scoring rubric for candidate models and tokenizers.\n",
    "- Perform dataset profiling to anticipate context window requirements.\n",
    "- Implement normalization, redaction, and chunking strategies for plant data.\n",
    "- Design post-processing for actionable insights and audit trails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720d8de",
   "metadata": {},
   "source": [
    "## üîç Data Landscape Snapshot\n",
    "| Source | Format | Typical Length | Sensitivities |\n",
    "| --- | --- | --- | --- |\n",
    "| Shift reports | Plain text | 1-3k tokens | Operational KPIs |\n",
    "| Maintenance tickets | Semi-structured | 80-200 tokens | Machine IDs, operators |\n",
    "| SOP manuals | PDF/DOCX | 5k-100k tokens | Compliance-critical |\n",
    "| Sensor anomalies | CSV/JSON | 50-200 rows | Real-time streaming |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb0786",
   "metadata": {},
   "source": [
    "## üßÆ Model Selection Rubric\n",
    "| Factor | Question | Weight | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| Accuracy | Does the model understand manufacturing jargon? | 30% | Evaluate on curated validation set |\n",
    "| Latency | Can it respond < 700 ms per request? | 20% | Edge vs. cloud |\n",
    "| Context window | Do tickets exceed default length? | 15% | Longformer vs. standard |\n",
    "| Privacy | Can data leave the facility? | 15% | On-prem models preferred if no |\n",
    "| Cost | Is licensing/OPEX acceptable? | 10% | Consider API pricing tiers |\n",
    "| Maintainability | Do we have talent to fine-tune? | 10% | Evaluate team skillset |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rubric = pd.DataFrame([\n",
    "weights = {'accuracy': 0.3, 'latency': 0.2, 'context': 0.15, 'privacy': 0.15, 'cost': 0.1, 'maintainability': 0.1}\n",
    "rubric['score'] = rubric.apply(lambda row: sum(row[col] * weight for col, weight in weights.items()), axis=1)\n",
    "rubric.sort_values('score', ascending=False)\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    ",\n",
    " \n",
    ": \n",
    ",\n",
    ": null,\n",
    ": {\n",
    ": \n",
    "\n",
    ": [],\n",
    ": [\n",
    ",\n",
    ",\n",
    ",\n",
    "92\n",
    ",\n",
    "2150\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d855620",
   "metadata": {},
   "source": [
    "- WordPiece splits units like `psi` cleanly, while GPT-2 BPE may fragment them.\n",
    "- For domain-specific acronyms (OEE, SPC), consider training a custom tokenizer (see Notebook 04)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4436f6",
   "metadata": {},
   "source": [
    "## üß™ Context Window Stress Test\n",
    "Estimate token lengths before selecting model context size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "long_log = '\n",
    "'.join([\n",
    "tok = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "length = len(tok(long_log)['input_ids'])\n",
    "print('Token length:', length)\n",
    "print('Fits in 512 context:', length <= 512)\n",
    "print('Fits in 4096 context:', length <= 4096)\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    ",\n",
    "1\n",
    ",\n",
    ",\n",
    ",\n",
    "\n",
    ": \n",
    ",\n",
    ": null,\n",
    ": {\n",
    ": \n",
    "\n",
    ": [],\n",
    ": [\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "92\n",
    "2150\n",
    "\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    "2\n",
    ",\n",
    "\n",
    "2\n",
    " \n",
    ": \n",
    ",\n",
    ": null,\n",
    ": {\n",
    ": \n",
    "\n",
    ": [],\n",
    ": [\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "7\n",
    "\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    "3\n",
    ",\n",
    " \n",
    ": \n",
    ",\n",
    ": null,\n",
    ": {\n",
    ": \n",
    "\n",
    ": [],\n",
    ": ["
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4be0d",
   "metadata": {},
   "source": [
    "## üì§ Post-processing\n",
    "After inference, translate logits into actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n",
    "ticket = 'Compressor 7 vibration exceeded 12 mm/s despite recent bearing change.'\n",
    "inputs = tok(ticket, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "probabilities = F.softmax(logits, dim=-1).squeeze().tolist()\n",
    "labels = ['normal', 'maintenance', 'safety']\n",
    "classified = dict(zip(labels, [round(p, 3) for p in probabilities]))\n",
    "classified\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    ",\n",
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ceab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e06a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
