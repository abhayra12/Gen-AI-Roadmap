{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b78187",
   "metadata": {},
   "source": [
    "# 🧰 Week 5-6, Notebook 2: A Deep Dive into Hugging Face Pipelines\n",
    "\n",
    "**Module:** LLMs, Prompt Engineering & RAG  \n",
    "**Project:** Build the Knowledge Core for the Manufacturing Copilot\n",
    "\n",
    "---\n",
    "\n",
    "In the previous notebook, we introduced the core concepts of Large Language Models. Now, it's time to get hands-on and explore the easiest way to use them: the Hugging Face `pipeline` function.\n",
    "\n",
    "**What is a Pipeline?**\n",
    "\n",
    "A pipeline is a high-level, easy-to-use API that handles all the complexity of model loading, tokenization, inference, and decoding for a specific task. Instead of writing dozens of lines of code to set up a model, you can often achieve your goal in just a few lines with a pipeline.\n",
    "\n",
    "This notebook provides a practical, manufacturing-focused tour of the most important pipelines, framing each one as a tool to solve a real-world problem for our **Manufacturing Copilot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3a251",
   "metadata": {},
   "source": [
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1.  **Map Scenarios to Pipelines:** Identify the correct Hugging Face pipeline for common NLP tasks like summarization, translation, and classification.\n",
    "2.  **Customize Pipeline Behavior:** Control model selection, batch processing, and hardware allocation (CPU/GPU) to optimize for speed or accuracy.\n",
    "3.  **Chain Pipelines:** Combine multiple pipelines to create sophisticated workflows (e.g., translate a document, then summarize it).\n",
    "4.  **Integrate with Applications:** Understand the data structures (inputs and outputs) for each pipeline, enabling you to integrate them into your own Python applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6038c",
   "metadata": {},
   "source": [
    "## 🏭 The Right Tool for the Job: A Manufacturing Pipeline Selector\n",
    "\n",
    "The Hugging Face Hub hosts tens of thousands of models, each specialized for different tasks. The `pipeline` function automatically selects a reasonable default model for a given task, but you can easily override it. Here’s a guide to the most useful pipelines for our manufacturing context.\n",
    "\n",
    "| Manufacturing Goal | Recommended Pipeline | Example Use Case |\n",
    "| :--- | :--- | :--- |\n",
    "| **Gauge Operator Sentiment** | `sentiment-analysis` | Analyze logbook entry: 'Shift B reported a strong chemical odor near CNC-7.' |\n",
    "| **Summarize Shift Logs** | `summarization` | Condense a multi-paragraph shift handover report into key bullet points. |\n",
    "| **Translate Supplier Notices** | `translation` | Translate a German safety bulletin for a new piece of equipment into English. |\n",
    "| **Retrieve SOP Steps** | `question-answering` | Find the correct torque specification from a 500-page maintenance manual. |\n",
    "| **Draft Downtime Reports** | `text-generation` | Generate a preliminary incident report from a structured alert. |\n",
    "| **Classify New Tickets** | `zero-shot-classification`| Categorize a new machine failure mode without needing a pre-existing label. |\n",
    "| **Extract Structured Data** | `token-classification` (NER) | Pull part numbers, asset IDs, and dates from an unstructured work order. |\n",
    "| **Fill in Missing Data** | `fill-mask` | Suggest a plausible value for a corrupted or missing sensor reading in a log file. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae025b5b",
   "metadata": {},
   "source": [
    "## ⚙️ Environment Setup and Quick Check\n",
    "\n",
    "Before we dive in, let's make sure our environment is set up correctly and check the versions of our key libraries. We'll also define a `device` variable to automatically leverage a GPU if one is available, which will significantly speed up inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97af747",
   "metadata": {},
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Print library versions for reproducibility\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = 0  # Use the first GPU (device 0)\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = -1  # Use CPU\n",
    "    print(\"GPU not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4281765",
   "metadata": {},
   "source": [
    "## Task 1: Sentiment Analysis\n",
    "\n",
    "**Use Case:** Automatically monitor operator feedback from a digital logbook. This can help you gauge morale, identify recurring safety concerns, or flag urgent issues that require immediate attention.\n",
    "\n",
    "A sentiment analysis pipeline classifies a piece of text as positive, negative, or neutral. It's a quick and powerful way to get a high-level understanding of large volumes of unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Sentiment Analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "# Example feedback entries from a factory floor logbook\n",
    "feedback_entries = [\n",
    "    \"The refurbished compressor is running silently and our energy draw has dropped by 3%. Great work by the maintenance team!\",\n",
    "    \"The paint booth filter change was skipped again during the night shift. We had to scrap 18 panels due to overspray contamination.\",\n",
    "    \"The new safety guards on the stamping press are working as expected.\"\n",
    "]\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "# We can specify a model fine-tuned on text similar to our use case.\n",
    "# 'cardiffnlp/twitter-roberta-base-sentiment' is trained on informal text and works well here.\n",
    "sentiment_pipeline = pipeline(\n",
    "    task='sentiment-analysis',\n",
    "    model='cardiffnlp/twitter-roberta-base-sentiment',\n",
    "    device=device  # Use GPU if available\n",
    ")\n",
    "\n",
    "# Run the feedback through the pipeline\n",
    "results = sentiment_pipeline(feedback_entries)\n",
    "\n",
    "# Print the results in a readable format\n",
    "for text, result in zip(feedback_entries, results):\n",
    "    # The model returns 'LABEL_0' (Negative), 'LABEL_1' (Neutral), 'LABEL_2' (Positive)\n",
    "    # We can map these to more descriptive names.\n",
    "    label_map = {'LABEL_0': 'Negative', 'LABEL_1': 'Neutral', 'LABEL_2': 'Positive'}\n",
    "    print(f\"Feedback: '{text[:60]}...'\")\n",
    "    print(f\"  -> Sentiment: {label_map.get(result['label'], 'Unknown')} (Score: {result['score']:.3f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Summarization\n",
    "from transformers import pipeline\n",
    "\n",
    "# A detailed shift log entry\n",
    "shift_log = \"\"\"\n",
    "Shift Supervisor: Maria Rodriguez\n",
    "Date: 2024-07-16, Night Shift (22:00 - 06:00)\n",
    "\n",
    "Summary of Operations:\n",
    "Line 3 experienced intermittent stoppages between 01:15 and 02:45, traced to a faulty sensor (ID: S-45B) on the conveyor belt. Maintenance was notified, and Technician David Chen bypassed the sensor at 03:00 to restore production. A permanent fix is scheduled for the next maintenance window. Total downtime was approximately 90 minutes, with a loss of 350 units.\n",
    "Line 1 and 2 operated at 98% efficiency with no major issues.\n",
    "\n",
    "Quality Control:\n",
    "QC team flagged a batch of 50 units from Line 3 (Batch ID: B-7891) produced just before the downtime for potential defects. They are currently under inspection.\n",
    "\n",
    "Safety:\n",
    "A minor coolant spill was reported near CNC machine #5 at 04:30. The area was cleaned and cordoned off per protocol. No injuries were reported.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "# 'facebook/bart-large-cnn' is a great model for summarizing news-like articles and reports.\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarizer(\n",
    "    shift_log,\n",
    "    max_length=100,  # The maximum length of the summary\n",
    "    min_length=30,   # The minimum length of the summary\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"Original Log Length:\", len(shift_log))\n",
    "print(\"Summary Length:\", len(summary[0]['summary_text']))\n",
    "print(\"\\nGenerated Summary:\\n\", summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ca5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3: Translation\n",
    "\n",
    "**Use Case:** Your company sources equipment from around the world. A new CNC machine arrives with its technical documentation and safety warnings in German. A translation pipeline can instantly make this critical information accessible to your English-speaking maintenance and safety teams.\n",
    "\n",
    "Hugging Face provides access to some of the world's most powerful translation models, originally developed by the University of Helsinki. These models are available for a vast number of language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae41065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hands-On: Translation\n",
    "from transformers import pipeline\n",
    "\n",
    "# A safety warning in German\n",
    "german_text = \"Achtung: Die Maschine darf nur von autorisiertem Personal bedient werden. Vor Wartungsarbeiten Stromzufuhr unterbrechen.\"\n",
    "\n",
    "# Initialize the translation pipeline\n",
    "# Model names follow a pattern: \"Helsinki-NLP/opus-mt-{source_language}-{target_language}\"\n",
    "translator = pipeline(\n",
    "    task=\"translation_de_to_en\",\n",
    "    model=\"Helsinki-NLP/opus-mt-de-en\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Perform the translation\n",
    "english_text = translator(german_text)\n",
    "\n",
    "print(f\"Original (German): {german_text}\")\n",
    "print(f\"Translated (English): {english_text[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40800724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 4: Question Answering\n",
    "\n",
    "**Use Case:** A technician needs to find a specific piece of information—like a torque specification or a pressure setting—buried deep within a long PDF maintenance manual. A question-answering (QA) system can instantly find the answer, saving valuable time and reducing the risk of errors.\n",
    "\n",
    "QA models work by taking a `question` and a `context` (the text to search within) and extracting the span of text that best answers the question. This is a form of **extractive QA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2: Summarization\n",
    "\n",
    "**Use Case:** Condense long, detailed shift handover logs or maintenance reports into a few key bullet points. This allows supervisors and engineers to quickly grasp the most critical information without reading through pages of text.\n",
    "\n",
    "Summarization models are trained to take a long document and generate a shorter, coherent version that captures the main ideas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
