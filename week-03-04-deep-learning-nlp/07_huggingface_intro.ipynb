{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73edf05a",
   "metadata": {},
   "source": [
    "# ü§ó Notebook 07: HuggingFace Transformers & Hub Intro\n",
    "\n",
    "**Week 3-4: Deep Learning & NLP Foundations**  \n",
    "**Gen AI Masters Program**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "1. ‚úÖ Navigating the HuggingFace ecosystem (Hub, Datasets, Spaces)\n",
    "2. ‚úÖ Using inference pipelines for manufacturing text tasks\n",
    "3. ‚úÖ Tokenizers, AutoModel, and configuration overview\n",
    "4. ‚úÖ Fine-tuning a transformer with the `Trainer` API\n",
    "5. ‚úÖ Evaluating and saving models locally & to the Hub\n",
    "6. ‚úÖ Manufacturing best practices for secure deployment\n",
    "\n",
    "**Estimated Time:** 4-5 hours\n",
    "\n",
    "---\n",
    "\n",
    "## üåç HuggingFace Ecosystem at a Glance\n",
    "\n",
    "- **Hub**: 400k+ models, datasets, spaces\n",
    "- **Transformers**: State-of-the-art model library\n",
    "- **Datasets**: Efficient dataset loading&streaming\n",
    "- **Evaluate**: Metrics ready-to-use\n",
    "- **Spaces**: Deploy demos with Gradio/Streamlit\n",
    "\n",
    "We'll connect these capabilities to manufacturing, pharma, and agribusiness automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "# HuggingFace libraries (pre-installed via requirements.txt)\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "print(f\"Transformers version: {pipeline.__module__.split('.')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d14517",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Authenticating with the HuggingFace Hub\n",
    "\n",
    "1. Create an account: https://huggingface.co\n",
    "2. Generate a **User Access Token** (Settings ‚Üí Access Tokens)\n",
    "3. Login from notebook or CLI\n",
    "\n",
    "```python\n",
    "from huggingface_hub import login\n",
    "login(token='hf_xxx...')  # or use os.environ['HF_TOKEN']\n",
    "```\n",
    "\n",
    "> üîê Tip: Store tokens securely in environment variables or GitHub Secrets for CI/CD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca787b3b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Quick Inference Pipelines\n",
    "\n",
    "### Zero-Shot Classification for Incident Severity\n",
    "Classify maintenance logs into Normal/Warning/Critical without training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879eb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_pipeline = pipeline(\n",
    "    'zero-shot-classification',\n",
    "    model='facebook/bart-large-mnli',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "maintenance_log = 'Hydraulic pump output pressure collapsed causing line shutdown'\n",
    "labels = ['normal', 'warning', 'critical']\n",
    "result = incident_pipeline(maintenance_log, candidate_labels=labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'label': result['labels'],\n",
    "    'score': result['scores']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262dae9",
   "metadata": {},
   "source": [
    "### Summarization for Maintenance Logs\n",
    "Compress a long log entry into an actionable summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    'summarization',\n",
    "    model='philschmid/bart-large-cnn-samsum',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "long_log = (\n",
    "    'During the night shift operators noticed persistent vibration spikes, '\n",
    "    'followed by coolant temperature rise in furnace bay three. '\n",
    "    'Manual inspection confirmed partial blockage in the coolant loop. '\n",
    "    'Temporary bypass restored flow but pressure remains unstable.'\n",
    ")\n",
    "summary = summarizer(long_log, max_length=45, min_length=15, do_sample=False)[0]['summary_text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a079e7a",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "Identify assets, components, and actions within logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = pipeline(\n",
    "    'ner',\n",
    "    model='dslim/bert-base-NER',\n",
    "    aggregation_strategy='simple',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "entities = ner_pipeline('Technicians replaced the Siemens servo motor on line 4 and recalibrated the ABB controller.')\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5556eb",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Tokenizers & AutoModel Essentials\n",
    "\n",
    "Tokenizers break text into model-friendly tokens. HuggingFace `AutoTokenizer` selects the correct tokenizer based on a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokens = tokenizer(maintenance_log, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2911b6",
   "metadata": {},
   "source": [
    "Inspect decoded tokens to understand subword splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_tokens = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n",
    "list(zip(decoded_tokens, tokens['input_ids'][0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d580f27",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Building a Manufacturing Incident Classifier\n",
    "\n",
    "We'll fine-tune `distilbert-base-uncased` to classify logs into **normal**, **warning**, and **critical** severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_data = pd.DataFrame({\n",
    "    'text': [\n",
    "        'Lubrication schedule completed with no deviations',\n",
    "        'Pressure fluctuations above tolerance noted on press',\n",
    "        'Emergency stop triggered due to high voltage surge',\n",
    "        'Routine inspection confirmed sensors calibrated',\n",
    "        'Coolant leak observed near heat exchanger',\n",
    "        'Critical alarm persisted despite manual override',\n",
    "        'Conveyor speed oscillation resolved after reset',\n",
    "        'Bearing temperature exceeded safety threshold',\n",
    "        'Hydraulic pump failure caused production halt',\n",
    "        'Minor vibration increase logged during swing shift'\n",
    "    ],\n",
    "    'label': [0, 1, 2, 0, 1, 2, 0, 2, 2, 1]\n",
    "})\n",
    "label_map = {0: 'normal', 1: 'warning', 2: 'critical'}\n",
    "incident_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c4be8",
   "metadata": {},
   "source": [
    "Split into train/validation sets and convert to a `datasets.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = incident_data.sample(frac=0.8, random_state=42)\n",
    "valid_df = incident_data.drop(train_df.index)\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(valid_df.reset_index(drop=True))\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89900014",
   "metadata": {},
   "source": [
    "Tokenize the dataset with padding and truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch: Dict[str, List[str]]):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd53e6",
   "metadata": {},
   "source": [
    "### Define Model & Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea40c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=3\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5507d",
   "metadata": {},
   "source": [
    "### Fine-Tuning with the Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='model_outputs/hf_incident_classifier',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    logging_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "train_result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
