{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0762fe",
   "metadata": {},
   "source": [
    "# üß± Week 11-12 ¬∑ Notebook 01 ¬∑ MLOps Fundamentals for GenAI in Manufacturing\n",
    "\n",
    "Design an auditable lifecycle for GenAI copilots powering maintenance, quality, and EHS workflows across multiple plants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3aad2",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Map the GenAI lifecycle from data intake to monitoring with manufacturing-specific checkpoints.\n",
    "- Stand up MLflow experiment tracking and register models tagged by plant and release.\n",
    "- Define governance artefacts that satisfy ISO 9001, SOX ITGC, and OSHA audit requirements.\n",
    "- Produce an MLOps readiness scorecard for the capstone deployment team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ad44f",
   "metadata": {},
   "source": [
    "## üß© Scenario\n",
    "Arvind Manufacturing operates 6 plants across India, Mexico, and Hungary. Each plant runs a GenAI assistant for maintenance troubleshooting. Leadership demands a unified lifecycle ensuring models, prompts, and datasets are versioned and auditable before Week 12 production launch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1cf61",
   "metadata": {},
   "source": [
    "## üîÑ Lifecycle Blueprint\n",
    "```text\n",
    "Data Intake ‚Üí Feature/Embedding Store ‚Üí Model & Prompt Versioning ‚Üí Continuous Integration ‚Üí Deployment ‚Üí Monitoring ‚Üí Feedback Loop\n",
    "```\n",
    "| Stage | Manufacturing Considerations | Tools | Evidence |\n",
    "| --- | --- | --- | --- |\n",
    "| Data Intake | PII scrub, SOP freshness & approvals | pandas, Great Expectations | Data quality report, SME sign-off |\n",
    "| Versioning | Tag models by plant/equipment, freeze prompts | Git, MLflow, DVC | Model card, prompt changelog |\n",
    "| CI/CD | Safety linting, regression tests | GitHub Actions, pytest | Pipeline logs, approval records |\n",
    "| Deployment | Edge vs. Cloud, shift scheduling | Cloud Run, GKE, Helm | Deployment manifest, runbook |\n",
    "| Monitoring | Drift alerts, cost caps | Prometheus, Grafana, BigQuery | Weekly KPI report, alert runbook |\n",
    "| Feedback | Technician ratings, root-cause capture | ServiceNow, custom forms | Feedback dashboard |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb71870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Logging a manufacturing maintenance model to MLflow\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))\n",
    "mlflow.set_experiment('maintenance_copilot_week11')\n",
    "\n",
    "Path('docs').mkdir(exist_ok=True)\n",
    "Path('release_notes').mkdir(exist_ok=True)\n",
    "\n",
    "with mlflow.start_run(run_name=f'plant-pune-{datetime.utcnow().date()}'):\n",
    "    mlflow.log_params({\n",
    "        'plant': 'Pune',\n",
    "        'equipment_cluster': 'Presses',\n",
    "        'rag_version': 'v0.9.1',\n",
    "        'adapter_version': 'lora-2025-09-30'\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        'precision_top3': 0.88,\n",
    "        'avg_latency_ms': 125,\n",
    "        'sme_rating': 4.5\n",
    "    })\n",
    "    model_card_path = Path('docs/model_card_pune.md')\n",
    "    model_card_path.write_text('# Model Card: Pune Plant\\n\\nKey metrics tracked weekly.')\n",
    "    mlflow.log_artifact(str(model_card_path))\n",
    "    mlflow.set_tags({\n",
    "        'release_train': 'Week11',\n",
    "        'change_ticket': 'CHG-4582',\n",
    "        'regulated': 'true'\n",
    "    })\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be2edb",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Model Registry Entry\n",
    "Document dependencies, prompts, and dataset snapshots before promoting to staging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/model',\n",
    "    name='maintenance_copilot_lora'\n",
    ")\n",
    "model_version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a2719",
   "metadata": {},
   "source": [
    "## üßæ Audit-Ready Metadata\n",
    "Create a release note capturing mandatory governance fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fa91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "release_note = {\n",
    "    'release_id': 'REL-2025-11-PlantPune',\n",
    "    'approved_by': 'Head of Maintenance',\n",
    "    'change_ticket': 'CHG-4582',\n",
    "    'mlflow_run_id': run_id,\n",
    "    'datasets': ['maintenance_logs_2024Q4.parquet', 'sop_manuals_v7.pdf'],\n",
    "    'prompts_version': 'prompts/maintenance_v12.yaml',\n",
    "    'risk_assessment': {\n",
    "        'hallucination_mitigation': 'RAG with filtered top-k=5 + SME review',\n",
    "        'pii_controls': 'Great Expectations + manual sampling'\n",
    "    }\n",
    "}\n",
    "with open('release_notes/REL-2025-11-PlantPune.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(release_note, fp, indent=2)\n",
    "release_note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692a886",
   "metadata": {},
   "source": [
    "## üßÆ MLOps Readiness Scorecard\n",
    "Assess maturity across lifecycle dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4131697",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard = pd.DataFrame([\n",
    "    {'dimension': 'Data Quality', 'score': 4, 'notes': 'Automated Great Expectations, SME review weekly'},\n",
    "    {'dimension': 'Model Versioning', 'score': 3, 'notes': 'MLflow registry, need branching policy'},\n",
    "    {'dimension': 'CI/CD', 'score': 2, 'notes': 'Basic tests, add security scan'},\n",
    "    {'dimension': 'Monitoring', 'score': 2, 'notes': 'Latency tracked, hallucination alerts pending'},\n",
    "    {'dimension': 'Governance', 'score': 3, 'notes': 'Change tickets recorded; add automated evidence export'}\n",
    "])\n",
    "scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e37db",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- Prioritize CI/CD and monitoring upgrades before Week 12 go-live.\n",
    "- Maintain scorecard in project tracker; update weekly.\n",
    "- Escalate gaps to Capstone PM and plant SMEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123378e",
   "metadata": {},
   "source": [
    "## üß™ Lab Assignment\n",
    "1. Deploy an MLflow tracking server (local or hosted) and connect via VPN if required by IT.\n",
    "2. Log experiments for at least two plants and compare metrics in the registry.\n",
    "3. Draft a lifecycle policy document describing branching, tagging, and rollback procedures.\n",
    "4. Present the readiness scorecard to stakeholders and capture action items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b606b",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Lifecycle documented with manufacturing-specific checkpoints\n",
    "- [ ] MLflow experiment & registry configured\n",
    "- [ ] Release metadata captured with audit evidence\n",
    "- [ ] Readiness scorecard shared with leadership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446836bf",
   "metadata": {},
   "source": [
    "## üìö References\n",
    "- MLflow Tracking & Registry Documentation\n",
    "- *MLOps Zoomcamp* ‚Äî Experiment Tracking Module\n",
    "- ISO 9001 Change Management Templates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
