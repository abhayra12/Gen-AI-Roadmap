{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40cdfc3e",
   "metadata": {},
   "source": [
    "# 🐳 Week 11-12 · Notebook 03 · Docker Containerization for the Manufacturing Copilot\n",
    "\n",
    "This notebook details how to package our FastAPI application, agent dependencies, and model weights into a secure, reproducible, and optimized Docker container, ready for deployment anywhere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c54ef",
   "metadata": {},
   "source": [
    "## 🎯 Learning Objectives\n",
    "\n",
    "- **Author a Production-Grade Dockerfile:** Write a multi-stage `Dockerfile` that creates a small, secure, and efficient container image.\n",
    "- **Implement Security Best Practices:** Learn to run containers as a non-root user, minimize the attack surface, and scan for vulnerabilities.\n",
    "- **Manage Configuration Flexibly:** Use build arguments and environment variables to create a single container image that can be configured for different plants or environments at runtime.\n",
    "- **Ensure Supply Chain Security:** Generate a Software Bill of Materials (SBOM) to create a transparent inventory of all dependencies in our container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a9986",
   "metadata": {},
   "source": [
    "## 🧩 Scenario: A \"Build Once, Deploy Anywhere\" Container\n",
    "\n",
    "The Manufacturing Copilot needs to be deployed across a hybrid environment: some plants will use on-premises edge servers (with limited resources), while others will deploy to GCP Cloud Run. Our container strategy must support this.\n",
    "\n",
    "**Requirements:**\n",
    "1.  **Small Image Size:** The final container image must be as small as possible (e.g., < 1.5 GB) to reduce storage costs and deployment times.\n",
    "2.  **Security:** The container must run as a non-root user and pass regular security scans for known vulnerabilities (CVEs).\n",
    "3.  **Configurability:** Plant-specific settings (like language translation flags or database endpoints) must be configurable at runtime via environment variables, not by rebuilding the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf0ad8",
   "metadata": {},
   "source": [
    "### 1. Authoring a Production-Grade Dockerfile\n",
    "\n",
    "A `Dockerfile` is a script that contains instructions for building a Docker image. For production, we use a **multi-stage build** to create a final image that is small, secure, and contains only what's necessary to run the application.\n",
    "\n",
    "**Key Principles:**\n",
    "- **Stage 1 (Builder):** This stage installs dependencies, including build-time tools. It's where we compile code or download packages.\n",
    "- **Stage 2 (Final):** This stage starts from a clean, minimal base image and copies *only the necessary artifacts* (like the compiled code and the Python virtual environment) from the builder stage. This technique dramatically reduces the final image size and attack surface.\n",
    "\n",
    "Let's create our `Dockerfile`. We'll use `%%writefile` to create the file in the `app` directory we made in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19998110",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile app/Dockerfile\n",
    "\n",
    "# --- STAGE 1: Builder ---\n",
    "# This stage installs all Python dependencies, including compile-time-only ones.\n",
    "# We use a specific version of Python for reproducibility.\n",
    "FROM python:3.10-slim as builder\n",
    "\n",
    "# Set best practices for Docker builds\n",
    "ENV PYTHONUNBUFFERED=1 \\\n",
    "    PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PIP_NO_CACHE_DIR=off \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=on \\\n",
    "    PIP_DEFAULT_TIMEOUT=100 \\\n",
    "    POETRY_VERSION=1.5.1\n",
    "\n",
    "# Install poetry for dependency management\n",
    "RUN pip install \"poetry==$POETRY_VERSION\"\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy only the files needed to install dependencies.\n",
    "# This leverages Docker's layer caching. The layer will only be rebuilt if\n",
    "# these files change.\n",
    "COPY poetry.lock pyproject.toml ./\n",
    "\n",
    "# Install dependencies into a virtual environment.\n",
    "# --no-root: Don't install poetry as root.\n",
    "# --no-dev: Don't install development dependencies (like pytest).\n",
    "# virtualenvs.in-project: Create the .venv folder in the project directory.\n",
    "RUN poetry config virtualenvs.in-project true && \\\n",
    "    poetry install --no-interaction --no-ansi --no-dev\n",
    "\n",
    "# --- STAGE 2: Final Image ---\n",
    "# This stage creates the final, lightweight, and secure image.\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Create a non-root user to run the application for security reasons.\n",
    "RUN useradd --create-home appuser\n",
    "USER appuser\n",
    "\n",
    "# Copy the virtual environment from the builder stage.\n",
    "COPY --from=builder /app/.venv ./.venv\n",
    "# Copy the application source code.\n",
    "COPY . .\n",
    "\n",
    "# Make the virtual environment's binaries accessible in the PATH.\n",
    "ENV PATH=\"/app/.venv/bin:$PATH\"\n",
    "\n",
    "# --- Configuration via Environment Variables ---\n",
    "# These can be overridden at runtime (e.g., in docker-compose or Cloud Run).\n",
    "ENV APP_PORT=8000\n",
    "ENV LOG_LEVEL=\"INFO\"\n",
    "\n",
    "# Expose the port the app will run on.\n",
    "EXPOSE 8000\n",
    "\n",
    "# --- Entrypoint ---\n",
    "# The command to run when the container starts.\n",
    "# Use `gunicorn` for a production-ready ASGI server with multiple workers.\n",
    "CMD [\"gunicorn\", \"-w\", \"4\", \"-k\", \"uvicorn.workers.UvicornWorker\", \"app.main:app\", \"--bind\", \"0.0.0.0:8000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5520e1a",
   "metadata": {},
   "source": [
    "### 🔍 Analysis of the Multi-Stage Dockerfile\n",
    "\n",
    "This `Dockerfile` is designed for both efficiency and security.\n",
    "\n",
    "-   **Stage 1 (`builder`):**\n",
    "    -   It starts from a slim Python base image and sets several environment variables to follow best practices for Python in Docker.\n",
    "    -   It installs `poetry`, a modern dependency management tool.\n",
    "    -   It copies *only* `pyproject.toml` and `poetry.lock`. This is a key optimization. Docker caches layers, and this step will only be re-run if the dependencies change, speeding up subsequent builds.\n",
    "    -   It installs dependencies into a virtual environment inside the project directory (`.venv`). We exclude development dependencies (`--no-dev`) to keep the image lean.\n",
    "\n",
    "-   **Stage 2 (Final Image):**\n",
    "    -   It also starts from a slim Python image, ensuring no unnecessary OS packages are included.\n",
    "    -   **Security:** It creates a dedicated, non-root user named `appuser` and switches to it. This is a critical security practice to limit the container's privileges and reduce the \"blast radius\" if the application is compromised.\n",
    "    -   **Efficiency:** It copies *only* the virtual environment from the `builder` stage and the application source code. It does *not* copy the build tools (like `poetry` itself), source packages, or cache, resulting in a much smaller final image.\n",
    "    -   **Configurability:** It defines `ENV` variables for runtime configuration (like `APP_PORT`). These act as defaults but can be easily overridden when the container is run.\n",
    "    -   **Production-Ready Entrypoint:** It uses `gunicorn` with `uvicorn` workers. `gunicorn` is a mature, robust process manager that can handle multiple concurrent requests by managing several `uvicorn` worker processes, making it ideal for production workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74831b31",
   "metadata": {},
   "source": [
    "### 2. Local Development with Docker Compose\n",
    "\n",
    "`docker-compose` is a tool for defining and running multi-container Docker applications. For our project, it simplifies local development by automating the process of building the image, running the container, and mapping ports.\n",
    "\n",
    "Let's create a `docker-compose.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dbc9c",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile app/docker-compose.yml\n",
    "\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  copilot_api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    image: manufacturing-copilot-api:latest\n",
    "    container_name: manufacturing_copilot_api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      # Override environment variables for local testing\n",
    "      - LOG_LEVEL=DEBUG\n",
    "      # Example of a secret that should be handled securely, not hardcoded\n",
    "      - DATABASE_URL=postgresql://user:password@host.docker.internal:5432/mydb\n",
    "    volumes:\n",
    "      # Mount local source code for live-reloading during development.\n",
    "      # This is for development only and should NOT be used in production.\n",
    "      - .:/app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17132fce",
   "metadata": {},
   "source": [
    "## 🛡️ Security, Compliance, and Software Supply Chain\n",
    "\n",
    "Containerizing an application is not just about packaging; it's also about securing the **software supply chain**. We need to know exactly what's inside our container and ensure it's free from known vulnerabilities.\n",
    "\n",
    "| Control                       | Implementation                                                                                             | Evidence & Artifacts                                                              |\n",
    "| ----------------------------- | ---------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |\n",
    "| **Vulnerability Scanning**    | Integrate a scanner like **Trivy** into the CI/CD pipeline to check the OS packages and Python libraries for known vulnerabilities (CVEs). | A passing Trivy scan report (JSON or table format). The pipeline should fail if high-severity CVEs are found. |\n",
    "| **Software Bill of Materials (SBOM)** | Generate an SBOM during the build process. This is a detailed inventory of all software components, their versions, and their licenses. | An SBOM file in a standard format like CycloneDX or SPDX, archived with the release artifacts. |\n",
    "| **Static Code Analysis**      | Use tools like `bandit` to scan Python code for common security issues (e.g., hardcoded passwords, SQL injection vulnerabilities). | A passing `bandit` report. The CI pipeline can be configured to fail if issues are found. |\n",
    "| **Base Image Management**     | Use minimal, trusted base images (like `python:3.10-slim`) from official sources and regularly update them to patch underlying vulnerabilities. | Dockerfile history, base image version pinning (e.g., `python:3.10.12-slim`). |\n",
    "| **Secrets Management**        | Never hardcode secrets (API keys, passwords) in the Docker image. Load them at runtime from a secure vault (like GCP Secret Manager or HashiCorp Vault). | Code review checklists confirming no secrets are in the repository. Configuration files that point to secret manager paths. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example CI Commands for Security Scans ---\n",
    "\n",
    "# These commands would typically be run in a CI/CD pipeline (e.g., GitHub Actions)\n",
    "# after the application has been built.\n",
    "\n",
    "# 1. Build the Docker image first\n",
    "# The `--tag` flag gives our image a human-readable name.\n",
    "build_command = \"docker build -t manufacturing-copilot-api:latest -f app/Dockerfile app/\"\n",
    "print(f\"Build Command:\\n{build_command}\\n\")\n",
    "\n",
    "\n",
    "# 2. Run Trivy for vulnerability scanning\n",
    "# This command scans the image for HIGH and CRITICAL severity vulnerabilities.\n",
    "# `--exit-code 1` ensures that the command will fail (exit with a non-zero code)\n",
    "# if any such vulnerabilities are found, which will stop the CI pipeline.\n",
    "trivy_command = \"trivy image --severity HIGH,CRITICAL --exit-code 1 manufacturing-copilot-api:latest\"\n",
    "print(f\"Vulnerability Scan Command:\\n{trivy_command}\\n\")\n",
    "\n",
    "\n",
    "# 3. Generate a Software Bill of Materials (SBOM)\n",
    "# This command generates a detailed list of all OS and Python packages in the container.\n",
    "# The output is saved in the CycloneDX JSON format, a common standard for SBOMs.\n",
    "# This artifact is crucial for compliance and for quickly identifying affected systems\n",
    "# if a new vulnerability is discovered in a dependency.\n",
    "sbom_command = \"trivy image --format cyclonedx --output sbom.json manufacturing-copilot-api:latest\"\n",
    "print(f\"SBOM Generation Command:\\n{sbom_command}\\n\")\n",
    "\n",
    "# 4. Run Bandit for static code analysis\n",
    "# This command scans the `app` directory for common security issues in Python code.\n",
    "# `-r` means recursive, and `-ll` sets the confidence level to medium.\n",
    "bandit_command = \"bandit -r app/ -ll\"\n",
    "print(f\"Static Analysis Command:\\n{bandit_command}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f6a96",
   "metadata": {},
   "source": [
    "## 🧪 Lab Assignment: Build and Secure Your Container\n",
    "\n",
    "1.  **Install Dependencies:**\n",
    "    -   Make sure you have **Docker Desktop** installed and running on your machine.\n",
    "    -   Install the necessary Python tools for security scanning: `pip install trivy bandit`.\n",
    "\n",
    "2.  **Build and Run the Container:**\n",
    "    -   Navigate to the `app` directory in your terminal.\n",
    "    -   Run the command: `docker-compose up --build`. This will:\n",
    "        -   Build the Docker image using the `Dockerfile`.\n",
    "        -   Start a container based on that image.\n",
    "        -   Map port 8000 on your local machine to port 8000 in the container.\n",
    "    -   Open your browser to [http://localhost:8000/docs](http://localhost:8000/docs). You should see the live FastAPI Swagger UI being served from within your container.\n",
    "\n",
    "3.  **Run a Smoke Test:**\n",
    "    -   While the container is running, open another terminal.\n",
    "    -   Use `curl` to test the `/health` endpoint: `curl http://localhost:8000/health`. You should see `{\"status\":\"ok\"}`.\n",
    "    -   Use `curl` to test the `/v1/diagnose` endpoint. Remember to include the required `X-Auth-Token` header and a valid JSON payload.\n",
    "        ```bash\n",
    "        curl -X POST \"http://localhost:8000/v1/diagnose\" \\\n",
    "        -H \"Content-Type: application/json\" \\\n",
    "        -H \"X-Auth-Token: Bearer technician-123\" \\\n",
    "        -d '{\n",
    "          \"plant_id\": \"MEX-GTO\",\n",
    "          \"equipment_id\": \"ROBOT-ARM-007\",\n",
    "          \"problem_description\": \"The arm is failing to grip parts consistently.\"\n",
    "        }'\n",
    "        ```\n",
    "\n",
    "4.  **Scan Your Image for Vulnerabilities:**\n",
    "    -   In your terminal (with the container stopped), run the Trivy scan command from the cell above on the `manufacturing-copilot-api:latest` image you just built.\n",
    "        ```bash\n",
    "        trivy image --severity HIGH,CRITICAL --exit-code 0 manufacturing-copilot-api:latest\n",
    "        ```\n",
    "        *(Note: We use `--exit-code 0` for the lab so it doesn't stop even if vulnerabilities are found. In a real CI pipeline, you would use `--exit-code 1`.)*\n",
    "    -   Analyze the output. Does Trivy find any vulnerabilities in the base OS packages or Python libraries?\n",
    "\n",
    "5.  **Generate an SBOM:**\n",
    "    -   Run the SBOM generation command from the cell above.\n",
    "    -   Inspect the `sbom.json` file that is created. Can you find `fastapi`, `gunicorn`, and `pydantic` in the list of components? This file is your container's \"list of ingredients.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9350d",
   "metadata": {},
   "source": [
    "## ✅ Checklist for this Notebook\n",
    "\n",
    "- [X] A multi-stage `Dockerfile` is created to produce a small and efficient final image.\n",
    "- [X] The container is configured to run as a non-root user for enhanced security.\n",
    "- [X] A `docker-compose.yml` file is set up for easy local development and testing.\n",
    "- [X] Commands for vulnerability scanning (`Trivy`) and SBOM generation are defined for CI/CD integration.\n",
    "- [ ] **TODO:** Complete the Lab Assignment to build, test, and scan your container image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfe1d6",
   "metadata": {},
   "source": [
    "## 📚 References and Further Reading\n",
    "\n",
    "-   [Docker Docs: Multi-stage builds](https://docs.docker.com/build/building/multi-stage/) - The official guide to creating optimized, multi-stage builds.\n",
    "-   [FastAPI in Containers - Official Tutorial](https://fastapi.tiangolo.com/deployment/docker/)\n",
    "-   [Aqua Trivy Documentation](https://aquasecurity.github.io/trivy/) - Comprehensive guide for the vulnerability scanner.\n",
    "-   [CycloneDX SBOM Standard](https://cyclonedx.org/) - Learn more about the Software Bill of Materials format.\n",
    "-   [OWASP Docker Security Cheat Sheet](https://cheatsheetseries.owasp.org/Docker_Security_Cheat_Sheet.html) - Excellent tips for securing your containers.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
