# ğŸš€ Gen AI Masters Program
### From Beginner to Production-Ready AI Engineer in 12 Weeks

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![GitHub Codespaces](https://img.shields.io/badge/Codespace-Ready-success)](https://github.com/features/codespaces)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-yellow)](https://huggingface.co/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **"Master Generative AI through hands-on projects and deploy production-grade solutions"**

---

## ğŸ“š Course Overview

Welcome to the most comprehensive, hands-on Gen AI Masters Program designed to take you from **beginner to production-ready AI engineer** in just 12 weeks! This course combines cutting-edge theory with practical implementation, culminating in a **portfolio-worthy capstone project**.

### ğŸ¯ What You'll Build

By the end of this course, you'll have:
- âœ… **15+ Jupyter Notebooks** covering every Gen AI concept
- âœ… **6 Mini-Projects** demonstrating real-world applications
- âœ… **1 Production-Grade Capstone Project** (Containerized, CI/CD, Cloud-Deployed)
- âœ… **Deep understanding** of Transformers, LLMs, RAG, and Agentic AI
- âœ… **Portfolio** that stands out to employers

---

## ğŸ—“ï¸ 12-Week Learning Journey

### **Phase 1: Foundations (Weeks 1-4)**

#### ğŸ“˜ **Week 1-2: Python & ML Fundamentals**
**Goal:** Build strong programming and ML foundations

| Topic | Notebook | Status |
|-------|----------|--------|
| Environment Setup | `01_environment_setup.ipynb` | âœ… |
| Python Essentials | `02_python_essentials.ipynb` | âœ… |
| NumPy & Pandas Mastery | `03_numpy_pandas.ipynb` | ğŸ”„ |
| Data Preprocessing | `04_data_preprocessing.ipynb` | ğŸ”„ |
| Classical ML Foundations | `05_ml_foundations.ipynb` | ğŸ”„ |

**ğŸ“ Homework:** Data Analysis Mini-Project

**ğŸ¯ Checkpoint 1:** Complete Python & ML fundamentals assessment

---

#### ğŸ“— **Week 3-4: Deep Learning & NLP Foundations**
**Goal:** Master neural networks and NLP basics

| Topic | Notebook | Status |
|-------|----------|--------|
| Neural Networks Fundamentals | `01_neural_networks.ipynb` | ğŸ”„ |
| CNNs for Computer Vision | `02_cnns_basics.ipynb` | ğŸ”„ |
| RNNs & Sequence Models | `03_rnns_sequences.ipynb` | ğŸ”„ |
| Introduction to Transformers | `04_transformer_architecture.ipynb` | ğŸ”„ |
| Transformer Internals | `05_attention_mechanism.ipynb` | ğŸ”„ |
| Token Embeddings & Context | `06_embeddings_tokenization.ipynb` | ğŸ”„ |
| HuggingFace Ecosystem | `07_huggingface_intro.ipynb` | ğŸ”„ |

**ğŸ“ Homework:** Build a text classifier using HuggingFace

**ğŸ¯ Checkpoint 2:** Implement transformer from scratch (simplified version)

---

### **Phase 2: LLMs & Advanced NLP (Weeks 5-6)**

#### ğŸ“™ **Week 5-6: LLMs, Prompt Engineering & RAG**
**Goal:** Master Large Language Models and their applications

| Topic | Notebook | Status |
|-------|----------|--------|
| Introduction to LLMs | `01_llms_introduction.ipynb` | ğŸ”„ |
| HuggingFace Tasks (Sentiment, Summarization, etc.) | `02_huggingface_tasks.ipynb` | ğŸ”„ |
| Model Selection & Pre-processing | `03_model_selection_preprocessing.ipynb` | ğŸ”„ |
| Tokenizers Deep Dive | `04_tokenizers_advanced.ipynb` | ğŸ”„ |
| Prompt Engineering Techniques | `05_prompt_engineering.ipynb` | ğŸ”„ |
| Few-Shot Learning | `06_few_shot_learning.ipynb` | ğŸ”„ |
| Introduction to RAG | `07_rag_introduction.ipynb` | ğŸ”„ |
| RAG Implementation | `08_rag_implementation.ipynb` | ğŸ”„ |
| Vector Embeddings | `09_vector_embeddings.ipynb` | ğŸ”„ |

**ğŸ“ Homework:** Build a domain-specific Q&A system using RAG

**ğŸ¯ Checkpoint 3:** Deploy a working RAG application

---

### **Phase 3: Advanced RAG & Agentic AI (Weeks 7-8)**

#### ğŸ“• **Week 7-8: LangChain, Agents & Advanced RAG**
**Goal:** Build intelligent agents and production-grade RAG systems

| Topic | Notebook | Status |
|-------|----------|--------|
| LangChain Framework | `01_langchain_essentials.ipynb` | ğŸ”„ |
| LangChain Message Structure | `02_langchain_messages.ipynb` | ğŸ”„ |
| Prompt Templates & Chains | `03_prompt_templates_chains.ipynb` | ğŸ”„ |
| Runnable Sequences | `04_runnable_sequences.ipynb` | ğŸ”„ |
| Document Loaders & Chunking | `05_document_loaders.ipynb` | ğŸ”„ |
| Vector Databases (ChromaDB, FAISS) | `06_vector_databases.ipynb` | ğŸ”„ |
| Advanced RAG Patterns | `07_advanced_rag_patterns.ipynb` | ğŸ”„ |
| Query Optimization | `08_query_optimization.ipynb` | ğŸ”„ |
| Query Transformation & Routing | `09_query_transformation.ipynb` | ğŸ”„ |
| RAG Fusion & Reranking | `10_rag_fusion_reranking.ipynb` | ğŸ”„ |
| Introduction to LangGraph | `11_langgraph_introduction.ipynb` | ğŸ”„ |
| Building AI Agents | `12_building_agents.ipynb` | ğŸ”„ |
| Agentic AI with Tools | `13_agentic_ai_tools.ipynb` | ğŸ”„ |
| State Management in Agents | `14_agent_state_management.ipynb` | ğŸ”„ |
| CRAG (Corrective RAG) | `15_corrective_rag.ipynb` | ğŸ”„ |

**ğŸ“ Homework:** Build a multi-agent system for data analysis

**ğŸ¯ Checkpoint 4:** Create an intelligent agent that can reason and take actions

---

### **Phase 4: Model Training & Fine-tuning (Weeks 9-10)**

#### ğŸ““ **Week 9-10: MLOps & Fine-tuning**
**Goal:** Learn to train, fine-tune, and deploy models

| Topic | Notebook | Status |
|-------|----------|--------|
| Model Pre-training Concepts | `01_pretraining_concepts.ipynb` | ğŸ”„ |
| Bigram Model Implementation | `02_bigram_model.ipynb` | ğŸ”„ |
| Understanding Tensors | `03_tensors_matrices.ipynb` | ğŸ”„ |
| Forward & Backward Pass | `04_forward_backward_pass.ipynb` | ğŸ”„ |
| MLP Implementation | `05_mlp_implementation.ipynb` | ğŸ”„ |
| Mini-batch Training | `06_minibatch_training.ipynb` | ğŸ”„ |
| Fine-tuning vs RAG | `07_finetuning_vs_rag.ipynb` | ğŸ”„ |
| Parameter Efficient Fine-Tuning (PEFT) | `08_peft_introduction.ipynb` | ğŸ”„ |
| LoRA & QLoRA | `09_lora_qlora.ipynb` | ğŸ”„ |
| Fine-tuning Practical | `10_finetuning_practical.ipynb` | ğŸ”„ |
| Model Evaluation & Metrics | `11_model_evaluation.ipynb` | ğŸ”„ |

**ğŸ“ Homework:** Fine-tune a model for domain-specific task

**ğŸ¯ Checkpoint 5:** Successfully fine-tune and evaluate a model

---

### **Phase 5: Production & Capstone (Weeks 11-12)**

#### ğŸ“” **Week 11-12: Production Deployment & Capstone Project**
**Goal:** Deploy production-grade Gen AI applications

| Topic | Notebook | Status |
|-------|----------|--------|
| MLOps Fundamentals | `01_mlops_fundamentals.ipynb` | ğŸ”„ |
| FastAPI for ML Serving | `02_fastapi_ml_serving.ipynb` | ğŸ”„ |
| Docker & Containerization | `03_docker_containerization.ipynb` | ğŸ”„ |
| Model Monitoring & Logging | `04_monitoring_logging.ipynb` | ğŸ”„ |
| CI/CD with GitHub Actions | `05_cicd_github_actions.ipynb` | ğŸ”„ |
| GCP Deployment | `06_gcp_deployment.ipynb` | ğŸ”„ |
| Terraform Infrastructure | `07_terraform_iac.ipynb` | ğŸ”„ |
| Kubernetes Orchestration | `08_kubernetes_orchestration.ipynb` | ğŸ”„ |

**ğŸ“ Capstone Project:** Production-Grade Gen AI Application
- See [CAPSTONE_PROJECT.md](./CAPSTONE_PROJECT.md) for detailed roadmap

**ğŸ¯ Final Checkpoint:** Deploy fully functional, production-ready application

---

## ğŸ—ï¸ Capstone Project: Intelligent Manufacturing Quality Assistant

**Domain:** Smart Manufacturing (India-focused)

### Project Overview
Build an **Intelligent Manufacturing Quality Control & Predictive Maintenance System** using Gen AI, designed for Indian manufacturing facilities in automotive, pharmaceutical, or electronics sectors.

### Key Features
- ğŸ“¸ **Visual Quality Inspection** using Vision-Language Models
- ğŸ“Š **Predictive Maintenance** using RAG + time-series analysis
- ğŸ¤– **Intelligent Agent** for root-cause analysis
- ğŸ“ **Automated Report Generation** in multiple Indian languages
- ğŸ”§ **Production-Ready Deployment** with Docker, Terraform, GCP

### Tech Stack
- **LLMs:** Open-source models via HuggingFace Endpoints
- **Frameworks:** LangChain, LangGraph, FastAPI
- **Vector DB:** ChromaDB / FAISS (open-source)
- **Monitoring:** Prometheus, Grafana (open-source)
- **Infrastructure:** Docker, Terraform, GCP (Cloud Run / GKE)
- **CI/CD:** GitHub Actions

**Full roadmap:** [CAPSTONE_PROJECT.md](./CAPSTONE_PROJECT.md)

---

## ğŸ› ï¸ Environment Setup

### Prerequisites
- Python 3.10+
- GitHub Codespaces (recommended) or local setup
- HuggingFace account (free tier)
- GCP account (free tier sufficient for learning)

### Quick Start

```bash
# Clone the repository
git clone <your-repo-url>
cd T_Tech

# Install dependencies (automatically handled in Codespaces)
pip install -r requirements.txt

# Set up HuggingFace token
# Get your token from: https://huggingface.co/settings/tokens
export HUGGINGFACE_TOKEN="your_token_here"

# Launch Jupyter
jupyter lab
```

### Using GitHub Codespaces
1. Click "Code" â†’ "Create codespace on main"
2. Wait for environment to build (automated setup)
3. Start with `00_environment_setup.ipynb`

**Detailed setup:** [GETTING_STARTED.md](./GETTING_STARTED.md)

---

## ğŸ“Š Progress Tracking

Track your journey using our built-in progress tracker:

```bash
# View your progress
python scripts/check_progress.py

# Update completion status
python scripts/update_progress.py --week 1 --notebook 1 --status completed
```

**Dashboard:** [PROGRESS_TRACKER.md](./PROGRESS_TRACKER.md)

---

## ğŸ“ Homework & Assessments

Each module includes hands-on homework assignments:

### Mini-Projects
1. **Week 1-2:** Exploratory Data Analysis on manufacturing dataset
2. **Week 3-4:** Text Classification with Transformers
3. **Week 5-6:** Domain-specific Q&A with RAG
4. **Week 7-8:** Multi-agent system for data analysis
5. **Week 9-10:** Model fine-tuning for custom task
6. **Week 11-12:** Capstone project deployment

**Submission guidelines:** [HOMEWORK.md](./HOMEWORK.md)

---

## ğŸ“ Learning Outcomes

By completing this course, you will:

### Technical Skills
- âœ… Master Python, NumPy, Pandas, and ML fundamentals
- âœ… Understand Transformer architecture from the ground up
- âœ… Build and deploy LLM-powered applications
- âœ… Implement RAG systems with query optimization
- âœ… Create intelligent agents using LangGraph
- âœ… Fine-tune models using LoRA/QLoRA
- âœ… Deploy production systems with Docker, Terraform, GCP
- âœ… Implement CI/CD pipelines with GitHub Actions

### Portfolio Projects
- âœ… 6 Mini-projects demonstrating specific skills
- âœ… 1 Production-grade capstone project
- âœ… GitHub repository showcasing your work

### Career Readiness
- âœ… Portfolio that impresses employers
- âœ… Hands-on experience with industry tools
- âœ… Understanding of production ML systems
- âœ… Ability to ship Gen AI products

---

## ğŸ“ Repository Structure

```
T_Tech/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ GETTING_STARTED.md                 # Setup instructions
â”œâ”€â”€ CAPSTONE_PROJECT.md                # Detailed capstone roadmap
â”œâ”€â”€ PROGRESS_TRACKER.md                # Track your progress
â”œâ”€â”€ HOMEWORK.md                        # Assignment guidelines
â”œâ”€â”€ COURSE_SUMMARY.md                  # Quick reference guide
â”œâ”€â”€ FAQ.md                             # Common questions
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .devcontainer/                     # Codespaces configuration
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ 00_environment_setup.ipynb         # Initial setup notebook
â”‚
â”œâ”€â”€ week-01-02-python-ml-foundations/  # Weeks 1-2
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_environment_setup.ipynb
â”‚   â”œâ”€â”€ 02_python_essentials.ipynb
â”‚   â”œâ”€â”€ 03_numpy_pandas.ipynb
â”‚   â”œâ”€â”€ 04_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 05_ml_foundations.ipynb
â”‚   â””â”€â”€ HOMEWORK.md
â”‚
â”œâ”€â”€ week-03-04-deep-learning-nlp/      # Weeks 3-4
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_neural_networks.ipynb
â”‚   â”œâ”€â”€ 02_cnns_basics.ipynb
â”‚   â”œâ”€â”€ 03_rnns_sequences.ipynb
â”‚   â”œâ”€â”€ 04_transformer_architecture.ipynb
â”‚   â”œâ”€â”€ 05_attention_mechanism.ipynb
â”‚   â”œâ”€â”€ 06_embeddings_tokenization.ipynb
â”‚   â”œâ”€â”€ 07_huggingface_intro.ipynb
â”‚   â””â”€â”€ HOMEWORK.md
â”‚
â”œâ”€â”€ week-05-06-llms-rag/               # Weeks 5-6
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_llms_introduction.ipynb
â”‚   â”œâ”€â”€ 02_huggingface_tasks.ipynb
â”‚   â”œâ”€â”€ 03_model_selection_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_tokenizers_advanced.ipynb
â”‚   â”œâ”€â”€ 05_prompt_engineering.ipynb
â”‚   â”œâ”€â”€ 06_few_shot_learning.ipynb
â”‚   â”œâ”€â”€ 07_rag_introduction.ipynb
â”‚   â”œâ”€â”€ 08_rag_implementation.ipynb
â”‚   â”œâ”€â”€ 09_vector_embeddings.ipynb
â”‚   â””â”€â”€ HOMEWORK.md
â”‚
â”œâ”€â”€ week-07-08-langchain-agents/       # Weeks 7-8
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_langchain_essentials.ipynb
â”‚   â”œâ”€â”€ 02_langchain_messages.ipynb
â”‚   â”œâ”€â”€ 03_prompt_templates_chains.ipynb
â”‚   â”œâ”€â”€ 04_runnable_sequences.ipynb
â”‚   â”œâ”€â”€ 05_document_loaders.ipynb
â”‚   â”œâ”€â”€ 06_vector_databases.ipynb
â”‚   â”œâ”€â”€ 07_advanced_rag_patterns.ipynb
â”‚   â”œâ”€â”€ 08_query_optimization.ipynb
â”‚   â”œâ”€â”€ 09_query_transformation.ipynb
â”‚   â”œâ”€â”€ 10_rag_fusion_reranking.ipynb
â”‚   â”œâ”€â”€ 11_langgraph_introduction.ipynb
â”‚   â”œâ”€â”€ 12_building_agents.ipynb
â”‚   â”œâ”€â”€ 13_agentic_ai_tools.ipynb
â”‚   â”œâ”€â”€ 14_agent_state_management.ipynb
â”‚   â”œâ”€â”€ 15_corrective_rag.ipynb
â”‚   â””â”€â”€ HOMEWORK.md
â”‚
â”œâ”€â”€ week-09-10-training-finetuning/    # Weeks 9-10
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_pretraining_concepts.ipynb
â”‚   â”œâ”€â”€ 02_bigram_model.ipynb
â”‚   â”œâ”€â”€ 03_tensors_matrices.ipynb
â”‚   â”œâ”€â”€ 04_forward_backward_pass.ipynb
â”‚   â”œâ”€â”€ 05_mlp_implementation.ipynb
â”‚   â”œâ”€â”€ 06_minibatch_training.ipynb
â”‚   â”œâ”€â”€ 07_finetuning_vs_rag.ipynb
â”‚   â”œâ”€â”€ 08_peft_introduction.ipynb
â”‚   â”œâ”€â”€ 09_lora_qlora.ipynb
â”‚   â”œâ”€â”€ 10_finetuning_practical.ipynb
â”‚   â”œâ”€â”€ 11_model_evaluation.ipynb
â”‚   â””â”€â”€ HOMEWORK.md
â”‚
â”œâ”€â”€ week-11-12-production-capstone/    # Weeks 11-12
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ 01_mlops_fundamentals.ipynb
â”‚   â”œâ”€â”€ 02_fastapi_ml_serving.ipynb
â”‚   â”œâ”€â”€ 03_docker_containerization.ipynb
â”‚   â”œâ”€â”€ 04_monitoring_logging.ipynb
â”‚   â”œâ”€â”€ 05_cicd_github_actions.ipynb
â”‚   â”œâ”€â”€ 06_gcp_deployment.ipynb
â”‚   â”œâ”€â”€ 07_terraform_iac.ipynb
â”‚   â”œâ”€â”€ 08_kubernetes_orchestration.ipynb
â”‚   â”œâ”€â”€ HOMEWORK.md
â”‚   â””â”€â”€ capstone/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docs/
â”‚       â”œâ”€â”€ src/
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ infrastructure/
â”‚       â”œâ”€â”€ .github/workflows/
â”‚       â””â”€â”€ docker/
â”‚
â”œâ”€â”€ datasets/                          # Sample datasets
â”‚   â”œâ”€â”€ manufacturing/
â”‚   â”œâ”€â”€ pharma/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ check_progress.py
â”‚   â”œâ”€â”€ update_progress.py
â”‚   â””â”€â”€ setup_env.py
â”‚
â””â”€â”€ resources/                         # Additional resources
    â”œâ”€â”€ cheatsheets/
    â”œâ”€â”€ references/
    â””â”€â”€ papers/
```

---

## ğŸ”— Important Links

- **HuggingFace Documentation:** https://huggingface.co/docs
- **LangChain Documentation:** https://python.langchain.com/
- **LangGraph Documentation:** https://langchain-ai.github.io/langgraph/
- **Transformers Course:** https://huggingface.co/learn/nlp-course
- **FastAPI Documentation:** https://fastapi.tiangolo.com/
- **Docker Documentation:** https://docs.docker.com/
- **Terraform Documentation:** https://www.terraform.io/docs
- **GCP Documentation:** https://cloud.google.com/docs

---

## ğŸ’¡ Tips for Success

1. **Follow the sequence:** Topics build on each other
2. **Code along:** Don't just read, implement everything
3. **Complete homework:** Mini-projects solidify learning
4. **Use checkpoints:** They ensure you're on track
5. **Ask questions:** Use GitHub Issues for course questions
6. **Build in public:** Share your progress on LinkedIn/Twitter
7. **Focus on capstone:** It's your portfolio centerpiece

---

## ğŸ¤ Community & Support

### Getting Help
- ğŸ“§ **Email:** [Your Email]
- ğŸ’¬ **Discord:** [Community Link]
- ğŸ› **Issues:** [GitHub Issues]
- ğŸ“ **Discussions:** [GitHub Discussions]

### Contributing
Found a bug or want to improve something? Contributions welcome!
See [CONTRIBUTING.md](./CONTRIBUTING.md)

---

## ğŸ“œ License

This course is released under the MIT License. See [LICENSE](./LICENSE) for details.

---

## ğŸŒŸ Acknowledgments

This course is inspired by:
- Sumit Mittal's Gen AI Masters Program Curriculum
- HuggingFace's Transformers Course
- LangChain Academy
- Fast.ai courses

Special thanks to the open-source community for making cutting-edge AI accessible to everyone.

---

## ğŸš€ Ready to Start?

1. â­ **Star this repository** to bookmark your progress
2. ğŸ“– Read [GETTING_STARTED.md](./GETTING_STARTED.md)
3. ğŸ”§ Complete [00_environment_setup.ipynb](./00_environment_setup.ipynb)
4. ğŸ¯ Begin with Week 1-2 modules
5. ğŸ“Š Track progress in [PROGRESS_TRACKER.md](./PROGRESS_TRACKER.md)

**Let's begin your journey to becoming a Gen AI Master! ğŸš€**

---

<div align="center">
Made with â¤ï¸ for aspiring AI Engineers | Last Updated: October 2025
</div>
