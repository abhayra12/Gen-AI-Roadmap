# 🚀 Gen AI Masters Program
### From Beginner to Production-Ready AI Engineer in 12 Weeks

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![GitHub Codespaces](https://img.shields.io/badge/Codespace-Ready-success)](https://github.com/features/codespaces)
[![HuggingFace](https://img.shields.io/badge/🤗-HuggingFace-yellow)](https://huggingface.co/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **"Master Generative AI through hands-on projects and deploy production-grade solutions"**

---

## 📚 Course Overview

Welcome to the most comprehensive, hands-on Gen AI Masters Program designed to take you from **beginner to production-ready AI engineer** in just 12 weeks! This course combines cutting-edge theory with practical implementation, culminating in a **portfolio-worthy capstone project**.

### 🎯 What You'll Build

By the end of this course, you'll have:
- ✅ **15+ Jupyter Notebooks** covering every Gen AI concept
- ✅ **6 Mini-Projects** demonstrating real-world applications
- ✅ **1 Production-Grade Capstone Project** (Containerized, CI/CD, Cloud-Deployed)
- ✅ **Deep understanding** of Transformers, LLMs, RAG, and Agentic AI
- ✅ **Portfolio** that stands out to employers

---

## 🗓️ 12-Week Learning Journey

### **Phase 1: Foundations (Weeks 1-4)**

#### 📘 **Week 1-2: Python & ML Fundamentals**
**Goal:** Build strong programming and ML foundations

| Topic | Notebook | Status |
|-------|----------|--------|
| Environment Setup | `01_environment_setup.ipynb` | ✅ |
| Python Essentials | `02_python_essentials.ipynb` | ✅ |
| NumPy & Pandas Mastery | `03_numpy_pandas.ipynb` | 🔄 |
| Data Preprocessing | `04_data_preprocessing.ipynb` | 🔄 |
| Classical ML Foundations | `05_ml_foundations.ipynb` | 🔄 |

**📝 Homework:** Data Analysis Mini-Project

**🎯 Checkpoint 1:** Complete Python & ML fundamentals assessment

---

#### 📗 **Week 3-4: Deep Learning & NLP Foundations**
**Goal:** Master neural networks and NLP basics

| Topic | Notebook | Status |
|-------|----------|--------|
| Neural Networks Fundamentals | `01_neural_networks.ipynb` | 🔄 |
| CNNs for Computer Vision | `02_cnns_basics.ipynb` | 🔄 |
| RNNs & Sequence Models | `03_rnns_sequences.ipynb` | 🔄 |
| Introduction to Transformers | `04_transformer_architecture.ipynb` | 🔄 |
| Transformer Internals | `05_attention_mechanism.ipynb` | 🔄 |
| Token Embeddings & Context | `06_embeddings_tokenization.ipynb` | 🔄 |
| HuggingFace Ecosystem | `07_huggingface_intro.ipynb` | 🔄 |

**📝 Homework:** Build a text classifier using HuggingFace

**🎯 Checkpoint 2:** Implement transformer from scratch (simplified version)

---

### **Phase 2: LLMs & Advanced NLP (Weeks 5-6)**

#### 📙 **Week 5-6: LLMs, Prompt Engineering & RAG**
**Goal:** Master Large Language Models and their applications

| Topic | Notebook | Status |
|-------|----------|--------|
| Introduction to LLMs | `01_llms_introduction.ipynb` | 🔄 |
| HuggingFace Tasks (Sentiment, Summarization, etc.) | `02_huggingface_tasks.ipynb` | 🔄 |
| Model Selection & Pre-processing | `03_model_selection_preprocessing.ipynb` | 🔄 |
| Tokenizers Deep Dive | `04_tokenizers_advanced.ipynb` | 🔄 |
| Prompt Engineering Techniques | `05_prompt_engineering.ipynb` | 🔄 |
| Few-Shot Learning | `06_few_shot_learning.ipynb` | 🔄 |
| Introduction to RAG | `07_rag_introduction.ipynb` | 🔄 |
| RAG Implementation | `08_rag_implementation.ipynb` | 🔄 |
| Vector Embeddings | `09_vector_embeddings.ipynb` | 🔄 |

**📝 Homework:** Build a domain-specific Q&A system using RAG

**🎯 Checkpoint 3:** Deploy a working RAG application

---

### **Phase 3: Advanced RAG & Agentic AI (Weeks 7-8)**

#### 📕 **Week 7-8: LangChain, Agents & Advanced RAG**
**Goal:** Build intelligent agents and production-grade RAG systems

| Topic | Notebook | Status |
|-------|----------|--------|
| LangChain Framework | `01_langchain_essentials.ipynb` | 🔄 |
| LangChain Message Structure | `02_langchain_messages.ipynb` | 🔄 |
| Prompt Templates & Chains | `03_prompt_templates_chains.ipynb` | 🔄 |
| Runnable Sequences | `04_runnable_sequences.ipynb` | 🔄 |
| Document Loaders & Chunking | `05_document_loaders.ipynb` | 🔄 |
| Vector Databases (ChromaDB, FAISS) | `06_vector_databases.ipynb` | 🔄 |
| Advanced RAG Patterns | `07_advanced_rag_patterns.ipynb` | 🔄 |
| Query Optimization | `08_query_optimization.ipynb` | 🔄 |
| Query Transformation & Routing | `09_query_transformation.ipynb` | 🔄 |
| RAG Fusion & Reranking | `10_rag_fusion_reranking.ipynb` | 🔄 |
| Introduction to LangGraph | `11_langgraph_introduction.ipynb` | 🔄 |
| Building AI Agents | `12_building_agents.ipynb` | 🔄 |
| Agentic AI with Tools | `13_agentic_ai_tools.ipynb` | 🔄 |
| State Management in Agents | `14_agent_state_management.ipynb` | 🔄 |
| CRAG (Corrective RAG) | `15_corrective_rag.ipynb` | 🔄 |

**📝 Homework:** Build a multi-agent system for data analysis

**🎯 Checkpoint 4:** Create an intelligent agent that can reason and take actions

---

### **Phase 4: Model Training & Fine-tuning (Weeks 9-10)**

#### 📓 **Week 9-10: MLOps & Fine-tuning**
**Goal:** Learn to train, fine-tune, and deploy models

| Topic | Notebook | Status |
|-------|----------|--------|
| Model Pre-training Concepts | `01_pretraining_concepts.ipynb` | 🔄 |
| Bigram Model Implementation | `02_bigram_model.ipynb` | 🔄 |
| Understanding Tensors | `03_tensors_matrices.ipynb` | 🔄 |
| Forward & Backward Pass | `04_forward_backward_pass.ipynb` | 🔄 |
| MLP Implementation | `05_mlp_implementation.ipynb` | 🔄 |
| Mini-batch Training | `06_minibatch_training.ipynb` | 🔄 |
| Fine-tuning vs RAG | `07_finetuning_vs_rag.ipynb` | 🔄 |
| Parameter Efficient Fine-Tuning (PEFT) | `08_peft_introduction.ipynb` | 🔄 |
| LoRA & QLoRA | `09_lora_qlora.ipynb` | 🔄 |
| Fine-tuning Practical | `10_finetuning_practical.ipynb` | 🔄 |
| Model Evaluation & Metrics | `11_model_evaluation.ipynb` | 🔄 |

**📝 Homework:** Fine-tune a model for domain-specific task

**🎯 Checkpoint 5:** Successfully fine-tune and evaluate a model

---

### **Phase 5: Production & Capstone (Weeks 11-12)**

#### 📔 **Week 11-12: Production Deployment & Capstone Project**
**Goal:** Deploy production-grade Gen AI applications

| Topic | Notebook | Status |
|-------|----------|--------|
| MLOps Fundamentals | `01_mlops_fundamentals.ipynb` | 🔄 |
| FastAPI for ML Serving | `02_fastapi_ml_serving.ipynb` | 🔄 |
| Docker & Containerization | `03_docker_containerization.ipynb` | 🔄 |
| Model Monitoring & Logging | `04_monitoring_logging.ipynb` | 🔄 |
| CI/CD with GitHub Actions | `05_cicd_github_actions.ipynb` | 🔄 |
| GCP Deployment | `06_gcp_deployment.ipynb` | 🔄 |
| Terraform Infrastructure | `07_terraform_iac.ipynb` | 🔄 |
| Kubernetes Orchestration | `08_kubernetes_orchestration.ipynb` | 🔄 |

**📝 Capstone Project:** Production-Grade Gen AI Application
- See [CAPSTONE_PROJECT.md](./CAPSTONE_PROJECT.md) for detailed roadmap

**🎯 Final Checkpoint:** Deploy fully functional, production-ready application

---

## 🏗️ Capstone Project: Intelligent Manufacturing Quality Assistant

**Domain:** Smart Manufacturing (India-focused)

### Project Overview
Build an **Intelligent Manufacturing Quality Control & Predictive Maintenance System** using Gen AI, designed for Indian manufacturing facilities in automotive, pharmaceutical, or electronics sectors.

### Key Features
- 📸 **Visual Quality Inspection** using Vision-Language Models
- 📊 **Predictive Maintenance** using RAG + time-series analysis
- 🤖 **Intelligent Agent** for root-cause analysis
- 📝 **Automated Report Generation** in multiple Indian languages
- 🔧 **Production-Ready Deployment** with Docker, Terraform, GCP

### Tech Stack
- **LLMs:** Open-source models via HuggingFace Endpoints
- **Frameworks:** LangChain, LangGraph, FastAPI
- **Vector DB:** ChromaDB / FAISS (open-source)
- **Monitoring:** Prometheus, Grafana (open-source)
- **Infrastructure:** Docker, Terraform, GCP (Cloud Run / GKE)
- **CI/CD:** GitHub Actions

**Full roadmap:** [CAPSTONE_PROJECT.md](./CAPSTONE_PROJECT.md)

---

## 🛠️ Environment Setup

### Prerequisites
- Python 3.10+
- GitHub Codespaces (recommended) or local setup
- HuggingFace account (free tier)
- GCP account (free tier sufficient for learning)

### Quick Start

```bash
# Clone the repository
git clone <your-repo-url>
cd T_Tech

# Install dependencies (automatically handled in Codespaces)
pip install -r requirements.txt

# Set up HuggingFace token
# Get your token from: https://huggingface.co/settings/tokens
export HUGGINGFACE_TOKEN="your_token_here"

# Launch Jupyter
jupyter lab
```

### Using GitHub Codespaces
1. Click "Code" → "Create codespace on main"
2. Wait for environment to build (automated setup)
3. Start with `00_environment_setup.ipynb`

**Detailed setup:** [GETTING_STARTED.md](./GETTING_STARTED.md)

---

## 📊 Progress Tracking

Track your journey using our built-in progress tracker:

```bash
# View your progress
python scripts/check_progress.py

# Update completion status
python scripts/update_progress.py --week 1 --notebook 1 --status completed
```

**Dashboard:** [PROGRESS_TRACKER.md](./PROGRESS_TRACKER.md)

---

## 📝 Homework & Assessments

Each module includes hands-on homework assignments:

### Mini-Projects
1. **Week 1-2:** Exploratory Data Analysis on manufacturing dataset
2. **Week 3-4:** Text Classification with Transformers
3. **Week 5-6:** Domain-specific Q&A with RAG
4. **Week 7-8:** Multi-agent system for data analysis
5. **Week 9-10:** Model fine-tuning for custom task
6. **Week 11-12:** Capstone project deployment

**Submission guidelines:** [HOMEWORK.md](./HOMEWORK.md)

---

## 🎓 Learning Outcomes

By completing this course, you will:

### Technical Skills
- ✅ Master Python, NumPy, Pandas, and ML fundamentals
- ✅ Understand Transformer architecture from the ground up
- ✅ Build and deploy LLM-powered applications
- ✅ Implement RAG systems with query optimization
- ✅ Create intelligent agents using LangGraph
- ✅ Fine-tune models using LoRA/QLoRA
- ✅ Deploy production systems with Docker, Terraform, GCP
- ✅ Implement CI/CD pipelines with GitHub Actions

### Portfolio Projects
- ✅ 6 Mini-projects demonstrating specific skills
- ✅ 1 Production-grade capstone project
- ✅ GitHub repository showcasing your work

### Career Readiness
- ✅ Portfolio that impresses employers
- ✅ Hands-on experience with industry tools
- ✅ Understanding of production ML systems
- ✅ Ability to ship Gen AI products

---

## 📁 Repository Structure

```
T_Tech/
├── README.md                          # This file
├── GETTING_STARTED.md                 # Setup instructions
├── CAPSTONE_PROJECT.md                # Detailed capstone roadmap
├── PROGRESS_TRACKER.md                # Track your progress
├── HOMEWORK.md                        # Assignment guidelines
├── COURSE_SUMMARY.md                  # Quick reference guide
├── FAQ.md                             # Common questions
├── requirements.txt                   # Python dependencies
├── .devcontainer/                     # Codespaces configuration
│   └── devcontainer.json
├── 00_environment_setup.ipynb         # Initial setup notebook
│
├── week-01-02-python-ml-foundations/  # Weeks 1-2
│   ├── README.md
│   ├── 01_environment_setup.ipynb
│   ├── 02_python_essentials.ipynb
│   ├── 03_numpy_pandas.ipynb
│   ├── 04_data_preprocessing.ipynb
│   ├── 05_ml_foundations.ipynb
│   └── HOMEWORK.md
│
├── week-03-04-deep-learning-nlp/      # Weeks 3-4
│   ├── README.md
│   ├── 01_neural_networks.ipynb
│   ├── 02_cnns_basics.ipynb
│   ├── 03_rnns_sequences.ipynb
│   ├── 04_transformer_architecture.ipynb
│   ├── 05_attention_mechanism.ipynb
│   ├── 06_embeddings_tokenization.ipynb
│   ├── 07_huggingface_intro.ipynb
│   └── HOMEWORK.md
│
├── week-05-06-llms-rag/               # Weeks 5-6
│   ├── README.md
│   ├── 01_llms_introduction.ipynb
│   ├── 02_huggingface_tasks.ipynb
│   ├── 03_model_selection_preprocessing.ipynb
│   ├── 04_tokenizers_advanced.ipynb
│   ├── 05_prompt_engineering.ipynb
│   ├── 06_few_shot_learning.ipynb
│   ├── 07_rag_introduction.ipynb
│   ├── 08_rag_implementation.ipynb
│   ├── 09_vector_embeddings.ipynb
│   └── HOMEWORK.md
│
├── week-07-08-langchain-agents/       # Weeks 7-8
│   ├── README.md
│   ├── 01_langchain_essentials.ipynb
│   ├── 02_langchain_messages.ipynb
│   ├── 03_prompt_templates_chains.ipynb
│   ├── 04_runnable_sequences.ipynb
│   ├── 05_document_loaders.ipynb
│   ├── 06_vector_databases.ipynb
│   ├── 07_advanced_rag_patterns.ipynb
│   ├── 08_query_optimization.ipynb
│   ├── 09_query_transformation.ipynb
│   ├── 10_rag_fusion_reranking.ipynb
│   ├── 11_langgraph_introduction.ipynb
│   ├── 12_building_agents.ipynb
│   ├── 13_agentic_ai_tools.ipynb
│   ├── 14_agent_state_management.ipynb
│   ├── 15_corrective_rag.ipynb
│   └── HOMEWORK.md
│
├── week-09-10-training-finetuning/    # Weeks 9-10
│   ├── README.md
│   ├── 01_pretraining_concepts.ipynb
│   ├── 02_bigram_model.ipynb
│   ├── 03_tensors_matrices.ipynb
│   ├── 04_forward_backward_pass.ipynb
│   ├── 05_mlp_implementation.ipynb
│   ├── 06_minibatch_training.ipynb
│   ├── 07_finetuning_vs_rag.ipynb
│   ├── 08_peft_introduction.ipynb
│   ├── 09_lora_qlora.ipynb
│   ├── 10_finetuning_practical.ipynb
│   ├── 11_model_evaluation.ipynb
│   └── HOMEWORK.md
│
├── week-11-12-production-capstone/    # Weeks 11-12
│   ├── README.md
│   ├── 01_mlops_fundamentals.ipynb
│   ├── 02_fastapi_ml_serving.ipynb
│   ├── 03_docker_containerization.ipynb
│   ├── 04_monitoring_logging.ipynb
│   ├── 05_cicd_github_actions.ipynb
│   ├── 06_gcp_deployment.ipynb
│   ├── 07_terraform_iac.ipynb
│   ├── 08_kubernetes_orchestration.ipynb
│   ├── HOMEWORK.md
│   └── capstone/
│       ├── README.md
│       ├── docs/
│       ├── src/
│       ├── tests/
│       ├── infrastructure/
│       ├── .github/workflows/
│       └── docker/
│
├── datasets/                          # Sample datasets
│   ├── manufacturing/
│   ├── pharma/
│   └── README.md
│
├── scripts/                           # Utility scripts
│   ├── check_progress.py
│   ├── update_progress.py
│   └── setup_env.py
│
└── resources/                         # Additional resources
    ├── cheatsheets/
    ├── references/
    └── papers/
```

---

## 🔗 Important Links

- **HuggingFace Documentation:** https://huggingface.co/docs
- **LangChain Documentation:** https://python.langchain.com/
- **LangGraph Documentation:** https://langchain-ai.github.io/langgraph/
- **Transformers Course:** https://huggingface.co/learn/nlp-course
- **FastAPI Documentation:** https://fastapi.tiangolo.com/
- **Docker Documentation:** https://docs.docker.com/
- **Terraform Documentation:** https://www.terraform.io/docs
- **GCP Documentation:** https://cloud.google.com/docs

---

## 💡 Tips for Success

1. **Follow the sequence:** Topics build on each other
2. **Code along:** Don't just read, implement everything
3. **Complete homework:** Mini-projects solidify learning
4. **Use checkpoints:** They ensure you're on track
5. **Ask questions:** Use GitHub Issues for course questions
6. **Build in public:** Share your progress on LinkedIn/Twitter
7. **Focus on capstone:** It's your portfolio centerpiece

---

## 🤝 Community & Support

### Getting Help
- 📧 **Email:** [Your Email]
- 💬 **Discord:** [Community Link]
- 🐛 **Issues:** [GitHub Issues]
- 📝 **Discussions:** [GitHub Discussions]

### Contributing
Found a bug or want to improve something? Contributions welcome!
See [CONTRIBUTING.md](./CONTRIBUTING.md)

---

## 📜 License

This course is released under the MIT License. See [LICENSE](./LICENSE) for details.

---

## 🌟 Acknowledgments

This course is inspired by:
- Sumit Mittal's Gen AI Masters Program Curriculum
- HuggingFace's Transformers Course
- LangChain Academy
- Fast.ai courses

Special thanks to the open-source community for making cutting-edge AI accessible to everyone.

---

## 🚀 Ready to Start?

1. ⭐ **Star this repository** to bookmark your progress
2. 📖 Read [GETTING_STARTED.md](./GETTING_STARTED.md)
3. 🔧 Complete [00_environment_setup.ipynb](./00_environment_setup.ipynb)
4. 🎯 Begin with Week 1-2 modules
5. 📊 Track progress in [PROGRESS_TRACKER.md](./PROGRESS_TRACKER.md)

**Let's begin your journey to becoming a Gen AI Master! 🚀**

---

<div align="center">
Made with ❤️ for aspiring AI Engineers | Last Updated: October 2025
</div>
